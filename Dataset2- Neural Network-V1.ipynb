{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ad1a2a",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff62b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#data pre-processing packages\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#results and analysis packages\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78cf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data modelling & results\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#NN\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#feature importance\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304bd4d",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd727e",
   "metadata": {},
   "source": [
    "## Error computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4247b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the Root Mean Squared Error\n",
    "\n",
    "def rmse(y_true, y_predicted):\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910f4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors computation\n",
    "\n",
    "def errors_computation(data):\n",
    "    \n",
    "    df=pd.DataFrame()\n",
    "    #df.at['RMSE (as root mean)', 'Wind']= round(rmse(data['Target'], data['WS_pred']), 3)\n",
    "    df.at['MAE (in avg)', 'Wind']= round(mae(data['Target'], data['WS_pred']), 3)\n",
    "    df.at['MAPE (%)', 'Wind']= round(mape(data['Target'], data['WS_pred'])*100, 3)\n",
    "    \n",
    "    #df.at['RMSE (as root mean)', 'Power']= round(rmse(data['P'], data['P_pred']), 3)\n",
    "    df.at['MAE (in avg)', 'Power']= round(mae(data['P'], data['P_pred']), 3)\n",
    "    df.at['MAPE (%)', 'Power']= round(mape(data['P'], data['P_pred'])*100, 3)\n",
    "    \n",
    "    \n",
    "    print('Wind RMSE: ', round(rmse(data['Target'], data['WS_pred']), 3), 'm/s as root mean')\n",
    "    print('Wind MAE: ', round(mae(data['Target'], data['WS_pred']), 3), 'm/s in avg')\n",
    "    print('Wind MAPE: ', round(mape(data['Target'], data['WS_pred'])*100, 3), '%')\n",
    "    \n",
    "    print('Power RMSE: ', round(rmse(data['P'], data['P_pred']), 3), 'kW as root mean')\n",
    "    print('Power MAE: ', round(mae(data['P'], data['P_pred']), 3), 'kW in avg')\n",
    "    print('Power MAPE: ', round(mape(data['P'], data['P_pred'])*100, 3), '%')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9f017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(data, title):\n",
    "    \n",
    "    #title is expected to be an str\n",
    "    #WS_pred and Target should be the variables names\n",
    "\n",
    "    #plotting the reference\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot([-1,17.5],[-1,17.5], 'green', linewidth=4, alpha=.12)\n",
    "    plt.plot(data['WS_pred'], data['Target'], marker='o', ls='', label='Regression', markersize=5, alpha=.1)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    ax=plt.gca()\n",
    "    ax.set(xlabel='y predicted', ylabel='y actual');\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(ymin=4, ymax=17.5)\n",
    "    ax.set_xlim(xmin=4, xmax=17.5)\n",
    "    \n",
    "    return print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58bd13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powercurve_computation(data, power_curve):\n",
    "    \n",
    "    from scipy import interpolate\n",
    "    \n",
    "    #this function computes the power at a observation given the information at a observation:\n",
    "    # the WS (in m/s) at the wind turbine location and at the hub height (Target)\n",
    "    # the power curve of the wind turbine in an xslx\n",
    "    \n",
    "    \n",
    "    x=power_curve['Wind Speed [m/s]']\n",
    "    y=power_curve['Warranted Power Curve [kW]']\n",
    "    x_new=data['Target']\n",
    "    \n",
    "    f = interpolate.interp1d(x, y)\n",
    "    #, kind='linear'\n",
    "    data['P']=f(x_new)\n",
    "    \n",
    "    if 'WS_pred' in data.keys():\n",
    "        x_new2=data['WS_pred']\n",
    "        data['P_pred']=f(x_new2)\n",
    "    \n",
    "    print('power curve computation performed')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c09062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_power_computation (data_test, data_train, power_curve):\n",
    "    \n",
    "    results_test=pd.DataFrame()\n",
    "    results_train=pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    results_test=powercurve_computation(data_test, power_curve)\n",
    "    results_train=powercurve_computation(data_train, power_curve)\n",
    "\n",
    "    return results_test, results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3896d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results(data_test, data_train, power_curve, plot_error):\n",
    "    \n",
    "    #this function computes and plots the results of a modelling:\n",
    "\n",
    "    results_test, results_train=control_power_computation (data_test, data_train, power_curve)\n",
    "    \n",
    "    \n",
    "    print('Modelling errors for training set:')\n",
    "    errors_computation(results_train)\n",
    "    print('')\n",
    "    print('Modelling errors for test set:')\n",
    "    errors_computation(results_test)\n",
    "    \n",
    "    if plot_error:\n",
    "        print('')\n",
    "        error_plot(results_test, 'Error plot for test set wind speed')\n",
    "\n",
    "    print('')\n",
    "    return print('Showing the results of the modelling: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71970e76",
   "metadata": {},
   "source": [
    "## Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bcfb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploading_csv(file_folder,file_name):\n",
    "    \n",
    "    #file folder required\n",
    "    #file name required\n",
    "    #file is expected to be in the data root: r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    #this function uploads and formats csv/txt/xlsx datasets into DataFrame\n",
    "    \n",
    "    \n",
    "    data_root=r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    data_folder=str(file_folder)\n",
    "    data_file=str(file_name)\n",
    "    \n",
    "    data_path=data_root+data_folder+data_file\n",
    "    \n",
    "    data1 = pd.read_csv(data_path)\n",
    "\n",
    "    \n",
    "    # We will save the WD_bin as the index\n",
    "    \n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c5e33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function saves a data csv\n",
    "\n",
    "def save (data, file_folder,file_name):\n",
    "    \n",
    "    #file folder required\n",
    "    #file name required\n",
    "    #file is expected to be saved in the data root: r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    #this function saves a csv/txt/xlsx into Irma's folder\n",
    "    #the saved file will keep the columns names but not the index\n",
    "    \n",
    "    data_root=r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    data_folder=str(file_folder)\n",
    "    data_file=str(file_name)\n",
    "    \n",
    "    data_path=data_root+data_folder+data_file\n",
    "    \n",
    "    data.to_csv (data_path, index = False, header=True)\n",
    "    \n",
    "    \n",
    "    return print('file', data_file, 'saved in', data_folder, 'folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaedaca",
   "metadata": {},
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "358a5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_selection(X_train, X_test, inputs):\n",
    "    \n",
    "    #this function returns the columns of the training and test sets in the inputs list\n",
    "    \n",
    "    X_train1 = pd.DataFrame()\n",
    "    X_test1 = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    X_train1 = X_train[inputs]\n",
    "    X_test1 = X_test[inputs]\n",
    "\n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd717ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_drop(X_train, X_test, list_2drop):\n",
    "    \n",
    "    #this function returns the columns of the training and test sets in the inputs list\n",
    "\n",
    "    X_train1 = X_train.drop(columns=list_2drop)\n",
    "    X_test1 = X_test.drop(columns=list_2drop)\n",
    "\n",
    "    \n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c2b31",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5c814",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eec63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model (n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8],\n",
    "                 activation='relu', optimizer='Adam', regularization=None, Leaky=False):\n",
    "    \n",
    "    #this function build model is created only for building the NN\n",
    "    #it will always initialize the weights using the strategy 'He normal' unless activation function 'selu' is selected\n",
    "    \n",
    "    \n",
    "    if activation!='relu':\n",
    "        Leaky==False\n",
    "    \n",
    "    \n",
    "    #we create a sequential model:\n",
    "    model=keras.models.Sequential()\n",
    "    \n",
    "    #we add the input layer with n_neurons=n_features (shape of X_train)\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    #we add a hidden layer for each n_hidden with ReLU as activation function\n",
    "    #this code considers the same n_neurons for each hidden layer\n",
    "    for layer in range(n_hidden):\n",
    "        \n",
    "        if regularization=='l2':\n",
    "            if activation=='relu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal',\n",
    "                                            kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "            elif activation=='elu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal',\n",
    "                                            kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "            elif activation=='selu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal',\n",
    "                                           kernel_regularizer=keras.regularizers.l2(0.01)))  \n",
    "        elif regularization=='l1':\n",
    "            if activation=='relu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal',\n",
    "                                             kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "            elif activation=='elu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal',\n",
    "                                             kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "            elif activation=='selu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal',\n",
    "                                            kernel_regularizer=keras.regularizers.l1(0.01))) \n",
    "        else:\n",
    "            if activation=='relu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal'))\n",
    "            elif activation=='elu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal'))\n",
    "            elif activation=='selu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal'))\n",
    "        \n",
    "        if Leaky:\n",
    "            model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    #dropout only considered in the last layer\n",
    "    if regularization=='Dropout':\n",
    "        model.add(keras.layers.Dropout(rate=0.2))\n",
    "        \n",
    "    #we add the output layer with one neuron (we only want to predict 1 target)\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    #we choose our optimizer and build it:\n",
    "    if optimizer=='SGD':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate)\n",
    "    elif optimizer=='Momentum':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer=='Nesterov':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    elif optimizer=='RMSprop':\n",
    "        optimizer=keras.optimizers.RMSprop(lr=learning_rate, rho=0.9)\n",
    "    elif optimizer=='Adam':\n",
    "        optimizer=keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    elif optimizer=='Nadam':\n",
    "        optimizer=keras.optimizers.Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    \n",
    "    #we compile our model with the selected optimizer and set the objective function loss='mse'\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb2847dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_old (n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8],\n",
    "                 activation='relu', optimizer='Adam', regularization=None, Leaky=False):\n",
    "    \n",
    "    #this function build model is created only for building the NN\n",
    "    #it will always initialize the weights using the strategy 'He normal' unless activation function 'selu' is selected\n",
    "    \n",
    "    \n",
    "    if activation!='relu':\n",
    "        Leaky==False\n",
    "    \n",
    "    \n",
    "    #we create a sequential model:\n",
    "    model=keras.models.Sequential()\n",
    "    \n",
    "    #we add the input layer with n_neurons=n_features (shape of X_train)\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    #we add a hidden layer for each n_hidden with ReLU as activation function\n",
    "    #this code considers the same n_neurons for each hidden layer\n",
    "    for layer in range(n_hidden):\n",
    "        if activation=='relu':\n",
    "            model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal'))\n",
    "        elif activation=='elu':\n",
    "            model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal'))\n",
    "        elif activation=='selu':\n",
    "            model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal'))\n",
    "        if Leaky:\n",
    "            model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "            \n",
    "    if regularization=='Dropout':\n",
    "        model.add(keras.layers.Dropout(rate=0.2))\n",
    "        \n",
    "    #we add the output layer with one neuron (we only want to predict 1 target)\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    #we choose our optimizer and build it:\n",
    "    if optimizer=='SGD':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate)\n",
    "    elif optimizer=='Momentum':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer=='Nesterov':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    elif optimizer=='RMSprop':\n",
    "        optimizer=keras.optimizers.RMSprop(lr=learning_rate, rho=0.9)\n",
    "    elif optimizer=='Adam':\n",
    "        optimizer=keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    elif optimizer=='Nadam':\n",
    "        optimizer=keras.optimizers.Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    \n",
    "    #we compile our model with the selected optimizer and set the objective function loss='mse'\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983f849",
   "metadata": {},
   "source": [
    "### Modelling NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c827782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling_NN (X, X_test, y, y_test, power_curve,  parameters, plot_error, plot):\n",
    "    \n",
    "    #creating the model\n",
    "    \n",
    "    n_hidden=parameters['n_hidden']\n",
    "    n_neurons=parameters['n_neurons']\n",
    "    learning_rate=parameters['learning_rate']\n",
    "    input_shape=X.shape[1:]\n",
    "    activation=parameters['activation']\n",
    "    optimizer=parameters['optimizer']\n",
    "    regularization=parameters['regularization']\n",
    "    Leaky=parameters['Leaky']\n",
    "    \n",
    "    model =build_model(n_hidden, n_neurons, learning_rate, input_shape,\n",
    "                 activation, optimizer, regularization, Leaky)\n",
    " \n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "    if regularization=='Early Stopping':\n",
    "        model.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid))\n",
    "    \n",
    "    \n",
    "#     if plot:\n",
    "#         loss_epochs_plot (history)\n",
    "        \n",
    "    \n",
    "    #model predicting\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    y_pred_valid=model.predict(X_valid)\n",
    "    \n",
    "    rmse_valid=rmse(y_valid, y_pred_valid)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    \n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "    print('')\n",
    "    print('RMSE for validation', rmse_valid)\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('NN modelling performed')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6df93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling_NN_ES (X, X_test, y, y_test, power_curve,  parameters, plot_error, plot):\n",
    "    \n",
    "    #creating the model\n",
    "    \n",
    "    n_hidden=parameters['n_hidden']\n",
    "    n_neurons=parameters['n_neurons']\n",
    "    learning_rate=parameters['learning_rate']\n",
    "    input_shape=X.shape[1:]\n",
    "    activation=parameters['activation']\n",
    "    optimizer=parameters['optimizer']\n",
    "    regularization=parameters['regularization']\n",
    "    Leaky=parameters['Leaky']\n",
    "    \n",
    "    model =build_model(n_hidden, n_neurons, learning_rate, input_shape,\n",
    "                 activation, optimizer, regularization, Leaky)\n",
    " \n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    \n",
    "    \n",
    "#     if plot:\n",
    "#         loss_epochs_plot (history)\n",
    "        \n",
    "    \n",
    "    #model predicting\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    \n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "#     mse_test=model.evaluate(X_test, y_test)\n",
    "#     rmse_test=np.sqrt(mse_test)\n",
    "#     print('RMSE for test', rmse_test)\n",
    "    \n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('NN modelling performed')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c283c5",
   "metadata": {},
   "source": [
    "### Random Search NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c6cd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSearch_NN(X, X_test, y, y_test, power_curve, param_distribs, plot_error):\n",
    "    \n",
    "    #counting the runing time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    #creating the model\n",
    "    input_shape=X.shape[1:]\n",
    "    param_distribs['input_shape']=input_shape\n",
    "    keras_reg =keras.wrappers.scikit_learn.KerasRegressor(build_model, verbose=0)\n",
    "    \n",
    "    \n",
    "    #Random Search CV\n",
    "    rnd_search_cv=RandomizedSearchCV(keras_reg, param_distribs, n_iter=20, cv=3)\n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    regularization=param_distribs['regularization']\n",
    "    \n",
    "    if regularization=='Early Stopping':\n",
    "        rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    else:\n",
    "        rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid))\n",
    "    \n",
    "    \n",
    "    #model predicting\n",
    "    \n",
    "    model=rnd_search_cv.best_estimator_.model\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    print('')\n",
    "    print('Best parameters :')\n",
    "    print(rnd_search_cv.best_params_)\n",
    "    print('Best score :')\n",
    "    print(rnd_search_cv.best_score_)\n",
    "    print('')\n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))\n",
    "    print('')\n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('RandomSearch_ NN performed')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6523601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSearch_NN_ES(X, X_test, y, y_test, power_curve, param_distribs, plot_error):\n",
    "    \n",
    "    #counting the runing time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #creating the model\n",
    "    input_shape=X.shape[1:]\n",
    "    param_distribs['input_shape']=input_shape\n",
    "    keras_reg =keras.wrappers.scikit_learn.KerasRegressor(build_model, verbose=0)\n",
    "    \n",
    "    #Random Search CV\n",
    "    rnd_search_cv=RandomizedSearchCV(keras_reg, param_distribs, n_iter=20, cv=3)\n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    \n",
    "    \n",
    "    #model predicting\n",
    "    \n",
    "    model=rnd_search_cv.best_estimator_.model\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    print('')\n",
    "    print('Best parameters :')\n",
    "    print(rnd_search_cv.best_params_)\n",
    "    print('Best score :')\n",
    "    print(rnd_search_cv.best_score_)\n",
    "    print('')\n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))\n",
    "    print('')\n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('RandomSearch_ NN performed')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7836fc",
   "metadata": {},
   "source": [
    "### Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a862833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_epochs_plot (history):\n",
    "    \n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.show\n",
    "    \n",
    "    return print('Loss vs. epochs plot performed')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54004cbb",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bfe8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing (X_train, X_test, y_train, y_test, power_curve, model, plot_error):\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X_train)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "\n",
    "\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y_train['Target']\n",
    "    \n",
    "    plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    \n",
    "    WS_pred=data_test['WS_pred']\n",
    "    print('NN results performed')\n",
    "    \n",
    "    return WS_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724a96a",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51189ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance (X_train, X_test, model):\n",
    "    \n",
    "    X_t, X_f, y_t, y_f = train_test_split(X_train,y_train, test_size=0.02, random_state=12)\n",
    "    \n",
    "    background = X_f.copy()\n",
    "    \n",
    "    explainer = shap.KernelExplainer(model.predict,background)\n",
    "    shap_values = explainer.shap_values(X_test,nsamples=100)\n",
    "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "    print('Feature importance through SHAP values performed')\n",
    "    \n",
    "\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046028e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_shap (shap_values, X_test):\n",
    "\n",
    "    v=np.array(shap_values)\n",
    "    d=v.reshape(X_test.shape)\n",
    "    shap_v=pd.DataFrame(d)\n",
    "    \n",
    "    feature_list=X_test.columns\n",
    "    shap_v.columns=feature_list\n",
    "    shap_v=shap_v.abs()\n",
    "    k=pd.DataFrame(shap_v.mean()).reset_index()\n",
    "    k.columns=['variables','SHAP_abs']\n",
    "    k.sort_values(by='variables')\n",
    "    \n",
    "    return k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d0819",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fec4a",
   "metadata": {},
   "source": [
    "## Dataset2- T11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3f2c12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WD1', 'WD4', 'WSHor', 'WSVer', 'WDHor', 'T1',\n",
       "       'RH1', 'PR1', 'Rain', 'WSH', 'WVeer', 'TI', 'WDVer', 'WD_bin', 'AD1',\n",
       "       'tod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "# data_up= uploading_csv('\\Dataset1-Normal_Site','\\data_comp14.csv')\n",
    "X_train= uploading_csv('\\Dataset2-Complex_Site','\\X_train11.csv')\n",
    "X_test= uploading_csv('\\Dataset2-Complex_Site','\\X_test11.csv')\n",
    "y_train= uploading_csv('\\Dataset2-Complex_Site','\\y_train11.csv')\n",
    "y_test= uploading_csv('\\Dataset2-Complex_Site','\\y_test11.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0a26d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08af60ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS1</th>\n",
       "      <th>WS3</th>\n",
       "      <th>WS4</th>\n",
       "      <th>WD1</th>\n",
       "      <th>WD4</th>\n",
       "      <th>WSHor</th>\n",
       "      <th>WSVer</th>\n",
       "      <th>WDHor</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH1</th>\n",
       "      <th>PR1</th>\n",
       "      <th>Rain</th>\n",
       "      <th>WSH</th>\n",
       "      <th>WVeer</th>\n",
       "      <th>TI</th>\n",
       "      <th>WDVer</th>\n",
       "      <th>WD_bin</th>\n",
       "      <th>AD1</th>\n",
       "      <th>tod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.499157</td>\n",
       "      <td>0.481840</td>\n",
       "      <td>0.488738</td>\n",
       "      <td>0.327588</td>\n",
       "      <td>0.389806</td>\n",
       "      <td>0.498695</td>\n",
       "      <td>0.500747</td>\n",
       "      <td>0.402230</td>\n",
       "      <td>0.477820</td>\n",
       "      <td>0.904717</td>\n",
       "      <td>0.602341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435078</td>\n",
       "      <td>0.498101</td>\n",
       "      <td>0.314046</td>\n",
       "      <td>0.357175</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.501449</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511992</td>\n",
       "      <td>0.529546</td>\n",
       "      <td>0.519846</td>\n",
       "      <td>0.410926</td>\n",
       "      <td>0.426596</td>\n",
       "      <td>0.509730</td>\n",
       "      <td>0.465955</td>\n",
       "      <td>0.478455</td>\n",
       "      <td>0.553334</td>\n",
       "      <td>0.826857</td>\n",
       "      <td>0.584383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374294</td>\n",
       "      <td>0.551549</td>\n",
       "      <td>0.714964</td>\n",
       "      <td>0.333262</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.431052</td>\n",
       "      <td>0.412587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.607426</td>\n",
       "      <td>0.593543</td>\n",
       "      <td>0.574152</td>\n",
       "      <td>0.479036</td>\n",
       "      <td>0.432011</td>\n",
       "      <td>0.604143</td>\n",
       "      <td>0.617217</td>\n",
       "      <td>0.530876</td>\n",
       "      <td>0.616927</td>\n",
       "      <td>0.835353</td>\n",
       "      <td>0.170710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453452</td>\n",
       "      <td>0.659106</td>\n",
       "      <td>0.546230</td>\n",
       "      <td>0.399321</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.279841</td>\n",
       "      <td>0.664336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242504</td>\n",
       "      <td>0.263195</td>\n",
       "      <td>0.269806</td>\n",
       "      <td>0.501256</td>\n",
       "      <td>0.584896</td>\n",
       "      <td>0.245660</td>\n",
       "      <td>0.276392</td>\n",
       "      <td>0.549438</td>\n",
       "      <td>0.373966</td>\n",
       "      <td>0.796075</td>\n",
       "      <td>0.673673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437901</td>\n",
       "      <td>0.302640</td>\n",
       "      <td>0.332881</td>\n",
       "      <td>0.242406</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.631229</td>\n",
       "      <td>0.020979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456821</td>\n",
       "      <td>0.443936</td>\n",
       "      <td>0.437853</td>\n",
       "      <td>0.698402</td>\n",
       "      <td>0.672309</td>\n",
       "      <td>0.460562</td>\n",
       "      <td>0.400329</td>\n",
       "      <td>0.722298</td>\n",
       "      <td>0.458211</td>\n",
       "      <td>0.816923</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488508</td>\n",
       "      <td>0.428085</td>\n",
       "      <td>0.162466</td>\n",
       "      <td>0.301140</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.511753</td>\n",
       "      <td>0.797203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WS1       WS3       WS4       WD1       WD4     WSHor     WSVer  \\\n",
       "0  0.499157  0.481840  0.488738  0.327588  0.389806  0.498695  0.500747   \n",
       "1  0.511992  0.529546  0.519846  0.410926  0.426596  0.509730  0.465955   \n",
       "2  0.607426  0.593543  0.574152  0.479036  0.432011  0.604143  0.617217   \n",
       "3  0.242504  0.263195  0.269806  0.501256  0.584896  0.245660  0.276392   \n",
       "4  0.456821  0.443936  0.437853  0.698402  0.672309  0.460562  0.400329   \n",
       "\n",
       "      WDHor        T1       RH1       PR1  Rain       WSH     WVeer        TI  \\\n",
       "0  0.402230  0.477820  0.904717  0.602341   0.0  0.435078  0.498101  0.314046   \n",
       "1  0.478455  0.553334  0.826857  0.584383   0.0  0.374294  0.551549  0.714964   \n",
       "2  0.530876  0.616927  0.835353  0.170710   0.0  0.453452  0.659106  0.546230   \n",
       "3  0.549438  0.373966  0.796075  0.673673   0.0  0.437901  0.302640  0.332881   \n",
       "4  0.722298  0.458211  0.816923  0.514354   0.0  0.488508  0.428085  0.162466   \n",
       "\n",
       "      WDVer  WD_bin       AD1       tod  \n",
       "0  0.357175   0.250  0.501449  0.762238  \n",
       "1  0.333262   0.375  0.431052  0.412587  \n",
       "2  0.399321   0.500  0.279841  0.664336  \n",
       "3  0.242406   0.500  0.631229  0.020979  \n",
       "4  0.301140   0.750  0.511753  0.797203  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db055157",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset2-Complex_Site','\\PC_V117.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adb853",
   "metadata": {},
   "source": [
    "### RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ff683ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam', 'RMSProp'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74963bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Early Stopping', 'optimizer': 'Momentum', 'n_neurons': 100, 'n_hidden': 1, 'learning_rate': 0.005, 'input_shape': 19, 'activation': 'relu', 'Leaky': True}\n",
      "Best score :\n",
      "-0.6488828857739767\n",
      "\n",
      "--- 12.630461589495342 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.774 m/s as root mean\n",
      "Wind MAE:  0.575 m/s in avg\n",
      "Wind MAPE:  7.982 %\n",
      "Power RMSE:  266.681 kW as root mean\n",
      "Power MAE:  152.839 kW in avg\n",
      "Power MAPE:  7.492292220539012e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.857 m/s as root mean\n",
      "Wind MAE:  0.614 m/s in avg\n",
      "Wind MAPE:  10.44 %\n",
      "Power RMSE:  296.199 kW as root mean\n",
      "Power MAE:  163.602 kW in avg\n",
      "Power MAPE:  1.8436701770959404e+18 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd3b8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam', 'RMSProp'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9055db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [-0.83447552 -0.72238638 -0.82365972 -0.73007492 -1.27835931 -0.69232341\n",
      " -0.7129965  -0.99825635 -1.04885946 -0.76619754 -0.76756475 -0.96938684\n",
      "         nan -0.82121068 -1.84089164 -0.84712869 -0.83041843 -0.70342112\n",
      " -0.89563972 -0.8879808 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Dropout', 'optimizer': 'Nadam', 'n_neurons': 50, 'n_hidden': 3, 'learning_rate': 0.0003, 'input_shape': 19, 'activation': 'selu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.6923234065373739\n",
      "\n",
      "--- 13.332086555163066 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.813 m/s as root mean\n",
      "Wind MAE:  0.592 m/s in avg\n",
      "Wind MAPE:  8.801 %\n",
      "Power RMSE:  290.522 kW as root mean\n",
      "Power MAE:  162.478 kW in avg\n",
      "Power MAPE:  9.73369940306925e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.893 m/s as root mean\n",
      "Wind MAE:  0.626 m/s in avg\n",
      "Wind MAPE:  11.383 %\n",
      "Power RMSE:  320.003 kW as root mean\n",
      "Power MAE:  174.166 kW in avg\n",
      "Power MAPE:  2.2010277810128532e+18 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b483daf",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4145fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3e2970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.7217 - val_loss: 1.0910\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.9004 - val_loss: 0.9157\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.8313 - val_loss: 0.8591\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7774 - val_loss: 0.8919\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7591 - val_loss: 0.8188\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7486 - val_loss: 0.8027\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7430 - val_loss: 0.7799\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7168 - val_loss: 0.7829\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7055 - val_loss: 0.7872\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7109 - val_loss: 0.7875\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7059 - val_loss: 0.8449\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6917 - val_loss: 0.8543\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7056 - val_loss: 0.7548\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.7051 - val_loss: 0.7679\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6724 - val_loss: 0.7970\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.6800 - val_loss: 0.8029\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6668 - val_loss: 0.9377\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6668 - val_loss: 0.8831\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6654 - val_loss: 0.7101\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.7228\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6344 - val_loss: 0.9153\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6639 - val_loss: 0.8271\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6606 - val_loss: 0.7827\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6419 - val_loss: 0.7642\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6366 - val_loss: 0.7141\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.7066\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.7881\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6176 - val_loss: 0.6780\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.7370\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6327 - val_loss: 0.7485\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5981 - val_loss: 0.8170\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.6933\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5986 - val_loss: 0.7380\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5953 - val_loss: 0.6772\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6735\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6880\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5794 - val_loss: 0.6594\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5839 - val_loss: 0.6684\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5774 - val_loss: 0.6840\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5887 - val_loss: 0.7608\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.6564\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5680 - val_loss: 0.6745\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5639 - val_loss: 0.6846\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5821 - val_loss: 0.7330\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5696 - val_loss: 0.6604\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5621 - val_loss: 0.6924\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5588 - val_loss: 0.6867\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5698 - val_loss: 0.7092\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5514 - val_loss: 0.7262\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5634 - val_loss: 0.7588\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5528 - val_loss: 0.7649\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5571 - val_loss: 0.6521\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5556 - val_loss: 0.6492\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.5547 - val_loss: 0.6456\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5829 - val_loss: 0.6359\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5493 - val_loss: 0.6169\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5599 - val_loss: 0.6466\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.6229\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5363 - val_loss: 0.6742\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5339 - val_loss: 0.6852\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 0.6771\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.5271 - val_loss: 0.6221\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 0.6603\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5424 - val_loss: 0.6330\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 0.6106\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5143 - val_loss: 0.6369\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5218 - val_loss: 0.7001\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 0.6209\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.6548\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5141 - val_loss: 0.6350\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5011 - val_loss: 0.6225\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.6101\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5119 - val_loss: 0.6205\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5183 - val_loss: 0.6399\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 0.6193\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5070 - val_loss: 0.6298\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4925 - val_loss: 0.6460\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4971 - val_loss: 0.6365\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4878 - val_loss: 0.6205\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4989 - val_loss: 0.6091\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 0.6329\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4839 - val_loss: 0.5811\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.6189\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.7256\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.5117 - val_loss: 0.6373\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4802 - val_loss: 0.6020\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4695 - val_loss: 0.5904\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4696 - val_loss: 0.6297\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.6583\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.6393\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.5052 - val_loss: 0.5758\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4650 - val_loss: 0.6282\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.7216\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.6200\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.6070\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.4739 - val_loss: 0.5965\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4404 - val_loss: 0.6236\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.6373\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4458 - val_loss: 0.6295\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.6023\n",
      "\n",
      "RMSE for validation 0.7760756730974255\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.676 m/s as root mean\n",
      "Wind MAE:  0.502 m/s in avg\n",
      "Wind MAPE:  6.793 %\n",
      "Power RMSE:  252.709 kW as root mean\n",
      "Power MAE:  140.465 kW in avg\n",
      "Power MAPE:  3.749904958984089e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.817 m/s as root mean\n",
      "Wind MAE:  0.573 m/s in avg\n",
      "Wind MAPE:  10.251 %\n",
      "Power RMSE:  313.796 kW as root mean\n",
      "Power MAE:  164.661 kW in avg\n",
      "Power MAPE:  1.843078834821214e+18 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2ee2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'selu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54351cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 12.7749 - val_loss: 1.1144\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9636\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.8642 - val_loss: 0.8922\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.8107 - val_loss: 0.8763\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.8087 - val_loss: 0.8730\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7871 - val_loss: 0.8786\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.7867 - val_loss: 0.8350\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7784 - val_loss: 0.8225\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7770 - val_loss: 0.8755\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7652 - val_loss: 0.8797\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7479 - val_loss: 0.9094\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7700 - val_loss: 0.8982\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7230 - val_loss: 0.7943\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7326 - val_loss: 0.8201\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7247 - val_loss: 1.1355\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7533 - val_loss: 0.7631\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7136 - val_loss: 0.7576\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7292 - val_loss: 0.7526\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.7176 - val_loss: 0.7505\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.7407 - val_loss: 0.7716\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6992 - val_loss: 0.7932\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6914 - val_loss: 0.7587\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6938 - val_loss: 0.7677\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6924 - val_loss: 0.7714\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6733 - val_loss: 0.8194\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6908 - val_loss: 0.7345\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6769 - val_loss: 0.7302\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.8294\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.6646 - val_loss: 0.8869\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.6694 - val_loss: 0.7304\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6686 - val_loss: 0.7622\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6523 - val_loss: 0.8514\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6681 - val_loss: 0.8468\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6774 - val_loss: 0.6923\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6545 - val_loss: 0.7528\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6491 - val_loss: 0.6848\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6663 - val_loss: 0.9329\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6540 - val_loss: 0.7071\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6470 - val_loss: 0.6949\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6600 - val_loss: 0.7214\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.6377 - val_loss: 0.6958\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.7198\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.6274 - val_loss: 0.8374\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6495 - val_loss: 0.6761\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.6776\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.6913\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6185 - val_loss: 0.8439\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.7226\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6302 - val_loss: 0.6883\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6330 - val_loss: 0.7007\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6359 - val_loss: 0.6717\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.7418\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.6206 - val_loss: 0.7419\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.7385\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.7214\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.7021\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5978 - val_loss: 0.6884\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.5885 - val_loss: 0.7117\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 0.6028 - val_loss: 0.7994\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6541\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5816 - val_loss: 0.6446\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6602\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 0.6696\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 0.6644\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5845 - val_loss: 0.7109\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5887 - val_loss: 0.7610\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5834 - val_loss: 0.7535\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5925 - val_loss: 0.8090\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.5796 - val_loss: 0.7039\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6471\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 0.6991\n",
      "\n",
      "RMSE for validation 0.8028942213482174\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.757 m/s as root mean\n",
      "Wind MAE:  0.554 m/s in avg\n",
      "Wind MAPE:  8.144 %\n",
      "Power RMSE:  267.012 kW as root mean\n",
      "Power MAE:  149.837 kW in avg\n",
      "Power MAPE:  8.946394901177798e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.848 m/s as root mean\n",
      "Wind MAE:  0.592 m/s in avg\n",
      "Wind MAPE:  10.73 %\n",
      "Power RMSE:  303.863 kW as root mean\n",
      "Power MAE:  163.088 kW in avg\n",
      "Power MAPE:  2.1017656052383532e+18 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb2d2b",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8524f1c",
   "metadata": {},
   "source": [
    "{'regularization': 'Early Stopping', 'optimizer': 'Momentum', 'n_neurons': 100, 'n_hidden': 1, 'learning_rate': 0.005, 'input_shape': 19, 'activation': 'relu', 'Leaky': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c207f",
   "metadata": {},
   "source": [
    "MAPE wind: 10.44 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1f39b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('T11_ANN1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f749c",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b0ff8",
   "metadata": {},
   "source": [
    "MAPE wind: 9.976 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab98c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('T11_ANN2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a401dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1a6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87134b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2a46ffb",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ffdeaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('T11_ANN2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd3e3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.715 m/s as root mean\n",
      "Wind MAE:  0.53 m/s in avg\n",
      "Wind MAPE:  7.056 %\n",
      "Power RMSE:  253.19 kW as root mean\n",
      "Power MAE:  141.847 kW in avg\n",
      "Power MAPE:  3.682586310545441e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.833 m/s as root mean\n",
      "Wind MAE:  0.596 m/s in avg\n",
      "Wind MAPE:  9.976 %\n",
      "Power RMSE:  307.208 kW as root mean\n",
      "Power MAE:  165.112 kW in avg\n",
      "Power MAPE:  1.5128036862987113e+18 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "WS_pred=model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91181028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ANN_T11.csv saved in \\Results_ folder\n"
     ]
    }
   ],
   "source": [
    "WS_pred=pd.DataFrame(WS_pred)\n",
    "save(WS_pred,'\\Results_','ANN_T11.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99bf60",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18076b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 130 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4ce2556ddc4d65957cdcbbbcd478a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x655.2 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance through SHAP values performed\n"
     ]
    }
   ],
   "source": [
    "shap_values=feature_importance (X_train, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4e3fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=transform_shap (shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ee9108f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WD1', 'WD4', 'WSHor', 'WSVer', 'WDHor', 'T1',\n",
       "       'RH1', 'PR1', 'Rain', 'WSH', 'WVeer', 'TI', 'WDVer', 'WD_bin', 'AD1',\n",
       "       'tod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d622497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>SHAP_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WS1</td>\n",
       "      <td>0.931588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WS3</td>\n",
       "      <td>0.047656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WS4</td>\n",
       "      <td>0.454398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WD1</td>\n",
       "      <td>0.083622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WD4</td>\n",
       "      <td>0.039101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WSHor</td>\n",
       "      <td>0.756692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WSVer</td>\n",
       "      <td>0.144684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WDHor</td>\n",
       "      <td>0.048118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.036579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RH1</td>\n",
       "      <td>0.102348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PR1</td>\n",
       "      <td>0.019791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WSH</td>\n",
       "      <td>0.032769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WVeer</td>\n",
       "      <td>0.157262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TI</td>\n",
       "      <td>0.193580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WDVer</td>\n",
       "      <td>0.010066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WD_bin</td>\n",
       "      <td>0.073521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AD1</td>\n",
       "      <td>0.022052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tod</td>\n",
       "      <td>0.101027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables  SHAP_abs\n",
       "0        WS1  0.931588\n",
       "1        WS3  0.047656\n",
       "2        WS4  0.454398\n",
       "3        WD1  0.083622\n",
       "4        WD4  0.039101\n",
       "5      WSHor  0.756692\n",
       "6      WSVer  0.144684\n",
       "7      WDHor  0.048118\n",
       "8         T1  0.036579\n",
       "9        RH1  0.102348\n",
       "10       PR1  0.019791\n",
       "11      Rain  0.000000\n",
       "12       WSH  0.032769\n",
       "13     WVeer  0.157262\n",
       "14        TI  0.193580\n",
       "15     WDVer  0.010066\n",
       "16    WD_bin  0.073521\n",
       "17       AD1  0.022052\n",
       "18       tod  0.101027"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844a2df",
   "metadata": {},
   "source": [
    "## Dataset2- T17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "143791ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WD1', 'WD4', 'WSHor', 'WSVer', 'WDHor', 'PR1',\n",
       "       'Rain', 'WSH', 'WVeer', 'TI', 'WDVer', 'WD_bin', 'tod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "X_train= uploading_csv('\\Dataset2-Complex_Site','\\X_train17.csv')\n",
    "X_test= uploading_csv('\\Dataset2-Complex_Site','\\X_test17.csv')\n",
    "y_train= uploading_csv('\\Dataset2-Complex_Site','\\y_train17.csv')\n",
    "y_test= uploading_csv('\\Dataset2-Complex_Site','\\y_test17.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e5ee809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c5bf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset2-Complex_Site','\\PC_V112.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca7797",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acf8d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4b969a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [ -1.07578381  -0.39619265 -16.41513602  -0.49583897  -0.47011769\n",
      "  -0.53511881  -0.6136086  -16.43231742  -1.04724256          nan\n",
      "  -0.40382962 -86.82775116          nan  -0.5123837   -0.46735646\n",
      "  -0.44322575  -0.3673082   -0.4475245   -7.31817595  -0.48747708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Dropout', 'optimizer': 'Nesterov', 'n_neurons': 100, 'n_hidden': 2, 'learning_rate': 0.003, 'input_shape': 16, 'activation': 'relu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.36730819940567017\n",
      "\n",
      "--- 9.923941997687022 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.566 m/s as root mean\n",
      "Wind MAE:  0.435 m/s in avg\n",
      "Wind MAPE:  4.637 %\n",
      "Power RMSE:  234.791 kW as root mean\n",
      "Power MAE:  149.818 kW in avg\n",
      "Power MAPE:  10.28 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.581 m/s as root mean\n",
      "Wind MAE:  0.453 m/s in avg\n",
      "Wind MAPE:  4.874 %\n",
      "Power RMSE:  232.359 kW as root mean\n",
      "Power MAE:  153.256 kW in avg\n",
      "Power MAPE:  10.934 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0313038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea99f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [-0.55291259 -2.70085859 -0.51208058 -0.50634738 -0.45095621 -0.47614641\n",
      " -0.40602157 -0.39175396 -0.45050852 -0.65759597 -0.45821362 -0.58228477\n",
      " -0.41942017 -0.51744967 -0.4513313  -0.43145026 -0.58018708 -2.89246694\n",
      "         nan -1.21432499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Early Stopping', 'optimizer': 'Nesterov', 'n_neurons': 90, 'n_hidden': 3, 'learning_rate': 0.001, 'input_shape': 16, 'activation': 'elu', 'Leaky': True}\n",
      "Best score :\n",
      "-0.3917539616425832\n",
      "\n",
      "--- 9.595975708961486 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.575 m/s as root mean\n",
      "Wind MAE:  0.445 m/s in avg\n",
      "Wind MAPE:  4.869 %\n",
      "Power RMSE:  246.565 kW as root mean\n",
      "Power MAE:  156.993 kW in avg\n",
      "Power MAPE:  11.484 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.601 m/s as root mean\n",
      "Wind MAE:  0.475 m/s in avg\n",
      "Wind MAPE:  5.254 %\n",
      "Power RMSE:  245.834 kW as root mean\n",
      "Power MAE:  162.641 kW in avg\n",
      "Power MAPE:  12.508 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9a321",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8676b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e58a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 8.3426 - val_loss: 0.6730\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.5343\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5300 - val_loss: 0.4999\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4988 - val_loss: 0.5281\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.4818\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.4518\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.4453\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.5059\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 0.4625\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4321 - val_loss: 0.4342\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.4422\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4226\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4298 - val_loss: 0.4161\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4255 - val_loss: 0.4161\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4161 - val_loss: 0.5367\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.4220\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.4089\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4141\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4449\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.4804\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3905 - val_loss: 0.4175\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.4062\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.4243\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.4326\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4506\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.4549\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 0.4048\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.3934\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.3927\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3745 - val_loss: 0.3747\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3782 - val_loss: 0.3858\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3706 - val_loss: 0.3916\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.3810\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3744\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.4239\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.4004\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3622 - val_loss: 0.4277\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3762\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3573 - val_loss: 0.3941\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.4097\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3658 - val_loss: 0.3554\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3603 - val_loss: 0.3776\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3549 - val_loss: 0.3645\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3618 - val_loss: 0.3576\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.3790\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3496 - val_loss: 0.4122\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.3458 - val_loss: 0.4148\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3517 - val_loss: 0.3641\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3437 - val_loss: 0.4066\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3317 - val_loss: 0.3640\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3312 - val_loss: 0.3516\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3532\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.3555\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3208 - val_loss: 0.3592\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3260 - val_loss: 0.3621\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3844\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3309 - val_loss: 0.3767\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3258 - val_loss: 0.5128\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3297 - val_loss: 0.3676\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3360 - val_loss: 0.4841\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.3648\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3125 - val_loss: 0.3603\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.3750\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3344 - val_loss: 0.4301\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3173 - val_loss: 0.3483\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3095 - val_loss: 0.3545\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3713\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3256 - val_loss: 0.3423\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3844\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3312 - val_loss: 0.3735\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.3501\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3456\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.5155\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.3511\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2975 - val_loss: 0.3671\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3247 - val_loss: 0.3600\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3037 - val_loss: 0.3651\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3126 - val_loss: 0.3598\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3158 - val_loss: 0.3766\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3099 - val_loss: 0.4346\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.3514\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3391\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3033 - val_loss: 0.3569\n",
      "Epoch 84/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3135 - val_loss: 0.3591\n",
      "Epoch 85/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3028 - val_loss: 0.3755\n",
      "Epoch 86/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 0.3494\n",
      "Epoch 87/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2912 - val_loss: 0.3406\n",
      "Epoch 88/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3063 - val_loss: 0.3484\n",
      "Epoch 89/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3674\n",
      "Epoch 90/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.3433\n",
      "Epoch 91/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2970 - val_loss: 0.3683\n",
      "Epoch 92/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.2909 - val_loss: 0.3477\n",
      "Epoch 93/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2973 - val_loss: 0.3683\n",
      "Epoch 94/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2985 - val_loss: 0.4020\n",
      "Epoch 95/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3075 - val_loss: 0.3882\n",
      "Epoch 96/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3395\n",
      "Epoch 97/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2876 - val_loss: 0.3850\n",
      "Epoch 98/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2982 - val_loss: 0.3621\n",
      "Epoch 99/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2865 - val_loss: 0.3408\n",
      "Epoch 100/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.2938 - val_loss: 0.3612\n",
      "\n",
      "RMSE for validation 0.6010065957995299\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.54 m/s as root mean\n",
      "Wind MAE:  0.414 m/s in avg\n",
      "Wind MAPE:  4.398 %\n",
      "Power RMSE:  228.391 kW as root mean\n",
      "Power MAE:  145.415 kW in avg\n",
      "Power MAPE:  9.502 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.576 m/s as root mean\n",
      "Wind MAE:  0.452 m/s in avg\n",
      "Wind MAPE:  4.831 %\n",
      "Power RMSE:  235.775 kW as root mean\n",
      "Power MAE:  155.627 kW in avg\n",
      "Power MAPE:  10.482 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "262e2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':2,\n",
    "    'n_neurons': 100,\n",
    "    'learning_rate':0.003,\n",
    "    'activation':'relu',\n",
    "    'optimizer':'Nesterov',\n",
    "    'regularization':'Dropout',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8ec7820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/110 [===========================>..] - ETA: 0s - loss: 2.9354WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0080s). Check your callbacks.\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 2.8698 - val_loss: 0.6813\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.1900 - val_loss: 0.4880\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.0417 - val_loss: 0.5568\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.9791 - val_loss: 0.4851\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.8464 - val_loss: 0.5179\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.8174 - val_loss: 1.0815\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.8166 - val_loss: 0.4626\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.7592 - val_loss: 1.1616\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.7577 - val_loss: 0.4785\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 0.6805 - val_loss: 1.1704\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.7067 - val_loss: 0.4849\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.6782 - val_loss: 0.7589\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.6679 - val_loss: 0.5927\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.6669 - val_loss: 0.4477\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.6311 - val_loss: 0.5197\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.6247 - val_loss: 0.4693\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.6044 - val_loss: 0.6528\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.6141 - val_loss: 0.4366\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5905 - val_loss: 0.4345\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5826 - val_loss: 0.9139\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 0.4830\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5801 - val_loss: 0.4181\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5348 - val_loss: 0.6290\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5663 - val_loss: 0.4739\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5451 - val_loss: 0.4490\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5223 - val_loss: 0.5293\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5242 - val_loss: 0.4211\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5501 - val_loss: 0.4770\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 0.4170\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5286 - val_loss: 0.4446\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5181 - val_loss: 0.4116\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5186 - val_loss: 0.4643\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.5098 - val_loss: 0.4150\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.4139\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4890 - val_loss: 0.4813\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4847 - val_loss: 0.4067\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4870 - val_loss: 0.3992\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4957 - val_loss: 0.4056\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.4721 - val_loss: 0.4034\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4783 - val_loss: 0.4462\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.4629 - val_loss: 0.4387\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.4681 - val_loss: 0.3939\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4637 - val_loss: 0.4459\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.4720 - val_loss: 0.4064\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4525 - val_loss: 0.4474\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4604 - val_loss: 0.4002\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4701 - val_loss: 0.4058\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.4671\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.4044\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.5293\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4096\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.4107\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4557 - val_loss: 0.3837\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 0.3931\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4508 - val_loss: 0.4609\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4317 - val_loss: 0.3909\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4332 - val_loss: 0.3741\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4346 - val_loss: 0.4008\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.3759\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 0.3903\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.3785\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 0.3871\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 0.3702\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4368 - val_loss: 0.3769\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 0.3654\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.3877\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.3761\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.3902\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.4467\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.414 - 0s 2ms/step - loss: 0.4096 - val_loss: 0.3644\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 0.3844\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4252\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4236 - val_loss: 0.4484\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4323 - val_loss: 0.3761\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4318 - val_loss: 0.3997\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 0.3855\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4105 - val_loss: 0.3892\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 0.3645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4182 - val_loss: 0.3989\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4277 - val_loss: 0.3652\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4107 - val_loss: 0.5197\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.3761\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4116 - val_loss: 0.4015\n",
      "Epoch 84/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4198 - val_loss: 0.5140\n",
      "Epoch 85/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 0.3742\n",
      "Epoch 86/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4064 - val_loss: 0.4334\n",
      "Epoch 87/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4106 - val_loss: 0.5014\n",
      "Epoch 88/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4019 - val_loss: 0.3694\n",
      "Epoch 89/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4080 - val_loss: 0.5517\n",
      "Epoch 90/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4164 - val_loss: 0.4200\n",
      "Epoch 91/100\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.4161 - val_loss: 0.3590\n",
      "Epoch 92/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.3778\n",
      "Epoch 93/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.4279\n",
      "Epoch 94/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3953 - val_loss: 0.4551\n",
      "Epoch 95/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4096 - val_loss: 0.3896\n",
      "Epoch 96/100\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.4036 - val_loss: 0.4276\n",
      "Epoch 97/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4008 - val_loss: 0.3853\n",
      "Epoch 98/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.3986 - val_loss: 0.4136\n",
      "Epoch 99/100\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 0.4024 - val_loss: 0.3861\n",
      "Epoch 100/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.5045\n",
      "\n",
      "RMSE for validation 0.710247941767448\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.687 m/s as root mean\n",
      "Wind MAE:  0.537 m/s in avg\n",
      "Wind MAPE:  5.894 %\n",
      "Power RMSE:  289.505 kW as root mean\n",
      "Power MAE:  185.872 kW in avg\n",
      "Power MAPE:  13.769 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.713 m/s as root mean\n",
      "Wind MAE:  0.564 m/s in avg\n",
      "Wind MAPE:  6.199 %\n",
      "Power RMSE:  280.548 kW as root mean\n",
      "Power MAE:  185.465 kW in avg\n",
      "Power MAPE:  14.398 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69222030",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 90,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Nesterov',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e41c67ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 3.2105 - val_loss: 0.8977\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.5568\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 0.5967\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.4763\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5063 - val_loss: 0.5109\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.7783\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.4559\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.4490\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.4772\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.5577\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4534 - val_loss: 0.5534\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.5814\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.4625\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4294\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4298 - val_loss: 0.4236\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.6588\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.5282\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.4327\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4144 - val_loss: 0.4593\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4225 - val_loss: 0.7025\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.5064\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4336\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 0.4425\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.4245\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4128\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.9272\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4082\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 0.4053\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4265\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.6002\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.4113\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.7318\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.5275\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.4026\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.5619\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.5782\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.4075\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.5885\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.4851\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.4218\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4810\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3868\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3717 - val_loss: 0.3947\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3727 - val_loss: 0.5772\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.3732 - val_loss: 0.3913\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.4302\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3834\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.3809\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.4522\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4611\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.4453\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.3831\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 0.3831\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3595 - val_loss: 0.3910\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.4247\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3603 - val_loss: 0.3943\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3612 - val_loss: 0.3782\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.4213\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 0.3795\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3609 - val_loss: 0.4655\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3608 - val_loss: 0.3699\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.4120\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3584 - val_loss: 0.3865\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 1.0068\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3614 - val_loss: 0.4554\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3590 - val_loss: 0.6327\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.3993\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3567 - val_loss: 0.5957\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 0.3733\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.6283\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3559 - val_loss: 0.3799\n",
      "\n",
      "RMSE for validation 0.6081821248122216\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.586 m/s as root mean\n",
      "Wind MAE:  0.449 m/s in avg\n",
      "Wind MAPE:  4.817 %\n",
      "Power RMSE:  245.149 kW as root mean\n",
      "Power MAE:  155.316 kW in avg\n",
      "Power MAPE:  10.756 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.599 m/s as root mean\n",
      "Wind MAE:  0.466 m/s in avg\n",
      "Wind MAPE:  5.019 %\n",
      "Power RMSE:  238.214 kW as root mean\n",
      "Power MAE:  155.743 kW in avg\n",
      "Power MAPE:  11.203 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d8e418",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e68dd",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c679f5f",
   "metadata": {},
   "source": [
    "MAPE power: 10.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce6c5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('T17_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5132e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('T17_ANN2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e998f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ad48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc041588",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "369fd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('T17_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a049d80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.54 m/s as root mean\n",
      "Wind MAE:  0.414 m/s in avg\n",
      "Wind MAPE:  4.398 %\n",
      "Power RMSE:  228.391 kW as root mean\n",
      "Power MAE:  145.415 kW in avg\n",
      "Power MAPE:  9.502 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.576 m/s as root mean\n",
      "Wind MAE:  0.452 m/s in avg\n",
      "Wind MAPE:  4.831 %\n",
      "Power RMSE:  235.775 kW as root mean\n",
      "Power MAE:  155.627 kW in avg\n",
      "Power MAPE:  10.482 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86b646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "577106b1",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ccaadba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e08181751d04aa5bf5e86fa03501eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x568.8 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance through SHAP values performed\n"
     ]
    }
   ],
   "source": [
    "shap_values=feature_importance (X_train, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a2bc171",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=transform_shap (shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11181317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>SHAP_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WS1</td>\n",
       "      <td>0.965660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WS3</td>\n",
       "      <td>1.422564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WS4</td>\n",
       "      <td>1.460906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WD1</td>\n",
       "      <td>0.362853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WD4</td>\n",
       "      <td>0.315924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WSHor</td>\n",
       "      <td>1.187850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WSVer</td>\n",
       "      <td>0.018416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WDHor</td>\n",
       "      <td>0.055578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PR1</td>\n",
       "      <td>0.021968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rain</td>\n",
       "      <td>0.003067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WSH</td>\n",
       "      <td>0.070877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WVeer</td>\n",
       "      <td>0.018036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TI</td>\n",
       "      <td>0.015409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WDVer</td>\n",
       "      <td>0.017086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WD_bin</td>\n",
       "      <td>0.015236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tod</td>\n",
       "      <td>0.244667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables  SHAP_abs\n",
       "0        WS1  0.965660\n",
       "1        WS3  1.422564\n",
       "2        WS4  1.460906\n",
       "3        WD1  0.362853\n",
       "4        WD4  0.315924\n",
       "5      WSHor  1.187850\n",
       "6      WSVer  0.018416\n",
       "7      WDHor  0.055578\n",
       "8        PR1  0.021968\n",
       "9       Rain  0.003067\n",
       "10       WSH  0.070877\n",
       "11     WVeer  0.018036\n",
       "12        TI  0.015409\n",
       "13     WDVer  0.017086\n",
       "14    WD_bin  0.015236\n",
       "15       tod  0.244667"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754bb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5277a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "886f8e66",
   "metadata": {},
   "source": [
    "## Dataset2- T22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a242daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WD1', 'WD4', 'WSHor', 'WSVer', 'WDHor', 'RH1',\n",
       "       'PR1', 'Rain', 'WSH', 'WVeer', 'TI', 'WDVer', 'WD_bin', 'tod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "X_train= uploading_csv('\\Dataset2-Complex_Site','\\X_train22.csv')\n",
    "X_test= uploading_csv('\\Dataset2-Complex_Site','\\X_test22.csv')\n",
    "y_train= uploading_csv('\\Dataset2-Complex_Site','\\y_train22.csv')\n",
    "y_test= uploading_csv('\\Dataset2-Complex_Site','\\y_test22.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43f87368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0d70110",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset2-Complex_Site','\\PC_V117.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab9e02",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8eba2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1cfb14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Dropout', 'optimizer': 'Nesterov', 'n_neurons': 80, 'n_hidden': 3, 'learning_rate': 0.001, 'input_shape': 17, 'activation': 'relu', 'Leaky': True}\n",
      "Best score :\n",
      "-0.6610205769538879\n",
      "\n",
      "--- 9.078933183352152 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.707 m/s as root mean\n",
      "Wind MAE:  0.538 m/s in avg\n",
      "Wind MAPE:  7.318 %\n",
      "Power RMSE:  317.923 kW as root mean\n",
      "Power MAE:  213.835 kW in avg\n",
      "Power MAPE:  7.421315656754958e+16 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.741 m/s as root mean\n",
      "Wind MAE:  0.559 m/s in avg\n",
      "Wind MAPE:  7.467 %\n",
      "Power RMSE:  348.899 kW as root mean\n",
      "Power MAE:  227.326 kW in avg\n",
      "Power MAPE:  24.052 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc2b3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55a0c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [-1.37643977 -1.69325157 -1.64425476 -1.00734305 -0.82106346 -0.83543595\n",
      " -0.89177605 -1.17182251 -0.69177105 -0.77259185 -1.05052233 -0.96071255\n",
      " -0.71196856 -0.72100133         nan -0.78692005 -0.82343479 -0.99675479\n",
      " -0.96730433 -1.00919571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Dropout', 'optimizer': 'Nesterov', 'n_neurons': 30, 'n_hidden': 2, 'learning_rate': 0.003, 'input_shape': 17, 'activation': 'relu', 'Leaky': True}\n",
      "Best score :\n",
      "-0.6917710502942404\n",
      "\n",
      "--- 8.941617663701376 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.844 m/s as root mean\n",
      "Wind MAE:  0.646 m/s in avg\n",
      "Wind MAPE:  8.645 %\n",
      "Power RMSE:  379.044 kW as root mean\n",
      "Power MAE:  251.963 kW in avg\n",
      "Power MAPE:  7.349464790500515e+16 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.821 m/s as root mean\n",
      "Wind MAE:  0.621 m/s in avg\n",
      "Wind MAPE:  8.116 %\n",
      "Power RMSE:  378.153 kW as root mean\n",
      "Power MAE:  242.28 kW in avg\n",
      "Power MAPE:  24.985 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6c74b",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ccb4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6564fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 5.0496 - val_loss: 1.4375\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.2842 - val_loss: 1.2392\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0901 - val_loss: 1.0316\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0301 - val_loss: 0.9676\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9400 - val_loss: 0.9169\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8907 - val_loss: 0.7976\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8351 - val_loss: 0.7823\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8359 - val_loss: 0.7433\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.8118 - val_loss: 0.9222\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8290 - val_loss: 0.9413\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7607 - val_loss: 0.7071\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7582 - val_loss: 0.6815\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7339 - val_loss: 0.6971\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7246 - val_loss: 0.6680\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7260 - val_loss: 0.6438\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7002 - val_loss: 0.6381\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6746 - val_loss: 0.8455\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6574 - val_loss: 0.6813\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6860 - val_loss: 0.6581\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6396 - val_loss: 0.6470\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6773 - val_loss: 0.6194\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6689 - val_loss: 0.6187\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6411 - val_loss: 0.5949\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.7075\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6236 - val_loss: 0.6011\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6271 - val_loss: 0.7330\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6448 - val_loss: 0.6269\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6348 - val_loss: 0.6717\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.5845\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5978 - val_loss: 0.5989\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6183\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6228 - val_loss: 0.6378\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5820 - val_loss: 0.6927\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5897 - val_loss: 0.5872\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.5763\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5939 - val_loss: 0.5720\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.5792\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5904 - val_loss: 0.6830\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5789 - val_loss: 0.5617\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5802 - val_loss: 0.6895\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5625 - val_loss: 0.6295\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6228 - val_loss: 0.6057\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.5612\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5749 - val_loss: 0.5935\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.5725\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 0.5544\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5784 - val_loss: 0.5926\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 0.5583\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5599 - val_loss: 0.6556\n",
      "Epoch 50/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 0.6921\n",
      "Epoch 51/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.5455 - val_loss: 0.6628\n",
      "Epoch 52/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 0.5890\n",
      "Epoch 53/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 0.5477\n",
      "Epoch 54/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5302 - val_loss: 0.5614\n",
      "Epoch 55/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 0.6947\n",
      "Epoch 56/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.5193 - val_loss: 0.6308\n",
      "Epoch 57/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 0.6301\n",
      "Epoch 58/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.5255 - val_loss: 0.5281\n",
      "Epoch 59/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.5141 - val_loss: 0.5528\n",
      "Epoch 60/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.5032 - val_loss: 0.5660\n",
      "Epoch 61/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.7072\n",
      "Epoch 62/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5407 - val_loss: 0.5608\n",
      "Epoch 63/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.4988 - val_loss: 0.5527\n",
      "Epoch 64/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.5632\n",
      "Epoch 65/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.4905 - val_loss: 0.5839\n",
      "Epoch 66/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.6479\n",
      "Epoch 67/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.5567\n",
      "Epoch 68/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.5151 - val_loss: 0.5768\n",
      "Epoch 69/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.4922 - val_loss: 0.5372\n",
      "Epoch 70/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.5820\n",
      "Epoch 71/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.5820\n",
      "Epoch 72/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5305\n",
      "Epoch 73/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5670\n",
      "Epoch 74/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.5389\n",
      "Epoch 75/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.5539\n",
      "Epoch 76/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4962 - val_loss: 0.5562\n",
      "Epoch 77/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.5265\n",
      "Epoch 78/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.4816 - val_loss: 0.5690\n",
      "Epoch 79/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5449\n",
      "Epoch 80/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.5398\n",
      "Epoch 81/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.5560\n",
      "Epoch 82/100\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.461 - 0s 2ms/step - loss: 0.4616 - val_loss: 0.5180\n",
      "Epoch 83/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.5233\n",
      "Epoch 84/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.5534\n",
      "Epoch 85/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.6702\n",
      "Epoch 86/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.5359\n",
      "Epoch 87/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.5367\n",
      "Epoch 88/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.5395\n",
      "Epoch 89/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.5214\n",
      "Epoch 90/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.4430 - val_loss: 0.5189\n",
      "Epoch 91/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.5102\n",
      "Epoch 92/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.4383 - val_loss: 0.5541\n",
      "Epoch 93/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.5632\n",
      "Epoch 94/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4373 - val_loss: 0.5709\n",
      "Epoch 95/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4286 - val_loss: 0.5656\n",
      "Epoch 96/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 0.5340\n",
      "Epoch 97/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4255 - val_loss: 0.5500\n",
      "Epoch 98/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.5670\n",
      "Epoch 99/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.5228\n",
      "Epoch 100/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.5269\n",
      "\n",
      "RMSE for validation 0.7258864225548489\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.649 m/s as root mean\n",
      "Wind MAE:  0.5 m/s in avg\n",
      "Wind MAPE:  6.59 %\n",
      "Power RMSE:  293.859 kW as root mean\n",
      "Power MAE:  200.143 kW in avg\n",
      "Power MAPE:  3.1538777425647944e+16 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.729 m/s as root mean\n",
      "Wind MAE:  0.549 m/s in avg\n",
      "Wind MAPE:  7.122 %\n",
      "Power RMSE:  344.713 kW as root mean\n",
      "Power MAE:  224.818 kW in avg\n",
      "Power MAPE:  21.002 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b7b0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c3cce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 6.6392 - val_loss: 1.4481\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.3232 - val_loss: 1.2216\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 1.1765 - val_loss: 1.0295\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0345 - val_loss: 0.9601\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9520 - val_loss: 0.8452\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8963 - val_loss: 0.7952\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.8539 - val_loss: 0.7890\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.8091 - val_loss: 1.0624\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.7757 - val_loss: 0.7210\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.7285 - val_loss: 0.7597\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.7551 - val_loss: 1.4953\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7546 - val_loss: 0.6663\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.7082 - val_loss: 0.6723\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6967 - val_loss: 0.6438\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6929 - val_loss: 0.6961\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.7139 - val_loss: 0.6517\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6733 - val_loss: 0.6523\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.7130 - val_loss: 0.6395\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.6592 - val_loss: 0.6585\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.6569 - val_loss: 0.6601\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.6469 - val_loss: 0.8074\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6521 - val_loss: 0.6637\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.6604 - val_loss: 0.6727\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6636 - val_loss: 0.6670\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6299 - val_loss: 0.6390\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6223 - val_loss: 0.6736\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6486 - val_loss: 0.6157\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.6495\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.647 - 0s 3ms/step - loss: 0.6438 - val_loss: 0.5897\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6327 - val_loss: 0.6254\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 0.6124\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6171 - val_loss: 0.6464\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5801 - val_loss: 0.5845\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.6665\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.7038\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6259 - val_loss: 0.6457\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6151\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5888 - val_loss: 0.6265\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 0.6307\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5743 - val_loss: 0.5767\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5916 - val_loss: 0.6697\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5977 - val_loss: 0.6514\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5646 - val_loss: 0.5691\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5737 - val_loss: 0.5608\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 0.7480\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5556 - val_loss: 0.5724\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5562 - val_loss: 0.5910\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5514 - val_loss: 0.5857\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5503 - val_loss: 0.5429\n",
      "Epoch 50/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5392 - val_loss: 0.5650\n",
      "Epoch 51/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.5411 - val_loss: 0.6339\n",
      "Epoch 52/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 0.6176\n",
      "Epoch 53/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5364 - val_loss: 0.6338\n",
      "Epoch 54/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.5581\n",
      "Epoch 55/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5546 - val_loss: 0.5766\n",
      "Epoch 56/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 0.6019\n",
      "Epoch 57/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5523 - val_loss: 0.5464\n",
      "Epoch 58/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5340 - val_loss: 0.6398\n",
      "Epoch 59/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5834 - val_loss: 0.6659\n",
      "\n",
      "RMSE for validation 0.7368291772180451\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.717 m/s as root mean\n",
      "Wind MAE:  0.547 m/s in avg\n",
      "Wind MAPE:  7.299 %\n",
      "Power RMSE:  322.437 kW as root mean\n",
      "Power MAE:  218.549 kW in avg\n",
      "Power MAPE:  6.29639591172661e+16 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.756 m/s as root mean\n",
      "Wind MAE:  0.573 m/s in avg\n",
      "Wind MAPE:  7.538 %\n",
      "Power RMSE:  352.059 kW as root mean\n",
      "Power MAE:  232.573 kW in avg\n",
      "Power MAPE:  23.296 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85cbe214",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':2,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'relu',\n",
    "    'optimizer':'Nesterov',\n",
    "    'regularization':'Dropout',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77a02646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 4.7634 - val_loss: 1.3797\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.0376 - val_loss: 1.0884\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.7800 - val_loss: 1.0608\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 1.7802 - val_loss: 0.9697\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.6685 - val_loss: 0.9390\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 1.5860 - val_loss: 0.9274\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 1.5561 - val_loss: 0.9059\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4866 - val_loss: 0.8839\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4041 - val_loss: 0.8614\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3642 - val_loss: 0.8620\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.3383 - val_loss: 0.8169\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3529 - val_loss: 0.7998\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3207 - val_loss: 0.9116\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2200 - val_loss: 0.7803\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2314 - val_loss: 0.7809\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2205 - val_loss: 0.7663\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1752 - val_loss: 0.7935\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1358 - val_loss: 0.7886\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1320 - val_loss: 0.7571\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1385 - val_loss: 0.7218\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1224 - val_loss: 0.7662\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 1.1405 - val_loss: 0.7357\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0943 - val_loss: 0.7158\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0593 - val_loss: 0.8236\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0710 - val_loss: 0.7063\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0814 - val_loss: 0.7393\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0546 - val_loss: 1.0542\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0236 - val_loss: 0.6965\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0170 - val_loss: 0.6877\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9716 - val_loss: 0.8603\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9917 - val_loss: 0.7171\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.9552 - val_loss: 0.8093\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.6705\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 0.6636\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9335 - val_loss: 0.6968\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9633 - val_loss: 0.6600\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9171 - val_loss: 0.6504\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 0.6998\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9110 - val_loss: 0.6510\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.6813\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.8890 - val_loss: 0.6879\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.8756 - val_loss: 0.6496\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.8803 - val_loss: 0.6564\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.8959 - val_loss: 0.6370\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.8692 - val_loss: 0.6489\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8138 - val_loss: 0.6328\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8471 - val_loss: 0.6894\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.8581 - val_loss: 0.6843\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8299 - val_loss: 0.6157\n",
      "Epoch 50/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8258 - val_loss: 0.6181\n",
      "Epoch 51/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.8374 - val_loss: 0.6595\n",
      "Epoch 52/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8329 - val_loss: 0.6153\n",
      "Epoch 53/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8181 - val_loss: 0.6492\n",
      "Epoch 54/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.8020 - val_loss: 0.6621\n",
      "Epoch 55/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8192 - val_loss: 0.6150\n",
      "Epoch 56/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7972 - val_loss: 0.6308\n",
      "Epoch 57/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8163 - val_loss: 0.6046\n",
      "Epoch 58/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7726 - val_loss: 0.6650\n",
      "Epoch 59/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8047 - val_loss: 0.6083\n",
      "Epoch 60/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7938 - val_loss: 0.6287\n",
      "Epoch 61/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7858 - val_loss: 0.6017\n",
      "Epoch 62/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8077 - val_loss: 0.6074\n",
      "Epoch 63/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.8161 - val_loss: 0.6306\n",
      "Epoch 64/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7861 - val_loss: 0.7791\n",
      "Epoch 65/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7973 - val_loss: 0.6438\n",
      "Epoch 66/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7945 - val_loss: 0.6002\n",
      "Epoch 67/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7841 - val_loss: 0.6270\n",
      "Epoch 68/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7795 - val_loss: 0.6160\n",
      "Epoch 69/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7285 - val_loss: 0.6456\n",
      "Epoch 70/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7787 - val_loss: 0.6532\n",
      "Epoch 71/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7520 - val_loss: 0.6020\n",
      "Epoch 72/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7598 - val_loss: 0.5974\n",
      "Epoch 73/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7628 - val_loss: 0.5906\n",
      "Epoch 74/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7508 - val_loss: 0.5972\n",
      "Epoch 75/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7279 - val_loss: 0.6189\n",
      "Epoch 76/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7305 - val_loss: 0.6782\n",
      "Epoch 77/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7445 - val_loss: 0.5958\n",
      "Epoch 78/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7348 - val_loss: 0.5993\n",
      "Epoch 79/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7544 - val_loss: 0.6726\n",
      "Epoch 80/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7421 - val_loss: 0.5826\n",
      "Epoch 81/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7152 - val_loss: 0.6349\n",
      "Epoch 82/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7213 - val_loss: 0.5850\n",
      "Epoch 83/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7155 - val_loss: 0.5944\n",
      "Epoch 84/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7218 - val_loss: 0.6046\n",
      "Epoch 85/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7188 - val_loss: 0.6027\n",
      "Epoch 86/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7299 - val_loss: 0.5890\n",
      "Epoch 87/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7218 - val_loss: 0.6237\n",
      "Epoch 88/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7103 - val_loss: 0.6007\n",
      "Epoch 89/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7148 - val_loss: 0.5869\n",
      "Epoch 90/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7365 - val_loss: 0.5920\n",
      "Epoch 91/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7272 - val_loss: 0.5896\n",
      "Epoch 92/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.7034 - val_loss: 0.6721\n",
      "Epoch 93/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7059 - val_loss: 0.5915\n",
      "Epoch 94/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 0.6125\n",
      "Epoch 95/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7113 - val_loss: 0.5863\n",
      "Epoch 96/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7132 - val_loss: 0.5888\n",
      "Epoch 97/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6822 - val_loss: 0.5925\n",
      "Epoch 98/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6968 - val_loss: 0.7275\n",
      "Epoch 99/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7056 - val_loss: 0.5921\n",
      "Epoch 100/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6912 - val_loss: 0.5846\n",
      "\n",
      "RMSE for validation 0.7646055374813\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.757 m/s as root mean\n",
      "Wind MAE:  0.581 m/s in avg\n",
      "Wind MAPE:  7.679 %\n",
      "Power RMSE:  341.788 kW as root mean\n",
      "Power MAE:  230.855 kW in avg\n",
      "Power MAPE:  7.552172816209491e+16 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.775 m/s as root mean\n",
      "Wind MAE:  0.597 m/s in avg\n",
      "Wind MAPE:  7.722 %\n",
      "Power RMSE:  364.348 kW as root mean\n",
      "Power MAE:  242.455 kW in avg\n",
      "Power MAPE:  22.917 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f5f492",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26db8c",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d5176",
   "metadata": {},
   "source": [
    "MAPE wind: 20.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4dd9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('T22_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71206bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568d86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5148bd3a",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "201fc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('T22_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cca62eca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.65 m/s as root mean\n",
      "Wind MAE:  0.501 m/s in avg\n",
      "Wind MAPE:  6.594 %\n",
      "Power RMSE:  293.747 kW as root mean\n",
      "Power MAE:  199.892 kW in avg\n",
      "Power MAPE:  3.4799457333710576e+16 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.73 m/s as root mean\n",
      "Wind MAE:  0.551 m/s in avg\n",
      "Wind MAPE:  7.162 %\n",
      "Power RMSE:  340.821 kW as root mean\n",
      "Power MAE:  223.019 kW in avg\n",
      "Power MAPE:  20.814 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad0ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a94611ab",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "288e9e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c57522992b34df09dd7b68a79770cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1722 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x597.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance through SHAP values performed\n"
     ]
    }
   ],
   "source": [
    "shap_values=feature_importance (X_train, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df370857",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=transform_shap (shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3448bcaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>SHAP_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WS1</td>\n",
       "      <td>0.979029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WS3</td>\n",
       "      <td>0.101241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WS4</td>\n",
       "      <td>0.544211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WD1</td>\n",
       "      <td>0.082908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WD4</td>\n",
       "      <td>0.052143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WSHor</td>\n",
       "      <td>0.578861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WSVer</td>\n",
       "      <td>0.059481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WDHor</td>\n",
       "      <td>0.054750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RH1</td>\n",
       "      <td>0.499326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PR1</td>\n",
       "      <td>0.370266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WSH</td>\n",
       "      <td>0.067663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WVeer</td>\n",
       "      <td>0.169055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TI</td>\n",
       "      <td>0.577915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WDVer</td>\n",
       "      <td>0.020230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WD_bin</td>\n",
       "      <td>0.159275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tod</td>\n",
       "      <td>0.122585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables  SHAP_abs\n",
       "0        WS1  0.979029\n",
       "1        WS3  0.101241\n",
       "2        WS4  0.544211\n",
       "3        WD1  0.082908\n",
       "4        WD4  0.052143\n",
       "5      WSHor  0.578861\n",
       "6      WSVer  0.059481\n",
       "7      WDHor  0.054750\n",
       "8        RH1  0.499326\n",
       "9        PR1  0.370266\n",
       "10      Rain  0.000000\n",
       "11       WSH  0.067663\n",
       "12     WVeer  0.169055\n",
       "13        TI  0.577915\n",
       "14     WDVer  0.020230\n",
       "15    WD_bin  0.159275\n",
       "16       tod  0.122585"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c2882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "354.74px",
    "left": "1350.99px",
    "right": "20px",
    "top": "2px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
