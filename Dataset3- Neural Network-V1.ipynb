{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ad1a2a",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff62b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#data pre-processing packages\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#results and analysis packages\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78cf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data modelling & results\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#NN\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#feature importance\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304bd4d",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd727e",
   "metadata": {},
   "source": [
    "## Error computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4247b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the Root Mean Squared Error\n",
    "\n",
    "def rmse(y_true, y_predicted):\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910f4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors computation\n",
    "\n",
    "def errors_computation(data):\n",
    "    \n",
    "    df=pd.DataFrame()\n",
    "    #df.at['RMSE (as root mean)', 'Wind']= round(rmse(data['Target'], data['WS_pred']), 3)\n",
    "    df.at['MAE (in avg)', 'Wind']= round(mae(data['Target'], data['WS_pred']), 3)\n",
    "    df.at['MAPE (%)', 'Wind']= round(mape(data['Target'], data['WS_pred'])*100, 3)\n",
    "    \n",
    "    #df.at['RMSE (as root mean)', 'Power']= round(rmse(data['P'], data['P_pred']), 3)\n",
    "    df.at['MAE (in avg)', 'Power']= round(mae(data['P'], data['P_pred']), 3)\n",
    "    df.at['MAPE (%)', 'Power']= round(mape(data['P'], data['P_pred'])*100, 3)\n",
    "    \n",
    "    \n",
    "    print('Wind RMSE: ', round(rmse(data['Target'], data['WS_pred']), 3), 'm/s as root mean')\n",
    "    print('Wind MAE: ', round(mae(data['Target'], data['WS_pred']), 3), 'm/s in avg')\n",
    "    print('Wind MAPE: ', round(mape(data['Target'], data['WS_pred'])*100, 3), '%')\n",
    "    \n",
    "    print('Power RMSE: ', round(rmse(data['P'], data['P_pred']), 3), 'kW as root mean')\n",
    "    print('Power MAE: ', round(mae(data['P'], data['P_pred']), 3), 'kW in avg')\n",
    "    print('Power MAPE: ', round(mape(data['P'], data['P_pred'])*100, 3), '%')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9f017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(data, title):\n",
    "    \n",
    "    #title is expected to be an str\n",
    "    #WS_pred and Target should be the variables names\n",
    "\n",
    "    #plotting the reference\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot([-1,17.5],[-1,17.5], 'green', linewidth=4, alpha=.12)\n",
    "    plt.plot(data['WS_pred'], data['Target'], marker='o', ls='', label='Regression', markersize=5, alpha=.1)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    ax=plt.gca()\n",
    "    ax.set(xlabel='y predicted', ylabel='y actual');\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(ymin=4, ymax=17.5)\n",
    "    ax.set_xlim(xmin=4, xmax=17.5)\n",
    "    \n",
    "    return print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58bd13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powercurve_computation(data, power_curve):\n",
    "    \n",
    "    from scipy import interpolate\n",
    "    \n",
    "    #this function computes the power at a observation given the information at a observation:\n",
    "    # the WS (in m/s) at the wind turbine location and at the hub height (Target)\n",
    "    # the power curve of the wind turbine in an xslx\n",
    "    \n",
    "    \n",
    "    x=power_curve['Wind Speed [m/s]']\n",
    "    y=power_curve['Warranted Power Curve [kW]']\n",
    "    x_new=data['Target']\n",
    "    \n",
    "    f = interpolate.interp1d(x, y)\n",
    "    #, kind='linear'\n",
    "    data['P']=f(x_new)\n",
    "    \n",
    "    if 'WS_pred' in data.keys():\n",
    "        x_new2=data['WS_pred']\n",
    "        data['P_pred']=f(x_new2)\n",
    "    \n",
    "    print('power curve computation performed')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c09062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_power_computation (data_test, data_train, power_curve):\n",
    "    \n",
    "    results_test=pd.DataFrame()\n",
    "    results_train=pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    results_test=powercurve_computation(data_test, power_curve)\n",
    "    results_train=powercurve_computation(data_train, power_curve)\n",
    "\n",
    "    return results_test, results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3896d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results(data_test, data_train, power_curve, plot_error):\n",
    "    \n",
    "    #this function computes and plots the results of a modelling:\n",
    "\n",
    "    results_test, results_train=control_power_computation (data_test, data_train, power_curve)\n",
    "    \n",
    "    \n",
    "    print('Modelling errors for training set:')\n",
    "    errors_computation(results_train)\n",
    "    print('')\n",
    "    print('Modelling errors for test set:')\n",
    "    errors_computation(results_test)\n",
    "    \n",
    "    if plot_error:\n",
    "        print('')\n",
    "        error_plot(results_test, 'Error plot for test set wind speed')\n",
    "\n",
    "    print('')\n",
    "    return print('Showing the results of the modelling: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71970e76",
   "metadata": {},
   "source": [
    "## Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bcfb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploading_csv(file_folder,file_name):\n",
    "    \n",
    "    #file folder required\n",
    "    #file name required\n",
    "    #file is expected to be in the data root: r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    #this function uploads and formats csv/txt/xlsx datasets into DataFrame\n",
    "    \n",
    "    \n",
    "    data_root=r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    data_folder=str(file_folder)\n",
    "    data_file=str(file_name)\n",
    "    \n",
    "    data_path=data_root+data_folder+data_file\n",
    "    \n",
    "    data1 = pd.read_csv(data_path)\n",
    "\n",
    "    \n",
    "    # We will save the WD_bin as the index\n",
    "    \n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c5e33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function saves a data csv\n",
    "\n",
    "def save (data, file_folder,file_name):\n",
    "    \n",
    "    #file folder required\n",
    "    #file name required\n",
    "    #file is expected to be saved in the data root: r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    #this function saves a csv/txt/xlsx into Irma's folder\n",
    "    #the saved file will keep the columns names but not the index\n",
    "    \n",
    "    data_root=r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    data_folder=str(file_folder)\n",
    "    data_file=str(file_name)\n",
    "    \n",
    "    data_path=data_root+data_folder+data_file\n",
    "    \n",
    "    data.to_csv (data_path, index = False, header=True)\n",
    "    \n",
    "    \n",
    "    return print('file', data_file, 'saved in', data_folder, 'folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaedaca",
   "metadata": {},
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "358a5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_selection(X_train, X_test, inputs):\n",
    "    \n",
    "    #this function returns the columns of the training and test sets in the inputs list\n",
    "    \n",
    "    X_train1 = pd.DataFrame()\n",
    "    X_test1 = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    X_train1 = X_train[inputs]\n",
    "    X_test1 = X_test[inputs]\n",
    "\n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd717ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_drop(X_train, X_test, list_2drop):\n",
    "    \n",
    "    #this function returns the columns of the training and test sets in the inputs list\n",
    "\n",
    "    X_train1 = X_train.drop(columns=list_2drop)\n",
    "    X_test1 = X_test.drop(columns=list_2drop)\n",
    "\n",
    "    \n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c2b31",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5c814",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eec63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model (n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8],\n",
    "                 activation='relu', optimizer='Adam', regularization=None, Leaky=False):\n",
    "    \n",
    "    #this function build model is created only for building the NN\n",
    "    #it will always initialize the weights using the strategy 'He normal' unless activation function 'selu' is selected\n",
    "    \n",
    "    \n",
    "    if activation!='relu':\n",
    "        Leaky==False\n",
    "    \n",
    "    \n",
    "    #we create a sequential model:\n",
    "    model=keras.models.Sequential()\n",
    "    \n",
    "    #we add the input layer with n_neurons=n_features (shape of X_train)\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    #we add a hidden layer for each n_hidden with ReLU as activation function\n",
    "    #this code considers the same n_neurons for each hidden layer\n",
    "    for layer in range(n_hidden):\n",
    "        \n",
    "        if regularization=='l2':\n",
    "            if activation=='relu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal',\n",
    "                                            kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "            elif activation=='elu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal',\n",
    "                                            kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "            elif activation=='selu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal',\n",
    "                                           kernel_regularizer=keras.regularizers.l2(0.01)))  \n",
    "        elif regularization=='l1':\n",
    "            if activation=='relu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal',\n",
    "                                             kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "            elif activation=='elu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal',\n",
    "                                             kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "            elif activation=='selu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal',\n",
    "                                            kernel_regularizer=keras.regularizers.l1(0.01))) \n",
    "        else:\n",
    "            if activation=='relu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal'))\n",
    "            elif activation=='elu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal'))\n",
    "            elif activation=='selu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal'))\n",
    "        \n",
    "        if Leaky:\n",
    "            model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    #dropout only considered in the last layer\n",
    "    if regularization=='Dropout':\n",
    "        model.add(keras.layers.Dropout(rate=0.2))\n",
    "        \n",
    "    #we add the output layer with one neuron (we only want to predict 1 target)\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    #we choose our optimizer and build it:\n",
    "    if optimizer=='SGD':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate)\n",
    "    elif optimizer=='Momentum':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer=='Nesterov':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    elif optimizer=='RMSprop':\n",
    "        optimizer=keras.optimizers.RMSprop(lr=learning_rate, rho=0.9)\n",
    "    elif optimizer=='Adam':\n",
    "        optimizer=keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    elif optimizer=='Nadam':\n",
    "        optimizer=keras.optimizers.Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    \n",
    "    #we compile our model with the selected optimizer and set the objective function loss='mse'\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb2847dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_old (n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8],\n",
    "                 activation='relu', optimizer='Adam', regularization=None, Leaky=False):\n",
    "    \n",
    "    #this function build model is created only for building the NN\n",
    "    #it will always initialize the weights using the strategy 'He normal' unless activation function 'selu' is selected\n",
    "    \n",
    "    \n",
    "    if activation!='relu':\n",
    "        Leaky==False\n",
    "    \n",
    "    \n",
    "    #we create a sequential model:\n",
    "    model=keras.models.Sequential()\n",
    "    \n",
    "    #we add the input layer with n_neurons=n_features (shape of X_train)\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    #we add a hidden layer for each n_hidden with ReLU as activation function\n",
    "    #this code considers the same n_neurons for each hidden layer\n",
    "    for layer in range(n_hidden):\n",
    "        if activation=='relu':\n",
    "            model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal'))\n",
    "        elif activation=='elu':\n",
    "            model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal'))\n",
    "        elif activation=='selu':\n",
    "            model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal'))\n",
    "        if Leaky:\n",
    "            model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "            \n",
    "    if regularization=='Dropout':\n",
    "        model.add(keras.layers.Dropout(rate=0.2))\n",
    "        \n",
    "    #we add the output layer with one neuron (we only want to predict 1 target)\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    #we choose our optimizer and build it:\n",
    "    if optimizer=='SGD':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate)\n",
    "    elif optimizer=='Momentum':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer=='Nesterov':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    elif optimizer=='RMSprop':\n",
    "        optimizer=keras.optimizers.RMSprop(lr=learning_rate, rho=0.9)\n",
    "    elif optimizer=='Adam':\n",
    "        optimizer=keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    elif optimizer=='Nadam':\n",
    "        optimizer=keras.optimizers.Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    \n",
    "    #we compile our model with the selected optimizer and set the objective function loss='mse'\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983f849",
   "metadata": {},
   "source": [
    "### Modelling NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c827782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling_NN (X, X_test, y, y_test, power_curve,  parameters, plot_error, plot):\n",
    "    \n",
    "    #creating the model\n",
    "    \n",
    "    n_hidden=parameters['n_hidden']\n",
    "    n_neurons=parameters['n_neurons']\n",
    "    learning_rate=parameters['learning_rate']\n",
    "    input_shape=X.shape[1:]\n",
    "    activation=parameters['activation']\n",
    "    optimizer=parameters['optimizer']\n",
    "    regularization=parameters['regularization']\n",
    "    Leaky=parameters['Leaky']\n",
    "    \n",
    "    model =build_model(n_hidden, n_neurons, learning_rate, input_shape,\n",
    "                 activation, optimizer, regularization, Leaky)\n",
    " \n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "    if regularization=='Early Stopping':\n",
    "        model.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid))\n",
    "    \n",
    "    \n",
    "#     if plot:\n",
    "#         loss_epochs_plot (history)\n",
    "        \n",
    "    \n",
    "    #model predicting\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    y_pred_valid=model.predict(X_valid)\n",
    "    \n",
    "    rmse_valid=rmse(y_valid, y_pred_valid)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    \n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "    print('')\n",
    "    print('RMSE for validation', rmse_valid)\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('NN modelling performed')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6df93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling_NN_ES (X, X_test, y, y_test, power_curve,  parameters, plot_error, plot):\n",
    "    \n",
    "    #creating the model\n",
    "    \n",
    "    n_hidden=parameters['n_hidden']\n",
    "    n_neurons=parameters['n_neurons']\n",
    "    learning_rate=parameters['learning_rate']\n",
    "    input_shape=X.shape[1:]\n",
    "    activation=parameters['activation']\n",
    "    optimizer=parameters['optimizer']\n",
    "    regularization=parameters['regularization']\n",
    "    Leaky=parameters['Leaky']\n",
    "    \n",
    "    model =build_model(n_hidden, n_neurons, learning_rate, input_shape,\n",
    "                 activation, optimizer, regularization, Leaky)\n",
    " \n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    \n",
    "    \n",
    "#     if plot:\n",
    "#         loss_epochs_plot (history)\n",
    "        \n",
    "    \n",
    "    #model predicting\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    \n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "#     mse_test=model.evaluate(X_test, y_test)\n",
    "#     rmse_test=np.sqrt(mse_test)\n",
    "#     print('RMSE for test', rmse_test)\n",
    "    \n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('NN modelling performed')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c283c5",
   "metadata": {},
   "source": [
    "### Random Search NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c6cd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSearch_NN(X, X_test, y, y_test, power_curve, param_distribs, plot_error):\n",
    "    \n",
    "    #counting the runing time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    #creating the model\n",
    "    input_shape=X.shape[1:]\n",
    "    param_distribs['input_shape']=input_shape\n",
    "    keras_reg =keras.wrappers.scikit_learn.KerasRegressor(build_model, verbose=0)\n",
    "    \n",
    "    \n",
    "    #Random Search CV\n",
    "    rnd_search_cv=RandomizedSearchCV(keras_reg, param_distribs, n_iter=20, cv=3)\n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    regularization=param_distribs['regularization']\n",
    "    \n",
    "    if regularization=='Early Stopping':\n",
    "        rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    else:\n",
    "        rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid))\n",
    "    \n",
    "    \n",
    "    #model predicting\n",
    "    \n",
    "    model=rnd_search_cv.best_estimator_.model\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    print('')\n",
    "    print('Best parameters :')\n",
    "    print(rnd_search_cv.best_params_)\n",
    "    print('Best score :')\n",
    "    print(rnd_search_cv.best_score_)\n",
    "    print('')\n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))\n",
    "    print('')\n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('RandomSearch_ NN performed')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6523601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSearch_NN_ES(X, X_test, y, y_test, power_curve, param_distribs, plot_error):\n",
    "    \n",
    "    #counting the runing time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #creating the model\n",
    "    input_shape=X.shape[1:]\n",
    "    param_distribs['input_shape']=input_shape\n",
    "    keras_reg =keras.wrappers.scikit_learn.KerasRegressor(build_model, verbose=0)\n",
    "    \n",
    "    #Random Search CV\n",
    "    rnd_search_cv=RandomizedSearchCV(keras_reg, param_distribs, n_iter=20, cv=3)\n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    \n",
    "    \n",
    "    #model predicting\n",
    "    \n",
    "    model=rnd_search_cv.best_estimator_.model\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    print('')\n",
    "    print('Best parameters :')\n",
    "    print(rnd_search_cv.best_params_)\n",
    "    print('Best score :')\n",
    "    print(rnd_search_cv.best_score_)\n",
    "    print('')\n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))\n",
    "    print('')\n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('RandomSearch_ NN performed')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7836fc",
   "metadata": {},
   "source": [
    "### Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a862833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_epochs_plot (history):\n",
    "    \n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.show\n",
    "    \n",
    "    return print('Loss vs. epochs plot performed')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54004cbb",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bfe8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing (X_train, X_test, y_train, y_test, power_curve, model, plot_error):\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X_train)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "\n",
    "\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y_train['Target']\n",
    "    \n",
    "    plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    \n",
    "    WS_pred=data_test['WS_pred']\n",
    "    print('NN results performed')\n",
    "    \n",
    "    return WS_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724a96a",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51189ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance (X_train, X_test, model):\n",
    "    \n",
    "    X_t, X_f, y_t, y_f = train_test_split(X_train,y_train, test_size=0.02, random_state=12)\n",
    "    \n",
    "    background = X_f.copy()\n",
    "    \n",
    "    explainer = shap.KernelExplainer(model.predict,background)\n",
    "    shap_values = explainer.shap_values(X_test,nsamples=100)\n",
    "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "    print('Feature importance through SHAP values performed')\n",
    "    \n",
    "\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046028e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_shap (shap_values, X_test):\n",
    "\n",
    "    v=np.array(shap_values)\n",
    "    d=v.reshape(X_test.shape)\n",
    "    shap_v=pd.DataFrame(d)\n",
    "    \n",
    "    feature_list=X_test.columns\n",
    "    shap_v.columns=feature_list\n",
    "    shap_v=shap_v.abs()\n",
    "    k=pd.DataFrame(shap_v.mean()).reset_index()\n",
    "    k.columns=['variables','SHAP_abs']\n",
    "    k.sort_values(by='variables')\n",
    "    \n",
    "    return k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d0819",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fec4a",
   "metadata": {},
   "source": [
    "## Dataset3- WTG18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3f2c12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WSHor', 'WDHor', 'WSVer', 'WDVer', 'T1', 'RH1',\n",
       "       'T2', 'RH2', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WD1', 'WD3', 'WD4',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "# data_up= uploading_csv('\\Dataset1-Normal_Site','\\data_comp14.csv')\n",
    "X_train= uploading_csv('\\Dataset3-New_Site','\\X_train18.csv')\n",
    "X_test= uploading_csv('\\Dataset3-New_Site','\\X_test18.csv')\n",
    "y_train= uploading_csv('\\Dataset3-New_Site','\\y_train18.csv')\n",
    "y_test= uploading_csv('\\Dataset3-New_Site','\\y_test18.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0a26d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08af60ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS1</th>\n",
       "      <th>WS3</th>\n",
       "      <th>WS4</th>\n",
       "      <th>WSHor</th>\n",
       "      <th>WDHor</th>\n",
       "      <th>WSVer</th>\n",
       "      <th>WDVer</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH1</th>\n",
       "      <th>T2</th>\n",
       "      <th>...</th>\n",
       "      <th>AD2</th>\n",
       "      <th>Rain</th>\n",
       "      <th>WD1</th>\n",
       "      <th>WD3</th>\n",
       "      <th>WD4</th>\n",
       "      <th>TI</th>\n",
       "      <th>WSH</th>\n",
       "      <th>WD_bin</th>\n",
       "      <th>tod</th>\n",
       "      <th>WVeer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.452444</td>\n",
       "      <td>0.347761</td>\n",
       "      <td>0.202223</td>\n",
       "      <td>0.454517</td>\n",
       "      <td>0.184304</td>\n",
       "      <td>0.680389</td>\n",
       "      <td>0.517188</td>\n",
       "      <td>0.286739</td>\n",
       "      <td>0.603215</td>\n",
       "      <td>0.160345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789553</td>\n",
       "      <td>0.643465</td>\n",
       "      <td>0.177710</td>\n",
       "      <td>0.343535</td>\n",
       "      <td>0.330779</td>\n",
       "      <td>0.044303</td>\n",
       "      <td>0.800919</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.610193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042582</td>\n",
       "      <td>0.142939</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>0.047671</td>\n",
       "      <td>0.445111</td>\n",
       "      <td>0.578917</td>\n",
       "      <td>0.509039</td>\n",
       "      <td>0.452673</td>\n",
       "      <td>0.543242</td>\n",
       "      <td>0.430103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606720</td>\n",
       "      <td>0.363330</td>\n",
       "      <td>0.441385</td>\n",
       "      <td>0.541391</td>\n",
       "      <td>0.523286</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.691417</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>0.632766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.076393</td>\n",
       "      <td>0.113539</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.907204</td>\n",
       "      <td>0.424257</td>\n",
       "      <td>0.303996</td>\n",
       "      <td>0.769867</td>\n",
       "      <td>0.111697</td>\n",
       "      <td>0.769392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254355</td>\n",
       "      <td>0.257218</td>\n",
       "      <td>0.908858</td>\n",
       "      <td>0.898883</td>\n",
       "      <td>0.902435</td>\n",
       "      <td>0.130473</td>\n",
       "      <td>0.490261</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.874126</td>\n",
       "      <td>0.512707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039519</td>\n",
       "      <td>0.104726</td>\n",
       "      <td>0.076846</td>\n",
       "      <td>0.047924</td>\n",
       "      <td>0.362332</td>\n",
       "      <td>0.586612</td>\n",
       "      <td>0.531281</td>\n",
       "      <td>0.204521</td>\n",
       "      <td>0.915944</td>\n",
       "      <td>0.223248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694487</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.360666</td>\n",
       "      <td>0.480799</td>\n",
       "      <td>0.454734</td>\n",
       "      <td>0.187784</td>\n",
       "      <td>0.668834</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304817</td>\n",
       "      <td>0.368122</td>\n",
       "      <td>0.411495</td>\n",
       "      <td>0.308579</td>\n",
       "      <td>0.432230</td>\n",
       "      <td>0.626046</td>\n",
       "      <td>0.507254</td>\n",
       "      <td>0.602922</td>\n",
       "      <td>0.647608</td>\n",
       "      <td>0.641780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428703</td>\n",
       "      <td>0.532343</td>\n",
       "      <td>0.527155</td>\n",
       "      <td>0.292199</td>\n",
       "      <td>0.348341</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.576159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        WS1       WS3       WS4     WSHor     WDHor     WSVer     WDVer  \\\n",
       "0  0.452444  0.347761  0.202223  0.454517  0.184304  0.680389  0.517188   \n",
       "1  0.042582  0.142939  0.071787  0.047671  0.445111  0.578917  0.509039   \n",
       "2  0.002431  0.076393  0.113539  0.005122  0.907204  0.424257  0.303996   \n",
       "3  0.039519  0.104726  0.076846  0.047924  0.362332  0.586612  0.531281   \n",
       "4  0.304817  0.368122  0.411495  0.308579  0.432230  0.626046  0.507254   \n",
       "\n",
       "         T1       RH1        T2  ...       AD2      Rain       WD1       WD3  \\\n",
       "0  0.286739  0.603215  0.160345  ...  0.789553  0.643465  0.177710  0.343535   \n",
       "1  0.452673  0.543242  0.430103  ...  0.606720  0.363330  0.441385  0.541391   \n",
       "2  0.769867  0.111697  0.769392  ...  0.254355  0.257218  0.908858  0.898883   \n",
       "3  0.204521  0.915944  0.223248  ...  0.694487  0.903226  0.360666  0.480799   \n",
       "4  0.602922  0.647608  0.641780  ...  0.327677  0.000000  0.428703  0.532343   \n",
       "\n",
       "        WD4        TI       WSH    WD_bin       tod     WVeer  \n",
       "0  0.330779  0.044303  0.800919  0.153846  0.230769  0.610193  \n",
       "1  0.523286  0.014165  0.691417  0.423077  0.048951  0.632766  \n",
       "2  0.902435  0.130473  0.490261  0.923077  0.874126  0.512707  \n",
       "3  0.454734  0.187784  0.668834  0.346154  0.000000  0.666537  \n",
       "4  0.527155  0.292199  0.348341  0.423077  0.958042  0.576159  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db055157",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset3-New_Site','\\PC_V150.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adb853",
   "metadata": {},
   "source": [
    "### RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ff683ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam', 'RMSProp'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74963bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [-0.28162809 -2.31641841 -0.22103334 -0.2437923  -0.24043911 -0.28493093\n",
      " -0.27551968 -0.28334983         nan -0.30713005 -2.10673717 -0.25823838\n",
      " -0.56209338 -0.26626723 -0.25863049 -0.27755742 -0.31576704 -0.23353337\n",
      " -0.22374796 -0.24266904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': None, 'optimizer': 'RMSProp', 'n_neurons': 60, 'n_hidden': 3, 'learning_rate': 0.01, 'input_shape': 24, 'activation': 'relu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.22103334466616312\n",
      "\n",
      "--- 24.763838251431782 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.761 m/s as root mean\n",
      "Wind MAE:  0.657 m/s in avg\n",
      "Wind MAPE:  8.411 %\n",
      "Power RMSE:  429.615 kW as root mean\n",
      "Power MAE:  337.373 kW in avg\n",
      "Power MAPE:  21.073 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.792 m/s as root mean\n",
      "Wind MAE:  0.667 m/s in avg\n",
      "Wind MAPE:  8.51 %\n",
      "Power RMSE:  449.623 kW as root mean\n",
      "Power MAE:  343.845 kW in avg\n",
      "Power MAPE:  19.27 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ecc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd3b8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9055db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [ -0.33635923  -0.24475749  -0.25788202  -0.27939104  -0.24706641\n",
      "  -0.2708785  -56.77045186  -0.30852381  -0.31891754  -0.31994725\n",
      "  -0.29888881  -0.26991477  -0.24741414  -0.31562376  -0.30552221\n",
      "  -0.70065536  -0.2621788           nan  -0.25593152  -0.2879117 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': None, 'optimizer': 'Nesterov', 'n_neurons': 20, 'n_hidden': 1, 'learning_rate': 0.01, 'input_shape': 24, 'activation': 'relu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.24475749333699545\n",
      "\n",
      "--- 25.240467631816863 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.517 m/s as root mean\n",
      "Wind MAE:  0.396 m/s in avg\n",
      "Wind MAPE:  5.29 %\n",
      "Power RMSE:  299.055 kW as root mean\n",
      "Power MAE:  203.149 kW in avg\n",
      "Power MAPE:  19.243 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.538 m/s as root mean\n",
      "Wind MAE:  0.41 m/s in avg\n",
      "Wind MAPE:  5.395 %\n",
      "Power RMSE:  306.293 kW as root mean\n",
      "Power MAE:  206.963 kW in avg\n",
      "Power MAPE:  13.847 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4615ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ef7f7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Early Stopping', 'optimizer': 'Adam', 'n_neurons': 30, 'n_hidden': 3, 'learning_rate': 0.003, 'input_shape': 24, 'activation': 'elu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.22901726265748343\n",
      "\n",
      "--- 21.87839259703954 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.439 m/s as root mean\n",
      "Wind MAE:  0.331 m/s in avg\n",
      "Wind MAPE:  4.386 %\n",
      "Power RMSE:  254.406 kW as root mean\n",
      "Power MAE:  169.293 kW in avg\n",
      "Power MAPE:  15.183 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.472 m/s as root mean\n",
      "Wind MAE:  0.351 m/s in avg\n",
      "Wind MAPE:  4.632 %\n",
      "Power RMSE:  273.559 kW as root mean\n",
      "Power MAE:  178.541 kW in avg\n",
      "Power MAPE:  11.677 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b483daf",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4145fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3e2970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.9545 - val_loss: 0.5687\n",
      "Epoch 2/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.4291 - val_loss: 0.4056\n",
      "Epoch 3/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.3505 - val_loss: 0.3567\n",
      "Epoch 4/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.3121 - val_loss: 0.2980\n",
      "Epoch 5/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2833 - val_loss: 0.2892\n",
      "Epoch 6/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2800 - val_loss: 0.2935\n",
      "Epoch 7/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2750 - val_loss: 0.4693\n",
      "Epoch 8/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2722 - val_loss: 0.3048\n",
      "Epoch 9/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2455 - val_loss: 0.2307\n",
      "Epoch 10/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2482 - val_loss: 0.2389\n",
      "Epoch 11/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2443 - val_loss: 0.2372\n",
      "Epoch 12/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2439 - val_loss: 0.3139\n",
      "Epoch 13/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2649 - val_loss: 0.2222\n",
      "Epoch 14/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2419 - val_loss: 0.3436\n",
      "Epoch 15/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2453 - val_loss: 0.2620\n",
      "Epoch 16/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2431 - val_loss: 0.2770\n",
      "Epoch 17/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2306 - val_loss: 0.3379\n",
      "Epoch 18/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2327 - val_loss: 0.2136\n",
      "Epoch 19/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2242 - val_loss: 0.2350\n",
      "Epoch 20/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2174 - val_loss: 0.2421\n",
      "Epoch 21/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2413 - val_loss: 0.2473\n",
      "Epoch 22/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2148 - val_loss: 0.2728\n",
      "Epoch 23/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2394 - val_loss: 0.2467\n",
      "Epoch 24/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2283 - val_loss: 0.2244\n",
      "Epoch 25/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2131 - val_loss: 0.2237\n",
      "Epoch 26/100\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.2176 - val_loss: 0.2667\n",
      "Epoch 27/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2097 - val_loss: 0.2123\n",
      "Epoch 28/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2167 - val_loss: 0.2379\n",
      "Epoch 29/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2151 - val_loss: 0.2396\n",
      "Epoch 30/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2118 - val_loss: 0.2854\n",
      "Epoch 31/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2052 - val_loss: 0.2272\n",
      "Epoch 32/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2063 - val_loss: 0.2086\n",
      "Epoch 33/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2032 - val_loss: 0.2419\n",
      "Epoch 34/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2091 - val_loss: 0.2363\n",
      "Epoch 35/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2075 - val_loss: 0.2260\n",
      "Epoch 36/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2079 - val_loss: 0.2374\n",
      "Epoch 37/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2054 - val_loss: 0.2501\n",
      "Epoch 38/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2065 - val_loss: 0.2198\n",
      "Epoch 39/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2241 - val_loss: 0.1982\n",
      "Epoch 40/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1949 - val_loss: 0.2023\n",
      "Epoch 41/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1988 - val_loss: 0.2085\n",
      "Epoch 42/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2033 - val_loss: 0.4333\n",
      "Epoch 43/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2215 - val_loss: 0.2562\n",
      "Epoch 44/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1953 - val_loss: 0.1913\n",
      "Epoch 45/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.2067\n",
      "Epoch 46/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1921 - val_loss: 0.3440\n",
      "Epoch 47/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2491 - val_loss: 0.2058\n",
      "Epoch 48/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1905 - val_loss: 0.1981\n",
      "Epoch 49/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1963 - val_loss: 0.2028\n",
      "Epoch 50/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1864 - val_loss: 0.2060\n",
      "Epoch 51/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.1832 - val_loss: 0.1981\n",
      "Epoch 52/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1968 - val_loss: 0.2116\n",
      "Epoch 53/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1960 - val_loss: 0.2091\n",
      "Epoch 54/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1998 - val_loss: 0.2046\n",
      "Epoch 55/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1833 - val_loss: 0.1927\n",
      "Epoch 56/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1903 - val_loss: 0.2108\n",
      "Epoch 57/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1912 - val_loss: 0.1924\n",
      "Epoch 58/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1776 - val_loss: 0.2537\n",
      "Epoch 59/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1955 - val_loss: 0.2025\n",
      "Epoch 60/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.1912 - val_loss: 0.1969\n",
      "Epoch 61/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1866 - val_loss: 0.2240\n",
      "Epoch 62/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.2251\n",
      "Epoch 63/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.1854 - val_loss: 0.2622\n",
      "Epoch 64/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1883 - val_loss: 0.2122\n",
      "Epoch 65/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1887 - val_loss: 0.2052\n",
      "Epoch 66/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1840 - val_loss: 0.1922\n",
      "Epoch 67/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1874 - val_loss: 0.2058\n",
      "Epoch 68/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1755 - val_loss: 0.2112\n",
      "Epoch 69/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1782 - val_loss: 0.2195\n",
      "Epoch 70/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1791 - val_loss: 0.2675\n",
      "Epoch 71/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.1930\n",
      "Epoch 72/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1820 - val_loss: 0.2032\n",
      "Epoch 73/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1815 - val_loss: 0.2277\n",
      "Epoch 74/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1830 - val_loss: 0.2355\n",
      "Epoch 75/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1915 - val_loss: 0.2122\n",
      "Epoch 76/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1775 - val_loss: 0.3987\n",
      "Epoch 77/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1824 - val_loss: 0.1908\n",
      "Epoch 78/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1691 - val_loss: 0.1856\n",
      "Epoch 79/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1789 - val_loss: 0.1864\n",
      "Epoch 80/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1694 - val_loss: 0.1834\n",
      "Epoch 81/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1672 - val_loss: 0.1851\n",
      "Epoch 82/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1693 - val_loss: 0.1994\n",
      "Epoch 83/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1826 - val_loss: 0.2309\n",
      "Epoch 84/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1725 - val_loss: 0.1962\n",
      "Epoch 85/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1715 - val_loss: 0.1908\n",
      "Epoch 86/100\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.1692 - val_loss: 0.1879\n",
      "Epoch 87/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.1687 - val_loss: 0.1901\n",
      "Epoch 88/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.1662 - val_loss: 0.2530\n",
      "Epoch 89/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1680 - val_loss: 0.2384\n",
      "Epoch 90/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1756 - val_loss: 0.1922\n",
      "Epoch 91/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1624 - val_loss: 0.2356\n",
      "Epoch 92/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1887 - val_loss: 0.2201\n",
      "Epoch 93/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.1903\n",
      "Epoch 94/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1623 - val_loss: 0.1964\n",
      "Epoch 95/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1614 - val_loss: 0.2061\n",
      "Epoch 96/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1625 - val_loss: 0.2523\n",
      "Epoch 97/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1654 - val_loss: 0.2098\n",
      "Epoch 98/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1610 - val_loss: 0.2017\n",
      "Epoch 99/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1617 - val_loss: 0.2516\n",
      "Epoch 100/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1576 - val_loss: 0.1818\n",
      "\n",
      "RMSE for validation 0.42639150942839976\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.386 m/s as root mean\n",
      "Wind MAE:  0.289 m/s in avg\n",
      "Wind MAPE:  3.854 %\n",
      "Power RMSE:  227.309 kW as root mean\n",
      "Power MAE:  150.04 kW in avg\n",
      "Power MAPE:  13.567 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.438 m/s as root mean\n",
      "Wind MAE:  0.325 m/s in avg\n",
      "Wind MAPE:  4.314 %\n",
      "Power RMSE:  255.622 kW as root mean\n",
      "Power MAE:  167.087 kW in avg\n",
      "Power MAPE:  11.016 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdbf6c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15318497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 7.8154 - val_loss: 0.5243\n",
      "Epoch 2/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4527 - val_loss: 0.3811\n",
      "Epoch 3/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3754 - val_loss: 0.3354\n",
      "Epoch 4/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.3346\n",
      "Epoch 5/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3253 - val_loss: 0.3045\n",
      "Epoch 6/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3078 - val_loss: 0.3329\n",
      "Epoch 7/100\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.3064 - val_loss: 0.3377\n",
      "Epoch 8/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.3024 - val_loss: 0.2718\n",
      "Epoch 9/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2803 - val_loss: 0.3535\n",
      "Epoch 10/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2746 - val_loss: 0.2722\n",
      "Epoch 11/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2650 - val_loss: 0.2764\n",
      "Epoch 12/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2586 - val_loss: 0.2866\n",
      "Epoch 13/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2565 - val_loss: 0.2468\n",
      "Epoch 14/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2606 - val_loss: 0.3089\n",
      "Epoch 15/100\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.2557 - val_loss: 0.2753\n",
      "Epoch 16/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2428 - val_loss: 0.2343\n",
      "Epoch 17/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2379 - val_loss: 0.2353\n",
      "Epoch 18/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2326 - val_loss: 0.2524\n",
      "Epoch 19/100\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.2379 - val_loss: 0.2486\n",
      "Epoch 20/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2556 - val_loss: 0.2345\n",
      "Epoch 21/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2366 - val_loss: 0.2533\n",
      "Epoch 22/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2245 - val_loss: 0.2715\n",
      "Epoch 23/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2367 - val_loss: 0.3197\n",
      "Epoch 24/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2298 - val_loss: 0.2345\n",
      "Epoch 25/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2283 - val_loss: 0.3107\n",
      "Epoch 26/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2404 - val_loss: 0.2375\n",
      "\n",
      "RMSE for validation 0.4840553852586909\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.475 m/s as root mean\n",
      "Wind MAE:  0.358 m/s in avg\n",
      "Wind MAPE:  4.714 %\n",
      "Power RMSE:  272.437 kW as root mean\n",
      "Power MAE:  183.69 kW in avg\n",
      "Power MAPE:  15.954 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.502 m/s as root mean\n",
      "Wind MAE:  0.374 m/s in avg\n",
      "Wind MAPE:  4.882 %\n",
      "Power RMSE:  288.196 kW as root mean\n",
      "Power MAE:  190.479 kW in avg\n",
      "Power MAPE:  12.018 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2ee2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'selu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54351cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 7.3927 - val_loss: 0.5057\n",
      "Epoch 2/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4286 - val_loss: 0.3421\n",
      "Epoch 3/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3686 - val_loss: 0.3087\n",
      "Epoch 4/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3018\n",
      "Epoch 5/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3196 - val_loss: 0.2774\n",
      "Epoch 6/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3022 - val_loss: 0.2716\n",
      "Epoch 7/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2944 - val_loss: 0.2687\n",
      "Epoch 8/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2932 - val_loss: 0.2942\n",
      "Epoch 9/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2784 - val_loss: 0.2891\n",
      "Epoch 10/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2764 - val_loss: 0.3135\n",
      "Epoch 11/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2692 - val_loss: 0.2700\n",
      "Epoch 12/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2697 - val_loss: 0.2657\n",
      "Epoch 13/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2601 - val_loss: 0.3377\n",
      "Epoch 14/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2650 - val_loss: 0.2896\n",
      "Epoch 15/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2642 - val_loss: 0.2324\n",
      "Epoch 16/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2502 - val_loss: 0.2608\n",
      "Epoch 17/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2518 - val_loss: 0.2562\n",
      "Epoch 18/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2462 - val_loss: 0.2542\n",
      "Epoch 19/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2516 - val_loss: 0.2496\n",
      "Epoch 20/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2638 - val_loss: 0.2362\n",
      "Epoch 21/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2333 - val_loss: 0.2372\n",
      "Epoch 22/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2434 - val_loss: 0.2841\n",
      "Epoch 23/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2500 - val_loss: 0.2265\n",
      "Epoch 24/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2317 - val_loss: 0.2331\n",
      "Epoch 25/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2662 - val_loss: 0.2739\n",
      "Epoch 26/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2651 - val_loss: 0.2300\n",
      "Epoch 27/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2260 - val_loss: 0.2472\n",
      "Epoch 28/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2339 - val_loss: 0.2396\n",
      "Epoch 29/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2439 - val_loss: 0.2283\n",
      "Epoch 30/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2371 - val_loss: 0.2247\n",
      "Epoch 31/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2427 - val_loss: 0.3388\n",
      "Epoch 32/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2291 - val_loss: 0.2485\n",
      "Epoch 33/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2270 - val_loss: 0.2368\n",
      "Epoch 34/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2359 - val_loss: 0.2342\n",
      "Epoch 35/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2285 - val_loss: 0.2492\n",
      "Epoch 36/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2310 - val_loss: 0.2371\n",
      "Epoch 37/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2308 - val_loss: 0.2430\n",
      "Epoch 38/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2272 - val_loss: 0.2552\n",
      "Epoch 39/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2468 - val_loss: 0.2539\n",
      "Epoch 40/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2134 - val_loss: 0.2231\n",
      "Epoch 41/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2193 - val_loss: 0.2085\n",
      "Epoch 42/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2162 - val_loss: 0.2989\n",
      "Epoch 43/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2351 - val_loss: 0.2584\n",
      "Epoch 44/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2372 - val_loss: 0.2083\n",
      "Epoch 45/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2190 - val_loss: 0.2856\n",
      "Epoch 46/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2277 - val_loss: 0.2192\n",
      "Epoch 47/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2230 - val_loss: 0.2158\n",
      "Epoch 48/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2110 - val_loss: 0.2338\n",
      "Epoch 49/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2206 - val_loss: 0.2270\n",
      "Epoch 50/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2164 - val_loss: 0.2033\n",
      "Epoch 51/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2156 - val_loss: 0.2634\n",
      "Epoch 52/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2120 - val_loss: 0.2396\n",
      "Epoch 53/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2084 - val_loss: 0.2168\n",
      "Epoch 54/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2056 - val_loss: 0.2082\n",
      "Epoch 55/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2082 - val_loss: 0.2955\n",
      "Epoch 56/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2183 - val_loss: 0.2464\n",
      "Epoch 57/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2110 - val_loss: 0.2140\n",
      "Epoch 58/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2118 - val_loss: 0.2174\n",
      "Epoch 59/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1995 - val_loss: 0.3295\n",
      "Epoch 60/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2161 - val_loss: 0.2279\n",
      "\n",
      "RMSE for validation 0.4508477777863255\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.443 m/s as root mean\n",
      "Wind MAE:  0.331 m/s in avg\n",
      "Wind MAPE:  4.332 %\n",
      "Power RMSE:  252.533 kW as root mean\n",
      "Power MAE:  168.481 kW in avg\n",
      "Power MAPE:  15.462 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.471 m/s as root mean\n",
      "Wind MAE:  0.348 m/s in avg\n",
      "Wind MAPE:  4.528 %\n",
      "Power RMSE:  272.618 kW as root mean\n",
      "Power MAE:  177.957 kW in avg\n",
      "Power MAPE:  11.349 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c49a245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 30,\n",
    "    'learning_rate':0.003,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41de0a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 5.9258 - val_loss: 0.5395\n",
      "Epoch 2/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.4059\n",
      "Epoch 3/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3965 - val_loss: 0.3218\n",
      "Epoch 4/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3492 - val_loss: 0.3010\n",
      "Epoch 5/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3237 - val_loss: 0.2904\n",
      "Epoch 6/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3106 - val_loss: 0.2919\n",
      "Epoch 7/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3047 - val_loss: 0.3316\n",
      "Epoch 8/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2851 - val_loss: 0.2684\n",
      "Epoch 9/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3017 - val_loss: 0.2874\n",
      "Epoch 10/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2927 - val_loss: 0.2774\n",
      "Epoch 11/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2799 - val_loss: 0.2970\n",
      "Epoch 12/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2888 - val_loss: 0.3528\n",
      "Epoch 13/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2695 - val_loss: 0.2654\n",
      "Epoch 14/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2680 - val_loss: 0.2586\n",
      "Epoch 15/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2612 - val_loss: 0.2448\n",
      "Epoch 16/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.2716\n",
      "Epoch 17/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2639 - val_loss: 0.2825\n",
      "Epoch 18/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2728 - val_loss: 0.2548\n",
      "Epoch 19/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2581 - val_loss: 0.4648\n",
      "Epoch 20/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2678 - val_loss: 0.2848\n",
      "Epoch 21/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2564 - val_loss: 0.2810\n",
      "Epoch 22/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2737 - val_loss: 0.2275\n",
      "Epoch 23/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2504 - val_loss: 0.2347\n",
      "Epoch 24/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2389 - val_loss: 0.2481\n",
      "Epoch 25/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2431 - val_loss: 0.3339\n",
      "Epoch 26/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2597 - val_loss: 0.2278\n",
      "Epoch 27/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2370 - val_loss: 0.2376\n",
      "Epoch 28/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2416 - val_loss: 0.2252\n",
      "Epoch 29/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2447 - val_loss: 0.3268\n",
      "Epoch 30/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2406 - val_loss: 0.3582\n",
      "Epoch 31/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2416 - val_loss: 0.2412\n",
      "Epoch 32/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2324 - val_loss: 0.2489\n",
      "Epoch 33/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2329 - val_loss: 0.2270\n",
      "Epoch 34/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2499 - val_loss: 0.4431\n",
      "Epoch 35/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2484 - val_loss: 0.2248\n",
      "Epoch 36/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2257 - val_loss: 0.3508\n",
      "Epoch 37/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2337 - val_loss: 0.4177\n",
      "Epoch 38/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2523 - val_loss: 0.2577\n",
      "Epoch 39/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2292 - val_loss: 0.5625\n",
      "Epoch 40/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2502 - val_loss: 0.2608\n",
      "Epoch 41/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2182 - val_loss: 0.3106\n",
      "Epoch 42/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2278 - val_loss: 0.2111\n",
      "Epoch 43/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2312 - val_loss: 0.2709\n",
      "Epoch 44/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2400 - val_loss: 0.2509\n",
      "Epoch 45/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.2204 - val_loss: 0.3341\n",
      "Epoch 46/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2253 - val_loss: 0.2273\n",
      "Epoch 47/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2180 - val_loss: 0.2220\n",
      "Epoch 48/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2271 - val_loss: 0.2286\n",
      "Epoch 49/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2290 - val_loss: 0.2188\n",
      "Epoch 50/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2208 - val_loss: 0.2371\n",
      "Epoch 51/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2240 - val_loss: 0.2745\n",
      "Epoch 52/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2253 - val_loss: 0.2473\n",
      "\n",
      "RMSE for validation 0.45945338349532205\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.45 m/s as root mean\n",
      "Wind MAE:  0.337 m/s in avg\n",
      "Wind MAPE:  4.459 %\n",
      "Power RMSE:  257.389 kW as root mean\n",
      "Power MAE:  172.545 kW in avg\n",
      "Power MAPE:  15.868 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.479 m/s as root mean\n",
      "Wind MAE:  0.353 m/s in avg\n",
      "Wind MAPE:  4.655 %\n",
      "Power RMSE:  277.622 kW as root mean\n",
      "Power MAE:  180.606 kW in avg\n",
      "Power MAPE:  11.803 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb2d2b",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8524f1c",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'selu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c207f",
   "metadata": {},
   "source": [
    "MAPE power: 11.723 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1f39b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WTG18_ANN1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f749c",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'selu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b0ff8",
   "metadata": {},
   "source": [
    "MAPE power: 11.349%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab98c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WTG18_ANN2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9efcd",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8abcc",
   "metadata": {},
   "source": [
    "MAPE power: 11.016%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87134b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WTG18_ANN3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a46ffb",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ffdeaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('WTG18_ANN3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd3e3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.386 m/s as root mean\n",
      "Wind MAE:  0.289 m/s in avg\n",
      "Wind MAPE:  3.854 %\n",
      "Power RMSE:  227.309 kW as root mean\n",
      "Power MAE:  150.04 kW in avg\n",
      "Power MAPE:  13.567 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.438 m/s as root mean\n",
      "Wind MAE:  0.325 m/s in avg\n",
      "Wind MAPE:  4.314 %\n",
      "Power RMSE:  255.622 kW as root mean\n",
      "Power MAE:  167.087 kW in avg\n",
      "Power MAPE:  11.016 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "WS_pred=model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54850f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ANN_WTG18.csv saved in \\Results_ folder\n"
     ]
    }
   ],
   "source": [
    "WS_pred=pd.DataFrame(WS_pred)\n",
    "save(WS_pred,'\\Results_','ANN_WTG18.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99bf60",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18076b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 105 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673636d3315b48469723e17e2d38a5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAI0CAYAAABvZkF8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABeEUlEQVR4nO3deXxM9/4/8FdiSGyNSkgUDTVJdCHIdJZMgiRVa+xaqi2lgqYklqLX189SVxUVUqGtuqg2V2vtFaqKcDOSixkhUolGqIuQWIIMJpkk5/eHOteQjU5mkpzX8/HwkPmcM+d8zjuTmdd8zuYgCIIAIiIikiRHe3eAiIiI7IdBgIiISMIYBIiIiCSMQYCIiEjCGASIiIgkjEGAiIhIwiQXBBITE+3dhRrnt99+s3cXahzW1PpYU+tjTa3PHjWVXBBwcnKydxdqHJPJZO8u1DisqfWxptbHmlqfPWoquSBARERE/8MgQEREJGEMAkRERBLGIEBERCRhDAJEREQSxiBAREQkYQwCREREEsYgQEREJGEMAkRERBLGIEBERCRhDAJEREQSxiBAREQkYQwCREREEsYgQEREJGEOgiAI9u6ELTksKbR3F4iIiEolTJXZdH0cESAiIpIwBgEiIiIJYxAgIiKSMJsEgYiICCxfvtyiLTw8HCqVCnl5eWJbcnIyAgMDYTQasXDhQvTo0QMBAQHo27cvoqOjUVBQ8Niy4+Pj8e6771b6NhAREdVENgkCarUaycnJ4uN79+7h5MmTkMvlSEpKEtv1ej0UCgUWL16Mq1evIjY2FjqdDjExMdDr9Vi2bJk4b2FhIdavX4+ZM2dCYsc7EhERWY3NgkB6ejpMJhMA4MiRI/Dx8UFISAh0Op04n16vh7+/P06dOoXOnTujcePGAICWLVti8uTJeOaZZ8R5Fy5ciEOHDmH48OG22AQiIqIaySZBoHXr1nB1dUVKSgoAQKfTQavVwt/fH4mJiSguLkZ+fj5SU1Oh0WjQrVs3LF26FIsWLcKBAwdw48YNdOjQAePGjROXOXbsWHz99dd4/vnnbbEJRERENZLNDhZ8ePdAYmIi/P394ePjA5lMhlOnTuHkyZNwd3dHixYtEBYWhtmzZ+PKlSuYM2cOXn/9dYwePRqnT58Wl9ekSRNbdZ2IiKjGstlVC9RqNbZs2YIzZ85AEAR4e3sDADQaDQ4fPgyz2Qx/f39x/uDgYAQHB6O4uBgZGRlYt24dJkyYgB07dsDJyclW3SYiIrIpg8Fg9WX6+fmVOs1mQUCpVGL+/PnQ6XQWH/harRbbt29HQUEBRo4ciZycHAwYMAAbN25Ey5Yt4ejoCB8fH8yYMQMhISG4du0amjdvbqtuExER2VRZH9qVwWa7BlxcXODp6YmtW7daBAG1Wo2MjAxkZmaiU6dOaNq0Kdq1a4cFCxbg3LlzAIDc3FysW7cOXl5eaNasma26TEREVOPZ9IJCGo0GOTk5UKlUYluDBg3g6emJl156Cc7OzgCAJUuWQC6XIyIiAgEBARg8eDCuX7+O6OhoODryGkhERETWwpsOERERVSG86RARERHZDIMAERGRhDEIEBERSZhtd0RUAfqgEzY/NaOmMxgMrKmVsabWx5paH2tqffevIVBDTx8kIiKiqodBgIiISMIYBIiIiCSMQYCIiEjCGASIiIgkjEGAiIhIwhgEiIiIJExy1xFQxPsC8bzfgHWxptbHmlqDra/ZTlQdcUSAiIhIwhgEiIiIJIxBgIiISMKeOAhERERg+fLlFm3h4eFQqVTIy8sT25KTkxEYGAij0YiFCxeiR48eCAgIQN++fREdHY2CggIAQFZWFhQKBe7evWuxzLt370KhUCArK+tptouIiIgq4ImDgFqtRnJysvj43r17OHnyJORyOZKSksR2vV4PhUKBxYsX4+rVq4iNjYVOp0NMTAz0ej2WLVtmlQ0gIiKip/dUQSA9PR0mkwkAcOTIEfj4+CAkJAQ6nU6cT6/Xw9/fH6dOnULnzp3RuHFjAEDLli0xefJkPPPMM0+03rS0NISFhaFLly4YNGgQduzYIU4LDQ3F3//+d4SEhODTTz990k0iIiKSrCc+t6Z169ZwdXVFSkoKlEoldDodtFot1Go1YmNjUVxcDLPZjNTUVMyaNQu5ublYunQpTp8+DaVSifbt26NDhw7o0KGDxXJ79epV6jpzc3Mxfvx4jBs3DitXrkR6ejoiIiLQuHFjaLVaAMCVK1ewc+dOFBbylCsiIqKKeqqTbB/sHlAqlUhMTERUVBS8vLwgk8lw6tQpmEwmuLu7o0WLFggLC4NcLkdcXBzmzJkDo9EIX19fTJs2DT4+PuIyd+3ahXr16omP7969i86dOwMADh48CHd3dwwdOhQA8Morr2DAgAGIi4sTg0BwcDCcnZ2fuhBEVPPcv7d76Y/pr2NNra8yaurn51fqtKcOAlu2bMGZM2cgCAK8vb0BABqNBocPH4bZbIa/v784f3BwMIKDg1FcXIyMjAysW7cOEyZMsBjeL0tubi6aNWtm0ebh4WFxrIKrq+vTbAoR1WAPv/kZDIYy3wzpybGm1mePmj7V6YNKpRJpaWnQ6XQWH/harRbJyck4duwY/P39kZOTA61WiwsXLtxfmaMjfHx8MGPGDNy4cQPXrl2r0Po8PDweO3sgKytLPO4AABwcHJ5mU4iIiCTtqYKAi4sLPD09sXXrVosgoFarkZGRgczMTHTq1AlNmzZFu3btsGDBApw7dw7A/W/369atg5eX12Pf8kuj1Wpx48YNbNy4EYWFhUhNTcX27dvRs2fPp+k+ERER/empLyik0WiQk5MDlUoltjVo0ACenp546aWXxP31S5YsgVwuR0REBAICAjB48GBcv34d0dHRcHSs2OqfeeYZfPHFF9i7dy9CQkIwc+ZMfPjhhwgODn7a7hMREREAB0EQBHt3wpYclvCsAiKpePimQ9yfbX2sqfVVm2MEiIiIqGZgECAiIpIwBgEiIiIJe6rrCFRn+qAT3KdlZdxPaH2sKRHZCkcEiIiIJIxBgIiISMIYBIiIiCSMQYCIiEjCGASIiIgkjEGAiIhIwiR3+qAi3heI52WGrevpa/rwJWCJiMj2OCJAREQkYQwCREREEsYgQEREJGGVGgQiIiKwfPlyi7bw8HCoVCrk5eWJbcnJyQgMDITRaMTChQvRo0cPBAQEoG/fvoiOjkZBQQEAICsrCwqFAnfv3rVY5t27d6FQKJCVlVWZm0NERFTjVGoQUKvVSE5OFh/fu3cPJ0+ehFwuR1JSktiu1+uhUCiwePFiXL16FbGxsdDpdIiJiYFer8eyZcsqs5tERESSVelBID09HSaTCQBw5MgR+Pj4ICQkBDqdTpxPr9fD398fp06dQufOndG4cWMAQMuWLTF58mQ888wzldlNIiIiyarUc7dat24NV1dXpKSkQKlUQqfTQavVQq1WIzY2FsXFxTCbzUhNTcWsWbOQm5uLpUuX4vTp01AqlWjfvj06dOiADh06WCy3V69eldltIiIiyaj0k7gf7B5QKpVITExEVFQUvLy8IJPJcOrUKZhMJri7u6NFixYICwuDXC5HXFwc5syZA6PRCF9fX0ybNg0+Pj7iMnft2oV69eqJj+/evYvOnTtX9qYQERHVODYJAlu2bMGZM2cgCAK8vb0BABqNBocPH4bZbIa/v784f3BwMIKDg1FcXIyMjAysW7cOEyZMwI4dOyq7q2QHBoPB3l2oslgb62NNrY81tb7KqKmfn1+p0yo9CCiVSsyfPx86nc7iA1+r1WL79u0oKCjAyJEjkZOTgwEDBmDjxo1o2bIlHB0d4ePjgxkzZiAkJATXrl2Dg4NDZXeXbKysF6eUGQwG1sbKWFPrY02tzx41rfTrCLi4uMDT0xNbt261CAJqtRoZGRnIzMxEp06d0LRpU7Rr1w4LFizAuXPnAAC5ublYt24dvLy80KxZs8ruKhERkeTY5IJCGo0GOTk5UKlUYluDBg3g6emJl156Cc7OzgCAJUuWQC6XIyIiAgEBARg8eDCuX7+O6OhoODry2kdERETW5iAIgmDvTtiSwxLecKgq4U2HSsYhV+tjTa2PNbW+GrlrgIiIiKouBgEiIiIJYxAgIiKSMMntoNUHneA+LSvjfkIiouqLIwJEREQSxiBAREQkYQwCREREEsYgQEREJGEMAkRERBLGIEBERCRhDAJEREQSJrnrCCjifYF43m/Aup6spry/ABFR1cERASIiIgljECAiIpIwBgEiIiIJs0kQiIiIwPLlyy3awsPDoVKpkJeXJ7YlJycjMDAQRqMRCxcuRI8ePRAQEIC+ffsiOjoaBQUFjy377Nmz0Gq1OHPmTKVvBxERUU1jkyCgVquRnJwsPr537x5OnjwJuVyOpKQksV2v10OhUGDx4sW4evUqYmNjodPpEBMTA71ej2XLllkst7CwELNnz0Z+fr4tNoOIiKjGsVkQSE9Ph8lkAgAcOXIEPj4+CAkJgU6nE+fT6/Xw9/fHqVOn0LlzZzRu3BgA0LJlS0yePBnPPPOMxXJXrVqFV1991RabQEREVCPZJAi0bt0arq6uSElJAQDodDpotVr4+/sjMTERxcXFyM/PR2pqKjQaDbp164alS5di0aJFOHDgAG7cuIEOHTpg3Lhx4jKTk5ORlJSE8ePH22ITiIiIaiSbndD9YPeAUqlEYmIioqKi4OXlBZlMhlOnTsFkMsHd3R0tWrRAWFgY5HI54uLiMGfOHBiNRvj6+mLatGnw8fGB0WjEJ598goULF6J27dq22gSyEoPBYO8uVAusk/WxptbHmlpfZdTUz8+v1Gk2DQJbtmzBmTNnIAgCvL29AQAajQaHDx+G2WyGv7+/OH9wcDCCg4NRXFyMjIwMrFu3DhMmTMCOHTuwePFihIaGisug6qWsFyTdZzAYWCcrY02tjzW1PnvU1GanDyqVSqSlpUGn01l84Gu1WiQnJ+PYsWPw9/dHTk4OtFotLly4cL+Djo7w8fHBjBkzcOPGDVy7dg179+7F+vXr0bVrV3Tt2hUAMHr0aOzevdtWm0NERFQj2CwIuLi4wNPTE1u3brUIAmq1GhkZGcjMzESnTp3QtGlTtGvXDgsWLMC5c+cAALm5uVi3bh28vLzQrFkzHDp0CAcOHBD/AcCaNWvQo0cPW20OERFRjWDTCwppNBrk5ORApVKJbQ0aNICnpydeeuklODs7AwCWLFkCuVyOiIgIBAQEYPDgwbh+/Tqio6Ph6MhrIBEREVmLgyAIgr07YUsOS3jDIXvjTYfKx32v1seaWh9ran01+hgBIiIiqnoYBIiIiCSMQYCIiEjCJLezVh90gvu0rIz7CYmIqi+OCBAREUkYgwAREZGEMQgQERFJGIMAERGRhDEIEBERSRiDABERkYRJ7vRBRbwvEF9zLzPMy/cSEdGT4IgAERGRhDEIEBERSRiDABERkYQxCBAREUmY3YPArFmzoFarcfXqVbFtx44dUCqVCAwMRGBgIAICAjBs2DBs3769xGWkpqaiR48eNuoxERFRzWHXQ8xv376NQ4cO4bXXXsOWLVswbtw4cZqPjw82bNgAACguLsbRo0cxc+ZMFBYWYvDgwQAAQRDwr3/9C1FRUahVq5ZdtoGIiKg6s+uIwM6dO9GxY0cMGTIE27Ztg9lsLnE+R0dHqFQqREZG4quvvkJxcTEA4B//+Ac2btyIUaNG2bLbRERENYZdg8C2bdvQt29f+Pr64tlnn8XevXvLnF+j0SA3Nxfnz58HAPTr1w+xsbF46aWXbNFdIiKiGsduuwZOnDgBo9GIgIAAAMCgQYPw448/omfPnqU+x8XFBQBgNBoBAG5ubpXf0WrGYDBIar01GWtqfayp9bGm1lcZNfXz8yt1mt2CwLZt23Dz5k306tULAFBYWIhbt24hLS2t1OfcvHkTAODh4WGLLlZLZf2yK4vBYLDLemsy1tT6WFPrY02tzx41tUsQMBqN2Lt3L1auXIkWLVqI7Z9//jl++OGHUouQmJgINzc3jgQQERFZiV2OEdi5cydatmyJDh06iB/sbm5u6NevH/bs2SN+83+gqKgIhw4dQkxMDMaPHw8HBwd7dJuIiKjGscuIwPbt29G9e/fH2pVKJRo1aoTCwkKcPn0agYGBAIDatWujRYsWmDx5conPIyIioqdjlyDwz3/+s8R2R0dH7Nq1CwDw3nvvVXh5CoUC+/bts0rfiIiIpMTuVxYkIiIi+2EQICIikjAGASIiIgmz670G7EEfdILnvRIREf2JIwJEREQSxiBAREQkYQwCREREEsYgQEREJGEMAkRERBLGIEBERCRhkjt9UBHvC8QX2rsbEKZKrvRERFQFcUSAiIhIwhgEiIiIJIxBgIiISMKq9I7qiRMnIjk5GQBQUFAABwcH1K5dGwDQs2dP+Pv7Y9WqVbhy5Qrc3d0xfvx4BAUF2bPLRERE1UqVDgLR0dHiz9OmTUObNm0wduxYAMD58+fx7rvvYsmSJVAoFDh8+DA++ugjbNiwAa1atbJTj4mIiKqXartr4PLly+jfvz9effVVODg4QK1Ww9PTE6mpqfbuGhERUbVRpUcEyqJWq6FWq8XHFy9exNmzZ+Ht7W3HXhEREVUv1XZE4GFXr15FREQE+vTpwyBARET0BKrtiMAD6enpmDx5MgICAjBjxgx7d6fCDAaDvbtgVTVte6oC1tT6WFPrY02trzJq6ufnV+q0ah0EEhMT8fHHH2PMmDF4++237d2dJ1LWL6W6MRgMNWp7qgLW1PpYU+tjTa3PHjWttkEgMzMT06ZNw6xZs9C9e3d7d4eIiKhaqrbHCGzcuBH5+fmYP38+AgMDxX9bt261d9eIiIiqjWozIrBo0SKLxzNnzsTMmTPt1BsiIqKaodqOCBAREdFfxyBAREQkYQwCREREElZtjhGwFn3QCZ7uQkRE9CeOCBAREUkYgwAREZGEMQgQERFJGIMAERGRhDEIEBERSRiDABERkYQxCBAREUmY5K4joIj3BeIL7bZ+YarkSk5ERFUYRwSIiIgkjEGAiIhIwhgEiIiIJMwmO6wjIiLwwgsvICIiQmwLDw+HXq/H3r170bBhQwBAcnIyJk6cCC8vL6SlpUEmu989mUwGX19fTJgwAW3atHls+UuWLIFMJkNkZKQtNoeIiKjGsMmIgFqtRnJysvj43r17OHnyJORyOZKSksR2vV4PhUIhfqgnJCQgISEBcXFx8PHxQVhYGLKzs8X5b968iTlz5mDjxo222AwiIqIax2ZBID09HSaTCQBw5MgR+Pj4ICQkBDqdTpxPr9fD39//sefXr18f48ePh1wuR2xsrNj+/vvvo1atWggODq78jSAiIqqBbBIEWrduDVdXV6SkpAAAdDodtFot/P39kZiYiOLiYuTn5yM1NRUajabU5Wg0Ghw/flx8vGrVKsyaNQv16tWr7E0gIiKqkWx2UvuD3QNKpRKJiYmIioqCl5cXZDIZTp06BZPJBHd3d7Ro0aLUZbi4uMBoNIqPmzRpYouuW5XBYLB3FypFTd0ue2JNrY81tT7W1Poqo6Z+fn6lTrNpENiyZQvOnDkDQRDg7e0N4P63/MOHD8NsNpe4W+BhN2/ehIeHhy26W2nK+mVUVwaDoUZulz2xptbHmlofa2p99qipzU4fVCqVSEtLg06ns/jA12q1SE5OxrFjx8oNAklJSXjxxRcru6tERESSYbMg4OLiAk9PT2zdutXiA1+tViMjIwOZmZno1KlTic81Go2IiYnB+fPnMXToUFt1mYiIqMaz6YXvNRoN1q9fD5VKJbY1aNAAnp6ecHJygrOzs9i+bNkyrFixAg4ODqhXrx46duyI1atXw83NzZZdJiIiqtFsGgTGjx+P8ePHP9b+9ddfl/m4PHPmzPkr3SIiIpIsXmKYiIhIwhgEiIiIJIxBgIiISMJseoxAVaAPOsHzXomIiP7EEQEiIiIJYxAgIiKSMAYBIiIiCWMQICIikjAGASIiIgljECAiIpIwyZ0+qIj3BeILbbY+YarkSkxERNUIRwSIiIgkjEGAiIhIwhgEiIiIJIxBgIiISMLKDAIRERFYvny5RVt4eDhUKhXy8vLEtuTkZAQGBmLUqFHQaDQIDAxEYGAggoKCEBkZiczMzAp1Rq/XIyQkpNTpgYGBOHfuXIWWRUREROUrMwio1WokJyeLj+/du4eTJ09CLpcjKSlJbNfr9VAoFJDJZIiMjERCQgISEhIQFxcHHx8fhIWFITs7+y93NiEhAa1bt/7LyyEiIqL7yg0C6enpMJlMAIAjR47Ax8cHISEh0Ol04nx6vR7+/v6PPb9+/foYP3485HI5YmNjK9QhQRCwfPlydOvWDYMHD8bevXvFaQqFAmfOnEFWVha6du2KdevWoXv37ujWrRs+//zzCi2fiIiI/qfMINC6dWu4uroiJSUFAKDT6aDVauHv74/ExEQUFxcjPz8fqamp0Gg0pS5Ho9Hg+PHjFerQ7du3AQA7d+7E1KlT8f/+3//DH3/88dh8RqMRWVlZ2LFjB5YuXYrNmzeL/SQiIqKKKfdqNw92DyiVSiQmJiIqKgpeXl6QyWQ4deoUTCYT3N3d0aJFi1KX4eLiAqPRWKEO1atXDx988AFq164NtVoNjUaDvXv34v33339s3hEjRqBOnTpo164dWrVqhf/+979o3759hdZjKwaDwd5dsAmpbKctsabWx5paH2tqfZVRUz8/v1KnVSgIbNmyBWfOnIEgCPD29gZw/1v+4cOHYTabS9wt8LCbN2/Cw8OjQp11c3ND7dq1xcdNmzbFtWvXSpz32Wef/d+GyGQQBKFC67ClsopfUxgMBklspy2xptbHmlofa2p99qhpuacPKpVKpKWlQafTWXzga7VaJCcn49ixY+UGgaSkJLz44osV6lBubi6KiorEx1euXKlwiCAiIqInU24QcHFxgaenJ7Zu3Wrxga9Wq5GRkYHMzEx06tSpxOcajUbExMTg/PnzGDp0aIU6lJeXhzVr1qCgoAAJCQkwGAzo0aNHBTeHiIiInkSF7oij0Wiwfv16qFQqsa1Bgwbw9PSEk5MTnJ2dxfZly5ZhxYoVcHBwQL169dCxY0esXr0abm5uFepQy5YtkZOTg9deew3NmjXD4sWLOSJARERUSRyEqrhjvRI5LLHdnQcBadx9kPsJrY81tT7W1PpYU+urkscIEBERUc1l06+rUVFR2Lp1a6nTExISbNgbIiIismkQmDRpEiZNmmTLVT5GH3SCQ1lERER/4q4BIiIiCWMQICIikjAGASIiIgljECAiIpIwBgEiIiIJYxAgIiKSMAYBIiIiCav51799hCLeF4iv/MsMS+HSwkREVP1xRICIiEjCGASIiIgkjEGAiIhIwmwSBCIiIrB8+XKLtvDwcKhUKuTl5YltycnJCAwMhNFoxMKFC9GjRw8EBASgb9++iI6ORkFBgTjvDz/8gNDQUAQGBuLdd99FcnKyLTaFiIioRrFJEFCr1RYf1Pfu3cPJkychl8uRlJQktuv1eigUCixevBhXr15FbGwsdDodYmJioNfrsWzZMgDA4cOHsWbNGnzxxRdISEjAwIEDMXXqVBQXF9tic4iIiGoMmwWB9PR0mEwmAMCRI0fg4+ODkJAQ6HQ6cT69Xg9/f3+cOnUKnTt3RuPGjQEALVu2xOTJk/HMM88AAFQqFbZv345WrVrh9u3buHnzJlxcXODoyD0dRERET8Im57i1bt0arq6uSElJgVKphE6ng1arhVqtRmxsLIqLi2E2m5GamopZs2YhNzcXS5cuxenTp6FUKtG+fXt06NABHTp0EJdZr1496PV6jB8/HjKZDIsWLbLFphAREdUoDoIgCLZY0SeffIKmTZti7Nix6N27N6KiouDl5YWePXtiyZIlMJlMWLBgAbZu3QoA2L9/P+Li4nDs2DEYjUb4+vpi2rRp8PHxEZdpNpvh4OCAffv2Yd68efj+++/RqlWrMvvhsKTyryEAAPqgEzZZDxERUXn8/PxKnWazq96o1Wps2bIFZ86cgSAI8Pb2BgBoNBocPnwYZrMZ/v7+4vzBwcEIDg5GcXExMjIysG7dOkyYMAE7duyAk5MTAKB27doAgO7du2PLli3Q6XTlBgFbKavoNY3BYJDU9toCa2p9rKn1sabWZ4+a2mynulKpRFpaGnQ6ncUHvlarRXJyMo4dOwZ/f3/k5ORAq9XiwoUL9zvo6AgfHx/MmDEDN27cwLVr17Bt2zbMnj3bYvlmsxkNGza01eYQERHVCDYLAi4uLvD09MTWrVstgoBarUZGRgYyMzPRqVMnNG3aFO3atcOCBQtw7tw5AEBubi7WrVsHLy8vNGvWDO3atcO+fftw5MgRFBUVYfv27bh48SI6d+5sq80hIiKqEWx6QXyNRoP169dDpVKJbQ0aNICnpyecnJzg7OwMAFiyZAm++uorRERE4MaNG3BycoJWq0V0dDQcHR0hl8vxySefiKcZent7IyYmBs8++6wtN4eIiKjas9nBglWFrQ4WlNJNh7if0PpYU+tjTa2PNbW+Gn2MABEREVU9DAJEREQSxiBAREQkYdLZkf0nfdAJ7tMiIiL6E0cEiIiIJIxBgIiISMIYBIiIiCSMQYCIiEjCGASIiIgkjEGAiIhIwiR3+qAi3heIf/rLDEvp0sFERFTzcUSAiIhIwhgEiIiIJIxBgIiISMIYBIiIiCTMLke+KRQKODk5wdHxfg4RBAFNmjTBiBEj0L9/fwBAWFgYQkJC8Oabb1o8d9q0aWjTpg3Gjh2LwsJCLF++HHv27IHZbIavry+mT58ODw8PW28SERFRtWS3EYH169cjISEBCQkJOHjwIMLCwrBgwQKcO3euwstYs2YNfvvtN8TGxuLnn39GkyZNMHPmzErsNRERUc1SJXYN1KpVCz179kT9+vWRmZlZ4eeZTCa8//77cHV1hZOTE9544w2kpqaiuLi4EntLRERUc1SJk+LNZjM2bdoEs9mMdu3aie3R0dFYtWqVxbwmkwlt2rQBAERERFhMO3jwINq0aSPuciAiIqKy2S0IjB49GsD9EAAAGo0GX375Jdzd3cV5Jk6cWOIxAiXZs2cP1q5di+XLl1dSj+8zGAyVuvzqinWxPtbU+lhT62NNra8yaurn51fqNLsFgTVr1kAul+PSpUv46KOP0KhRI7z88stPtax169Zh7dq1WLRoUZkbaw2VvfzqyGAwsC5WxppaH2tqfayp9dmjpnYfQ2/evDk+//xz7N+/H//4xz+e6LnFxcWYP38+Nm/ejNWrV8Pf37+SeklERFQz2T0IAECzZs0wefJkrF69GhkZGRV+3urVq3H06FGsW7cO3t7eldhDIiKimqlKHCwIAKGhodi9ezfmzZuHdevWlTt/YWEhNmzYgMLCQgwYMMBi2p49e1C3bt1K6ikREVHNYZcgoNfrS2yPiYkRf/76669LnGfRokXizzqdzrodIyIikpgqsWuAiIiI7INBgIiISMIYBIiIiCSsyhwsaCv6oBM875WIiOhPHBEgIiKSMAYBIiIiCWMQICIikjAGASIiIgljECAiIpIwBgEiIiIJk9zpg4p4XyC+8KmeK0yVXLmIiKiG44gAERGRhDEIEBERSRiDABERkYRVm53eEydORHJyMgCgoKAADg4OqF27NgCgZ8+eSEpKwrRp0xAYGGjPbhIREVUr1SYIREdHiz9PmzYNbdq0wdixY8W20NBQe3SLiIioWuOuASIiIgljECAiIpKwarNroCowGAz27kKVxdpYH2tqfayp9bGm1lcZNfXz8yt1GoPAEyirkFJmMBhYGytjTa2PNbU+1tT67FFT7hogIiKSMAYBIiIiCWMQICIikrBqeYzAokWLHmvbsWOHHXpCRERUvXFEgIiISMIYBIiIiCSMQYCIiEjCquUxAn+FPugEz3slIiL6E0cEiIiIJIxBgIiISMIYBIiIiCSMQYCIiEjCGASIiIgkjEGAiIhIwiR3+qAi3heIL3zi5wlTJVcqIiKSAI4IEBERSRiDABERkYQxCBAREUkYgwAREZGE2eUIOIVCAScnJzg63s8hgiCgSZMmGDFiBPr37w8ACAsLQ0hICN58802L506bNg1t2rTB2LFjxbbi4mJMmzYNr7766mPzExERUensdij8+vXrIZfLAQBFRUXYs2cPZs+eDV9fX7Ru3brCy7ly5Qo+/fRTHDp0CK+++mpldZeIiKhGqhK7BmrVqoWePXuifv36yMzMrPDzzGYzhg8fDrlcjvbt21diD4mIiGqmKnFyvNlsxqZNm2A2m9GuXTuxPTo6GqtWrbKY12QyoU2bNgDuB4gffvgBbm5uCAsLs2mfiYiIagK7BYHRo0cDuB8CAECj0eDLL7+Eu7u7OM/EiRNLPEbgAUdHR7i5udmgt4DBYLDJeqor1sf6WFPrY02tjzW1vsqoqZ+fX6nT7BYE1qxZA7lcjkuXLuGjjz5Co0aN8PLLL9urO+Uqq4hSZzAYWB8rY02tjzW1PtbU+uxRU7sfI9C8eXN8/vnn2L9/P/7xj3/YuztERESSYvcgAADNmjXD5MmTsXr1amRkZNi7O0RERJJRJYIAAISGhsLPzw/z5s1DUVGRvbtDREQkCXY5RkCv15fYHhMTI/789ddflzjPokWLSmwvbX4iIiIqXZUZESAiIiLbYxAgIiKSMAYBIiIiCasSVxa0JX3QCZ73SkRE9CeOCBAREUkYgwAREZGEMQgQERFJGIMAERGRhDEIEBERSRiDABERkYRJ7vRBRbwvEF/4RM8RpkquTEREJBEcESAiIpIwBgEiIiIJYxAgIiKSMLvs/FYoFHBycoKjoyMcHBzg4OCAdu3aITIyEnK5HHq9HuPGjUPdunUtnvfCCy9gypQpaN++PQDg+PHjiIqKwh9//IFGjRrh3XffxaBBg+yxSURERNWS3Y6CW79+PeRyOQCgsLAQK1asQEREBP71r38BAFxcXLBv3z5xfpPJhOjoaMyYMQM7duzAnTt3MHnyZHz00Ufo3r07fv/9d3zwwQdo0aIFVCqVXbaJiIiouqkSuwZkMhlCQ0ORnZ2NvLy8EudxdnZGv379kJOTg7y8PFy+fBlarRY9e/aEo6Mj2rZtCz8/P6SkpNi490RERNVXlQgCt2/fxsaNG9GmTRs0atSoxHny8vLw7bffwsvLC40aNYKPjw8++eQTi2UcP34cXl5eNuo1ERFR9We3XQOjR4+Gg4MDAKBOnTp4+eWXsWjRInH67du30bVrVxQXF8NsNqNevXoICgpCdHT0Y8syGo2YNGkSXnzxRXTu3Nlm20BERFTd2S0IrFmzRjxGoCTPPPOMeIyAXq/Hxx9/jFdeeQVNmjSxmO/SpUuYNGkSmjdvjk8//RSOjtYf5DAYDFZfZk3DGlkfa2p9rKn1sabWVxk19fPzK3VatbhknkKhwMyZMzF9+nS0bNlS3KD09HRMmDABPXv2RGRkZKWEAKDsAtL9Fy1rZF2sqfWxptbHmlqfPWpaJY4RqIiuXbuiZ8+emDdvHu7du4fr169jwoQJGD58OCZPnlxpIYCIiKgmq1afnpMmTYLJZMLKlSvx008/ITc3F2vWrEFgYKD4LyYmxt7dJCIiqjbssmtAr9eXOV2hUFhcQ+ABFxcX/PLLL+LjUaNGWb1vREREUlKtRgSIiIjIuhgEiIiIJIxBgIiISMKqxemD1qQPOsHTXYiIiP7EEQEiIiIJYxAgIiKSMAYBIiIiCWMQICIikjAGASIiIgljECAiIpIwBgEiIiIJk9x1BBTxvkB8YYXmFaZKrjxERCQxHBEgIiKSMAYBIiIiCWMQICIikrAnDgIRERFYvny5RVt4eDhUKhXy8vLEtuTkZAQGBmLUqFHQaDQIDAxEYGAggoKCEBkZiczMTADA5cuXoVQqkZ6e/ti6jh49ii5duuDu3btP2k0iIiKqgCcOAmq1GsnJyeLje/fu4eTJk5DL5UhKShLb9Xo9FAoFZDIZIiMjkZCQgISEBMTFxcHHxwdhYWHIzs5Gs2bNoFarERcX99i6/vWvf6FHjx6oV6/eU24eERERleWpgkB6ejpMJhMA4MiRI/Dx8UFISAh0Op04n16vh7+//2PPr1+/PsaPHw+5XI7Y2FgAwIABA7B7924UFv7vaH6j0Yj9+/dj0KBBKCoqwurVqxEaGopu3bph7ty5MBqNAIAdO3bg/fffx4gRIxASEoILFy486SYRERFJ1hMHgdatW8PV1RUpKSkAAJ1OB61WC39/fyQmJqK4uBj5+flITU2FRqMpdTkajQbHjx8HAAQGBkImk1kEid27d8Pb2xve3t74/vvvER8fj9WrV2P79u0wmUxYvHixOO+JEycQHh6On376CS1btnzSTSIiIpKspzpR/sHuAaVSicTERERFRcHLywsymQynTp2CyWSCu7s7WrRoUeoyXFxcxG/1MpkMffv2xc6dO9G1a1cA93cLvPHGGwCAn376CR9++CE8PDwAABMnTkS/fv3wt7/9DQDg5uYGpVL5NJtSJoPBYPVl1lSslfWxptbHmlofa2p9lVFTPz+/Uqc9dRDYsmULzpw5A0EQ4O3tDeD+t/zDhw/DbDaXuFvgYTdv3hQ/2AGgf//+GDJkCG7duoWrV6/i4sWLeO211wAAV65cwezZszF37tz/dVwmw5UrVwAArq6uT7MZ5SqrcPQ/BoOBtbIy1tT6WFPrY02tzx41faogoFQqMX/+fOh0OosPfK1Wi+3bt6OgoAAjR44scxlJSUlo3769+Pi5555Dp06dsGfPHly4cAG9e/eGs7MzgPvf+P/v//4Pr776KgCgsLAQFy9eRIsWLZCSkgIHB4en2QwiIiLJe6rrCLi4uMDT0xNbt261CAJqtRoZGRnIzMxEp06dSnyu0WhETEwMzp8/j6FDh1pMGzBgAPbs2YO9e/di0KBBYnufPn2wevVqXLt2DYWFhVi5ciUmTpwIQRCepvtERET0p6e+mL5Go8H69euhUqnEtgYNGsDT0xNOTk7it3kAWLZsGVasWAEHBwfUq1cPHTt2xOrVq+Hm5maxzM6dO2PRokXw9PREq1atxPb33nsPZrMZI0eORF5eHtq2bYtly5ZBJuO9AIiIiP4KB0FiX6sdllTshkMAbzpUUdxPaH2sqfWxptbHmlqfPWrKSwwTERFJGIMAERGRhDEIEBERSZjkdoLrg05wnxYREdGfOCJAREQkYQwCREREEsYgQEREJGEMAkRERBLGIEBERCRhDAJEREQSJrnTBxXxvkB8+ZcZ5uWFiYhICjgiQEREJGEMAkRERBLGIEBERCRhDAJEREQSZpMj4iIiIvDCCy8gIiJCbAsPD4der8fevXvRsGFDAEBycjImTpwILy8vpKWlQSa73z2ZTAZfX19MmDABbdq0AQAUFBRg6dKl2Lt3L8xmM/z8/DBjxgw0bdrUFptERERUI9hkRECtViM5OVl8fO/ePZw8eRJyuRxJSUliu16vh0KhgEwmQ2RkJBISEpCQkIC4uDj4+PggLCwM2dnZAIBvvvkGZ8+exZYtW7B37164uLhg8eLFttgcIiKiGsNmQSA9PR0mkwkAcOTIEfj4+CAkJAQ6nU6cT6/Xw9/f/7Hn169fH+PHj4dcLkdsbCwAYOzYsYiOjoaLiwuuX7+OO3fuoFGjRrbYHCIiohrDJkGgdevWcHV1RUpKCgBAp9NBq9XC398fiYmJKC4uRn5+PlJTU6HRaEpdjkajwfHjxwEAtWrVgrOzM7766iuEhoYiNTUVI0aMsMXmEBER1Rg2u2rOg90DSqUSiYmJiIqKgpeXF2QyGU6dOgWTyQR3d3e0aNGi1GW4uLjAaDRatI0cORIjRozAihUrMGHCBGzatEk8tuCvMBgMf3kZUsJ6WR9ran2sqfWxptZXGTX18/MrdZpNg8CWLVtw5swZCIIAb29vAPe/5R8+fBhms7nE3QIPu3nzJjw8PCzanJycANw/IHHz5s04c+YM2rZt+5f7W1bRyJLBYGC9rIw1tT7W1PpYU+uzR01tdvqgUqlEWloadDqdxQe+VqtFcnIyjh07Vm4QSEpKwosvvggAmDt3LjZv3ixOKyoqgiAIaNCgQeVsABERUQ1ksyDg4uICT09PbN261eIDX61WIyMjA5mZmejUqVOJzzUajYiJicH58+cxdOhQAMDLL7+MDRs2ICsrCyaTCUuWLEGHDh3K3LVARERElmx6Zx2NRoP169dDpVKJbQ0aNICnpyecnJzg7Owsti9btgwrVqyAg4MD6tWrh44dO2L16tVwc3MDAAwaNAi5ubkYPXo0zGYz1Go1PvvsM1tuDhERUbXnIAiCYO9O2JLDkvLvPAjw7oNPgvsJrY81tT7W1PpYU+ur0ccIEBERUdXDIEBERCRhkhv/1ged4FAWERHRnzgiQEREJGEMAkRERBLGIEBERCRhDAJEREQSxiBAREQkYQwCREREEsYgQEREJGGSu46AIt4XiC/9MsO8tDAREUkJRwSIiIgkjEGAiIhIwhgEiIiIJMwmQSAiIgLLly+3aAsPD4dKpUJeXp7YlpycjMDAQIwaNQoajQaBgYEIDAxEUFAQIiMjkZmZWeLyf/rpJ4SEhFTqNhAREdVENgkCarUaycnJ4uN79+7h5MmTkMvlSEpKEtv1ej0UCgVkMhkiIyORkJCAhIQExMXFwcfHB2FhYcjOzrZY9sWLFxEVFWWLzSAiIqpxbBYE0tPTYTKZAABHjhyBj48PQkJCoNPpxPn0ej38/f0fe379+vUxfvx4yOVyxMbGiu1FRUWYPXs2BgwYUPkbQUREVAPZJAi0bt0arq6uSElJAQDodDpotVr4+/sjMTERxcXFyM/PR2pqKjQaTanL0Wg0OH78uPh43bp1eOGFF6DVait7E4iIiGokm500/2D3gFKpRGJiIqKiouDl5QWZTIZTp07BZDLB3d0dLVq0KHUZLi4uMBqNAIC0tDTs2rULGzZswKlTp6zWT4PBYLVlSQnrZn2sqfWxptbHmlpfZdTUz8+v1Gk2DQJbtmzBmTNnIAgCvL29Adz/ln/48GGYzeYSdws87ObNm/Dw8IDJZMLs2bMxa9Ys1KtXz6r9LKtYVDKDwcC6WRlran2sqfWxptZnj5ra7PRBpVKJtLQ06HQ6iw98rVaL5ORkHDt2rNwgkJSUhBdffBFpaWm4dOkSIiMj0bVrV0yaNAm3b99G165dceXKlcreFCIiohrDZiMCLi4u8PT0xNatWxEZGSm2q9VqLF68GIWFhejUqVOJzzUajVi/fj3Onz+PBQsWwM3NDYcOHRKn6/V6TJ8+Hfv27avszSAiIqpRbHphfY1Gg/Xr10OlUoltDRo0gKenJ5ycnODs7Cy2L1u2DCtWrICDgwPq1auHjh07YvXq1XBzc7Nll4mIiGo0mwaB8ePHY/z48Y+1f/3112U+Lo9CoeBoABER0VPgJYaJiIgkjEGAiIhIwhgEiIiIJMymxwhUBfqgEzzvlYiI6E8cESAiIpIwBgEiIiIJYxAgIiKSMAYBIiIiCWMQICIikjAGASIiIgmT3OmDinhfIL6wxGnCVMmVg4iIJI4jAkRERBLGIEBERCRhDAJEREQSxiBAREQkYTY/Ok6hUMDJyQmOjvcziCAIaNKkCUaMGIH+/fuX+/wFCxbAxcUF4eHhldxTIiKims8uh8mvX78ecrkcAFBUVIQ9e/Zg9uzZ8PX1RevWrct87t/+9jdbdJGIiEgS7L5roFatWujZsyfq16+PzMxMAEB6ejo++OADdO/eHVqtFuHh4bh+/ToAYM6cOVi2bBkAICwsDCtXrsRbb72FLl26ICwsDFlZWfbaFCIiomrH7kHAbDYjNjYWZrMZ7dq1AwDMmDEDnTt3xu7du7Fz504YjUb8+OOPJT7/l19+weLFi7Fz504IgoC1a9fasvtERETVml12DYwePRrA/RAAABqNBl9++SXc3d0BACtWrMBzzz0Hk8mEnJwcNGrUCDk5OSUuq1evXmjevDkAoGvXrkhISHjqfhkMhqd+rtSxdtbHmlofa2p9rKn1VUZN/fz8Sp1mlyCwZs0ayOVyXLp0CR999BEaNWqEl19+WZyempqKiRMn4u7du5DL5bh9+zaeffbZEpfVqFEj8WeZTIbi4uKn7ldZhaLSGQwG1s7KWFPrY02tjzW1PnvU1K7X1G3evDk+//xzvPXWW3juuecwevRoZGdnY/bs2VizZg1eeeUVAMDcuXMhCII9u0pERFQj2f0YgWbNmmHy5MlYvXo1MjIycO/ePQCAs7MzBEHAoUOHsG/fPhQWlnx/ACIiInp6VeIuO6Ghodi9ezfmzZuHdevW4f3338e4ceNQVFSE1q1bY+DAgTh69Ki9u0lERFTjOAgSG3N3WFL6yALvPvh0uJ/Q+lhT62NNrY81tT571NTuuwaIiIjIfhgEiIiIJIxBgIiISMIkt1NcH3SC+7SIiIj+xBEBIiIiCWMQICIikjAGASIiIgljECAiIpIwBgEiIiIJYxAgIiKSMMmdPqiI9wXiS77MMC8xTEREUsMRASIiIgljECAiIpIwBgEiIiIJs3sQmDVrFtRqNa5evSq27dixA0qlEoGBgQgMDERAQACGDRuG7du3Wzz3+PHjGDFiBLp06YJ+/fphy5YtNu49ERFR9WbXo+Nu376NQ4cO4bXXXsOWLVswbtw4cZqPjw82bNgAACguLsbRo0cxc+ZMFBYWYvDgwbh9+zYmT56Mjz76CN27d8fvv/+ODz74AC1atIBKpbLXJhEREVUrdh0R2LlzJzp27IghQ4Zg27ZtMJvNJc7n6OgIlUqFyMhIfPXVVyguLsbly5eh1WrRs2dPODo6om3btvDz80NKSoqNt4KIiKj6smsQ2LZtG/r27QtfX188++yz2Lt3b5nzazQa5Obm4vz58/Dx8cEnn3wiTrt9+zaOHz8OLy+vyu42ERFRjWG3IHDixAkYjUYEBAQAAAYNGoQff/yxzOe4uLgAAIxGo0W70WjEpEmT8OKLL6Jz586V02EiIqIayG7HCGzbtg03b95Er169AACFhYW4desW0tLSSn3OzZs3AQAeHh5i26VLlzBp0iQ0b94cn376KRwdnz7bGAyGp36u1LF21seaWh9ran2sqfVVRk39/PxKnWaXIGA0GrF3716sXLkSLVq0ENs///xz/PDDD6V2ODExEW5ubnBzcwMApKenY8KECejZsyciIyP/UggAyi4Ulc5gMLB2VsaaWh9ran2sqfXZo6Z2CQI7d+5Ey5Yt0aFDB4v2fv36YfLkyWjTpo1Fe1FREf7zn/8gJiYGH3zwARwcHHD9+nVMmDABw4cPx8iRI23XeSIiohrELkFg+/bt6N69+2PtSqUSjRo1QmFhIU6fPo3AwEAAQO3atdGiRQtMnjxZfN5PP/2E3NxcrFmzBmvWrBGXMXToUISHh9tmQ4iIiKo5uwSBf/7znyW2Ozo6YteuXQCA9957r8xljBo1CqNGjbJ634iIiKTE7lcWJCIiIvthECAiIpIwBgEiIiIJs+u9BuxBH3SCp7sQERH9iSMCREREEsYgQEREJGEMAkRERBLGIEBERCRhDAJEREQSxiBAREQkYQwCREREEia56wgo4n2B+EKLNmGq5MpAREQEgCMCREREksYgQEREJGEMAkRERBL2REEgIiICy5cvt2gLDw+HSqVCXl6e2JacnIzAwECMGjUKGo0GgYGBCAwMRFBQECIjI5GZmSnOu2PHDrzzzjuPrSshIQGhoaFPuj1ERET0BJ4oCKjVaiQnJ4uP7927h5MnT0IulyMpKUls1+v1UCgUkMlkiIyMREJCAhISEhAXFwcfHx+EhYUhOzvbeltBRERET+WJg0B6ejpMJhMA4MiRI/Dx8UFISAh0Op04n16vh7+//2PPr1+/PsaPHw+5XI7Y2Ngn6uju3bsxZMgQdOnSBaNGjUJqaioAICsrC126dMGcOXPQtWtX7Nq164mWS0REJGVPdN5c69at4erqipSUFCiVSuh0Omi1WqjVasTGxqK4uBhmsxmpqamYNWsWfv311xKXo9FoEB8fLz7+/fff0bVrV4t5ioqK0KhRIwBAUlISPv30U0RFRaF9+/bYuXMnPvzwQ2zevBkAcOfOHTRr1gx79uxBcXHxk2wSERGRpD3xCfQPdg8olUokJiYiKioKXl5ekMlkOHXqFEwmE9zd3dGiRYtSl+Hi4gKj0Sg+9vb2xoYNGyzmSUhIwKJFiwAAu3btQu/evdGpUycAQL9+/bB9+3YcOHBAHHno2bMn6tSp86SbAwAwGAxP9Tz6H9bQ+lhT62NNrY81tb7KqKmfn1+p054qCGzZsgVnzpyBIAjw9vYGcP9b/uHDh2E2m0vcLfCwmzdvwsPDo8LrzM3NFdfzgIeHB3JycsTHrq6uT7AVlsoqEJXPYDCwhlbGmlofa2p9rKn12aOmT3z6oFKpRFpaGnQ6ncUHvlarRXJyMo4dO1ZuEEhKSsKLL75Y4XV6eHggKyvLoi0rKwuNGzcWHzs4OFR4eURERHTfEwcBFxcXeHp6YuvWrRYf+Gq1GhkZGcjMzBSH8B9lNBoRExOD8+fPY+jQoRVeZ+/evbFr1y4cO3YMhYWF+Omnn3D27NnHjisgIiKiJ/NUF9nXaDRYv349VCqV2NagQQN4enrCyckJzs7OYvuyZcuwYsUKODg4oF69eujYsSNWr14NNze3Cq+vY8eO+Pjjj/Hpp5/iypUraN26NaKjo0scKSAiIqKKcxAEQbB3J2zJYUnhY2286dBfw/2E1seaWh9ran2sqfVVi2MEiIiIqOZgECAiIpIwBgEiIiIJk9zOcX3QCe7TIiIi+hNHBIiIiCSMQYCIiEjCGASIiIgkjEGAiIhIwhgEiIiIJIxBgIiISMIkd/qgIt4XiLe8zDAvMUxERFLFEQEiIiIJYxAgIiKSMAYBIiIiCatyQcBkMuH69ev27gYREZEkVLkgMGbMGJw6deqJnxcSEgK9Xl8JPSIiIqq5qlwQuHnzpr27QEREJBlV6ry5qVOn4sqVK5gxYwYmTJgAQRCwceNG3L59Gy+99BI++ugjtGrVCgCwe/durFq1Cjdv3sSgQYPs23EiIqJqqkqNCCxZsgQeHh5YuHAh6tSpgw0bNmDJkiXYs2cPfH19ERERAZPJhIyMDHzyySeYNWsW9u7dCwcHB9y6dcve3SciIqp2qtSIwMN27dqFt956C15eXgCA999/H9u2bcOxY8eQkpICf39/KBQKAMC4cePw448/PvW6DAaDVfosZayh9bGm1seaWh9ran2VUVM/P79Sp1XZIHDjxg14eHiIjx0dHeHu7o6cnBxcv34dTZo0EafVrl0bbm5uT72usgpE5TMYDKyhlbGm1seaWh9ran32qGmV2jXwMA8PD1y+fFl8XFxcjCtXrqBx48Zwc3OzmFZYWIgbN27Yo5tERETVWpUbEahduzbu3LmDPn36YMWKFdBoNPD09MTatWsBAK+++iqef/55fPvtt0hISIBGo8E333yDO3fuWL0vDksKy5/pL+A9DoiIyN6q3IhAnz59MH/+fGRlZWH48OGYMmUKQkJCcOzYMcTExKBu3bpo1aoV/v73vyMqKgpBQUG4evUqWrZsae+uV6qioiKsXbsWAwcORL9+/dCrVy8sXrwYBQUFAIAZM2ZgzZo1ldqHP/74A8OHD0evXr0wePBgZGZmVur6iIio8lW5r6SjRo3CqFGjxMfDhw8vcb6uXbuia9euNuqV/c2ZMwe3bt3C+vXr0bBhQ9y9exdTp07FzJkzsXjxYpv0YerUqRgxYgRCQ0Nx8OBBREREYMeOHTZZNxERVY4qFwTocRcvXsSOHTug0+nQoEEDAEC9evUwd+5cHDt27LH5N2/ejB9++AFmsxm3bt3CmDFj8NZbb+Hq1auYPn06cnNzAQBdunRBZGRkqe0Py87OxtmzZ9G7d29xnrlz5z7VVSCJiKjqqHK7Buhxv/32G+RyuRgCHmjSpAm6d+9u0Xbnzh1s2rQJX3/9NbZv346oqChxxODHH39EixYtsG3bNnz//fc4f/488vLySm1/2OXLl9G0aVM4Ov7vJePu7o4rV65U0lYTEZEtSG5EQB90otqd7uLo6Iji4uIKzVu/fn18+eWXOHjwIP744w+kp6fj7t27AIDAwECEhYXh8uXL8Pf3x5QpU9CwYcNS2x9WXFwMBwcHizZBEFCrVi3rbCQREdkFRwSqgfbt2+Ps2bMwGo0W7dnZ2QgLC4PJZBLbrly5gv79++PSpUvw8/OzGOJv37499u3bhzfffBOXLl3CkCFDkJqaWmr7w5577jlcvXoVgiCIbTk5ORbXeiAiouqHQaAacHd3R2hoKP72t7+JYcBoNGLOnDlo1KgRnJ2dxXlTU1PRuHFjfPDBBwgICEB8fDyA+2cdLFmyBCtXrsRrr72GmTNnQi6XIyMjo9T2h3l4eOD555/Hrl27AAAJCQlwdHSEt7e3japARESVQXK7Bqqr2bNnY+XKlRg6dChq1aqFgoICvPbaa5gwYYLFfFqtFps3b0aPHj3g4OAApVKJxo0b4/z58xgxYgRmzJiBPn36oE6dOvDx8UHv3r1x69atEtsftXTpUsyaNQurVq1CnTp1sHz5cotjBoiIqPpxEB4e65UAXhLT+lhT62NNrY81tT7W1Pp4iWEiIiKyKQYBIiIiCWMQICIikjAGASIiIgljECAiIpIwBgEiIiIJYxAgIiKSMAYBIiIiCWMQICIikjAGASIiIgmT1L0GHlxNOT8/3849qXlYU+tjTa2PNbU+1tT6KqumderUeex28oDE7jWQn5//2O11iYiIpOCVV16Bk5PTY+2SCgKCIKCgoMDe3SAiIrI5jggQERHRY3iwIBERkYQxCBAREUkYgwAREZGEMQgQERFJGIMAERGRhNXYILB7924MGTIEAwYMwI8//vjY9NOnT+Odd97BwIED8cknn6CwsNAOvaxeyqvpgQMH8NZbb2HYsGGYMmUKbt++bYdeVi/l1fQBnU6Hvn372rBn1Vd5Nf3jjz8QFhaGYcOG4cMPP+TrtALKq2l6ejreffddDBs2DJGRkcjLy7NDL6sXo9GIN954A1lZWY9Ns/nnk1ADZWdnC6GhocLNmzeFu3fvCkOHDhUyMzMt5hkyZIiQkpIiCIIgzJ07V9i0aZM9ulptlFfTvLw8oXv37kJ2drYgCIKwatUqYfHixfbqbrVQkdepIAjCtWvXhEGDBgl9+vSxQy+rl/JqWlxcLAwYMEA4dOiQIAiCEB0dLSxfvtxe3a0WKvI6HT16tKDT6QRBEISlS5cKMTEx9uhqtXHy5EnhzTffFFQqlXDp0qXHptv686lGjggcOXIECoUCLi4uqFu3LkJCQrBv3z5x+uXLl5Gfn4927doBAEJDQ7F37157dbdaKK+mhYWFmD59Opo2bQoAkMvluHLlir26Wy2UV9MH5s+fjzFjxtihh9VPeTVNT09H3bp14e/vDwB477338MYbb9iru9VCRV6nxcXFuHPnDgDAZDKVePU6+p9t27Zh+vTpaNKkyWPT7PH5VCODwNWrV+Hm5iY+dnNzQ05OToWn0+PKq1mjRo0QFBQE4P4bwfr169G1a1dbd7NaqcjrcOPGjWjbtq34pkBlK6+mFy5cgKurK+bNm4fhw4dj4cKFqFu3rj26Wm1U5HU6adIk/P3vf0f37t1x+PBhDBo0yNbdrFZmzZqFjh07ljjNHp9PNTIIFBcXW1xGURAEi8flTafHVbRmRqMRkZGR8PLyQp8+fWzZxWqnvJqeOXMG+/fvx+jRo+3RvWqpvJoWFRXBYDBg8ODB+P7779G8eXNERUXZo6vVRnk1NZlM+OSTTxATE4NffvkFgwcPxuzZs+3R1RrBHp9PNTIIuLu749q1a+Lj69evWwzBlDedHleRml27dg3vv/8+vLy8MGvWLFt3sdopr6b79u3DtWvX8O677yIiIgJXr17F+++/b4+uVhvl1dTV1RXPP/88XnrpJQBA9+7d8dtvv9m8n9VJeTXNzMyEk5MTXnnlFQDAoEGDYDAYbN7PmsIen081MggolUocPXoUubm5MJlM2L9/PzQajTi9WbNmqFOnDo4fPw4A2LVrl7jPkEpWXk2LioowadIkvPbaa5gyZQpHWCqgvJqOHTsWW7duRWxsLJYvX44mTZrgm2++sWOPq77yatq+fXvk5ubi999/BwD8+9//Rtu2be3V3WqhvJq2bNkS2dnZ+OOPPwAABw8eFIMWPTl7fD7JKnXpdtK0aVN88MEHGDt2LAoLC9GvXz+88sormDhxIsaNG4eXXnoJ8+fPx/z583Hnzh20bdsWQ4cOtXe3q7TyapqdnY309HQUFRVh//79AIAXX3yRIwNlqMjrlJ5MRWq6ZMkSzJ8/HyaTCU2bNsW8efPs3e0qrSI1nT17Nj7++GMIgoDGjRtz18BTsOfnE+8+SEREJGE1ctcAERERVQyDABERkYQxCBAREUkYgwAREZGEMQgQUbV34cIFe3eh2rJW7arT76A69dUWGAQkbvz48Th9+jQAIDg4GBcvXgRw/94BS5cuRXBwMDp06IDAwED8v//3/3Dr1i3xuT4+PuL52A9TqVQ4fPiwRdumTZvg4+ODn3/+2aL94sWL8PHxQceOHcV/r776Kj788ENkZ2dbbTu3bt2KgQMH/uXlfPHFF/jiiy8AAHq9Hh9//HG5z3m4xjXFl19+iY8++sje3QAAfPfdd1i8eLG9u/FU7ty5Ax8fH/HvrizvvPMOvvvuO6uu31q1O3XqFIYNG2aFHlWOh1+v+/btw6RJk55qOfHx8QgODi53vsLCQrz99tu4cePGU63H1hgEJCwuLg6NGjWCj4/PY9NWrlyJw4cPY8OGDTh+/Dg2b96My5cvY/r06U+1rh9//BGDBw8u9Y1Mp9MhOTkZycnJ+Pe//406depg4sSJT7UuW1EoFMjLy8OhQ4dKnaesGldn48aNqzIfvrm5ufbuQrVlrdrl5eXBbDZbZVmV4eHX661bt1BcXFyp65PJZBg5ciQWLFhQqeuxFgYBO7h48SJUKhXWrl0LjUYDlUqFTZs24auvvoJarYZWq8WOHTvE+Y8ePYpBgwZBoVBgyJAhSElJEaclJSVh6NChUKvV6NSpEyZOnIh79+4BuP8NIioqCv369UOnTp3w9ttvi988BEHAypUrS03xJ0+ehL+/P5o3bw7g/mUvP/74Y7i7uz/x9qanp+O///0vPv74Y5w+fRrp6ellzl+3bl307du3xNGGKVOm4LPPPhMf3717Fx06dEBmZiZyc3MxZcoUBAcHw9fXF6GhoSVe6vTR0YFHv5U9uBe4QqFAaGgoDh48WGpf33jjDcTExJQ4raQaf/vttwgNDYWfnx/8/f3F0YWlS5daBB9BEBAcHIx///vfAIDY2Fi8/vrrUKlUCA8Px9WrVwEAhw8fRs+ePTFmzBgolUocPnwYp06dwsiRIxEQEABfX1+MGjVKvGSp0WjEpEmT4Ofnh169emHFihUW33D27NmDPn36QKFQYMSIETh37lyJ2/bFF1+I/Z0xYwYWLVqEoUOHokOHDnj77beRkpKCoUOHomPHjhg1ahSMRiOA+6/JRYsWoXv37ujYsSMmTJiAmzdvArh/zfo5c+agW7du6NChA15//XWLu6798ssv6N27Nzp27IjBgwcjNTUVv/zyC7766ivs3bsXgwcPLrGv69evR0hICF599VWMGjUKZ8+eFWsXGhqKTz/9FEqlEp07d8bq1atLXMbWrVsxbtw4zJgxAx07dsTrr7+Oo0ePYsqUKejYsSN69+4tvq4LCwuxbNkydO7cGSqVChMnTrQY3Vq3bh0CAgKgUqmwbt06i/VkZWVh3LhxUKlUeP3117Fly5YS+/OoQ4cOYeDAgejUqRP69etn8Zp9dORu4sSJ+OKLL0qsnY+PD77++mv4+/tDpVJh6dKl4ofmoyMS3333Hd555x1cv34dY8aMwc2bN9GxY8fHwsWTvt+V9jcC3B+F69u3LxQKBcLDwxEeHi5OL+v97sHrNSUlBbNnz0ZaWhq0Wi2A+yOh8fHx4jo+++wzzJgxAwCQn5+P//u//4Ofnx+Cg4MfG+ks6705ODgYR48eLfVvqEqp1JscU4kuXLggeHt7C5988olQUFAg/PDDD8KLL74oLFiwQCgoKBC+//57QalUCoIgCJcuXRI6duwo/Prrr4LZbBZ27dolKJVKITc3V7hz547QqVMnYe/evYIgCMLly5eFoKAg4ccffxQEQRDefvttISQkRPjvf/8r3L59W3jrrbeEWbNmCYIgCHq9XujSpYtFv4KCgoQLFy4IgiAIW7ZsEV555RVhxowZQlxcnHD58uXHtsPb21vo2LGj4OfnZ/HPx8dH+M9//iPON2fOHGHBggWCIAjCvHnzhJkzZz5WC6PRKLZlZ2cLY8eOFcaOHfvYOg8ePCh07dpVKC4uFgRBELZv3y4MHDhQEARB+Pjjj4XJkycL9+7dE/Lz84XZs2cLw4YNE7dnwIABj/0sCIJgNBoFb29v4cKFC0JeXp6g1WqF7777TjCbzcJ//vMfQaFQCGfPnhUE4f7966Ojo8Xnms1mi+kPe7TGR48eFTQajXDu3DnxsY+Pj/DHH38IZ86cEdq3by/W4ejRo4K/v79QWFgo7Nq1S+jSpYvw+++/CyaTSfj000+F4cOHC4IgCP/5z38Eb29vYfPmzcLdu3cFs9ksvPbaa8K3334rFBcXCzdu3BAGDx4sREVFCYIgCB999JHw/vvvC7dv3xbOnz8vdOvWTQgKChIEQRBOnDgh+Pn5CXq9XigoKBDWrl0rdOvWTSgoKHhs26Kjo4UJEyYIgiAI06dPF1QqlZCRkSEYjUahe/fuglarFc6cOSPcvHlTeP3114XvvvtOEIT7r0l/f38hLS1NyMvLE8LCwoTIyEhBEARhxYoVwttvvy3cvn1bKCwsFFatWiV07txZEARB+P3334V27doJBw8eFIqKioTvvvtO6NKli1BYWGjRl0dt3LhRCAwMFNLS0oT8/Hzhiy++EIKDg4V79+6JtYuJiRHMZrOwZ88eoW3btiW+1rds2SJ4e3sLO3fuFIqKioSpU6cKL730krB7924hPz9fmDJlitiHzz//XOjTp49w4cIF4e7du8LMmTOFN998UyguLhbi4+MFlUolpKWlCXfv3hWmTJkivvYKCwuF0NBQYcmSJUJ+fr6QlpYmaLVaISkpSazdhg0bHuvbg9r88ssvgtlsFg4cOCD4+voK6enpgiDc/zs9ffq0OP+ECRPE1/CjtfP29haGDRsmXL9+XTh//rwQFBQkxMbGlrj+DRs2CG+//bb4OnzwnvWoJ3m/K+tvJDc3V1AoFMKPP/4omM1mYdu2bYK3t7e4LWW93z28nY/+/QcFBQn79+8XHy9cuFCYPn26+PObb74pXL9+Xbh8+bLQp08f8e+lrPfmB+bOnSt8/vnnJdalKuGIgB299957qF27NtRqNYqKisTHgYGBuHnzJu7du4e4uDioVCq89tprkMlk6NmzJ7y9vfHLL7/AyckJ27ZtQ0hICPLy8pCTk4NGjRpZfPvo27cvWrZsiYYNG6Jbt27i9cD1ej3at29fat8GDhyIr7/+Gvn5+Zg/fz66dOmCvn37IikpyWK+jRs3Qq/XW/xzcXERp5tMJsTFxYn3fB86dCji4uIsjjUAgC5dukChUMDPzw+DBg1C/fr1MX/+/Mf6pdVqYTabcezYMQD3h9779esH4P6tUOfOnYtatWohKysLzzzzzBMfZ3Dw4EE0btwYw4cPh0wmE2u/bdu2EueXyWRo27Ytjh49+ti0R2v88ssvY+vWrWjVqhWuXbsGs9kMZ2dn5OTkoE2bNvDy8hLv8x4XF4c+ffqgVq1a2Lx5M0aOHAkvLy84OTlh8uTJOHHihPhNw8HBAaGhoahbty5kMhnWrFmD4cOH4969e8jOzsazzz6L7OxsFBQUYPfu3Zg8eTIaNmyI559/HqNGjRL7t3nzZvTv3x9+fn6oXbs2Ro4cicLCwse+BZUkKCgIcrkc9evXR7t27dClSxe0adMGLi4u8PX1xaVLl8R53377bbRt2xYNGjRAZGQkfv31VxQUFGD48OGIjo5GvXr1cPnyZdSvX1/8/f38888IDAxE586d4ejoiGHDhiEqKgpCORdG/emnnzBy5Ei0bdsWderUwQcffICCggIcOXIEAFCrVi2MGTMGMpkM3bp1Q7169Uo9kKx58+bo1asXHB0doVQq8dxzz6F79+6oU6cO1Go1srKyxHV++OGHaNGiBerWrYu//e1vOHnyJM6ePYtdu3ahX79+aNu2LerWrWtxnMXJkydx+fJlTJo0CXXq1BEvLbtp06Yyt3Hnzp3w9/fH66+/DplMhi5duiA4ONjiW/aTmDJlCho3boznn38e7777Lnbu3PlUy3lURd7vyvobOXDgAJ577jkMGTIEMpkM/fv3R4cOHSzWUdr73dP6+eefMWbMGDRu3BgeHh4YM2aMOK2s9+YHXnnlFfG1VpXVyHsNVBcPPjAdHe/nsYYNGwKAeMOe4uJiZGVlISEhAQqFQnxeYWEh/Pz8UKtWLezfvx/r168HcH9Y7969exZvjo0bNxZ/lslk4rQrV66Ue0crjUYj3lwkMzMT//znPzF27Fjs3bsXTZs2rdA27tq1C3l5eXj33XfFNpPJhM2bN1vcXvfgwYOoX79+ucurVasWQkNDsWvXLrRu3RpHjhzBwoULAQA5OTn4+9//jszMTLRu3RqNGjUq94PiUVlZWcjMzLSod1FREbp161bqc5o0aYIrV6481v5ojR0dHbFy5Ur88ssvcHV1Fe/W9mDotX///ti1axd69eqFX375BWvWrAEAXL58GcuWLcOKFSvEZTk4OCArKwsymQwuLi6oU6eOOC0lJQVjxowRd3ncunULjRs3xq1bt5Cfnw8PDw9x3ueee078+fLlyzh8+DC2b98utpnNZly+fLncuj0c/mrVqoVnnnnGYrsf/j14enqKP7u7u8NsNuPmzZvIz8/H3LlzkZKSgpYtW6Jly5bi865du2bRb0dHx1Lv5/6w69evW2yjo6MjmjVrhuzsbDz//PNo2LAhateuLU6XyWSl7j9u1KiRxTY++Ht9sNwHz3t0nfXq1RMD+rVr1yxucuTu7g6Z7P7bcFZWFoxGI5RKpTi9qKgIL7/8cpnbeOPGDYv1Afd/ryW9Jivi4d+Ph4eHuBvqr6rI+51MJiv1byQnJwfNmjWzWOaj213a+93TunbtmsXu0Ae7SgGU+d78QJMmTax60HNlYRCwo4rcoa9Jkybo1asXFi1aJLZduHABzz77LI4dO4aYmBhs2rQJrVq1AgCLD9zy1l3aG15RURFUKhWio6PFu161adMGM2fOxPbt23H27NkKB4Eff/wRU6dOFb+1A/fDwbfffov33nuvQst4VL9+/fD+++9DLpdDrVbD1dUVADB58mS8+eab+P777+Hg4IDt27eXeJyBo6OjxYFND/ZRA/fr3aFDB3z//fdi25UrV+Dk5FRqfwoLC8U3t4c9WuO1a9fi999/x969e9GwYUOYzWbs2rVLnN6rVy98/vnn+PXXX+Hq6iredKhJkyYYNWqUxT7wzMxMtGzZEsnJyRbrvHLlCqZPn47Y2Fj4+voCgMXNYOrUqYPLly/j2WefBQCLN6kmTZpg9OjRiIiIENv++OOPCh0X8iR3m8zJyRF/zsrKgrOzMxo1aoRx48ahTZs2+PLLLyGTyXD06FHxLBN3d3ekpaWJzxMEAYsXLy73tszPPfecxWjEg3D94DVTGR6ss127dgDuH4OSm5sLV1dXNG3aVBw5AO6HhsLCQgD3b+7j7u6OAwcOiNOvXbtW7odZs2bNxDvVPXDx4kUxOD36ei/vAMGcnBy4ubkBuP/7efDhW9bfTUVU5DVS1t+Ih4eHRe2A+6/3F1544Yn68aiytuvB7+tBIHn076W09+YHioqKSnxvqGqqfg8lrnfv3oiPj0dSUhIEQYDBYEDfvn1x8uRJGI1GODo6wtnZGUVFRdi+fTv0er34xlKWZs2alZr0a9WqhW7duuGzzz5DSkoKBEHA7du38e2338LZ2Vl8gytPRkYGTp48iYEDB6JJkybiv4EDB+Lq1asWb3hPom3btmjcuDG++uori4BhNBpRt25dODg4IDMzE6tXry7xSObWrVvj3LlzOHHiBPLz8/H111+Lb1Jdu3bF2bNnERcXh6KiImRmZmLIkCEWB6096urVqxbfVh94tMZGoxG1a9dG7dq1cefOHXz22Wcwm83i76tx48ZQq9X47LPP0LdvX/F5AwYMwNq1a3H+/HkUFxdjw4YNeOONN8SDQh92584dAICzszMEQcDBgwexe/dumM1m1KpVC/369cPy5cthNBpx6dIlrF271mI9mzZtwm+//QZBEPDrr7+iT58+FRoReBLfffcdLly4gLy8PCxbtgy9e/dGnTp1YDQa4ezsjFq1auHy5ctYvnw5gPujEj179sShQ4eQlJSE4uJixMbGYvfu3eJoyIODER/Vv39/rF+/HqdPn0ZBQQFWrlwJAFCr1VbdpkfXGRMTg0uXLuHevXv49NNPIZfL4e3tjX79+mHbtm3ia2/JkiXi83x9feHs7IxvvvkGZrMZV65cwXvvvWcRSkvSq1cvHD58GHv27EFRUREOHjyI/fv3o1evXgCAVq1aIS4uDmazGYcOHbIIDSXVLjo6GkajEefOncOGDRvQv39/cTl79+6F0WjEhQsX8K9//ctiOQUFBSgoKPhLtSvrbyQ4OBjZ2dnYsmULCgsLsXv3bnEX4ZOoU6cO7ty5IwasVq1a4eeff4bJZMKpU6fEu6cC93c1rFy5EtnZ2bh69arFwaRlvTc/UNp7Q1XDIFDFtWrVCsuWLcPixYvh5+eH6dOn4+OPP4ZGo0FAQAB69OiB0NBQ+Pv7Y8eOHRgwYAAyMzPLXa5Go3nsW8TD5s6di5CQEHz00Ufo1KmTeMTst99+W6EhfAD44YcfoFarLYbrgPtDgq+99lq5b3Bl6d+/P/Ly8iyOeJ83bx7WrFmDTp064cMPP8SAAQOQm5v72DcgX19fvPPOOxg/fjyCg4PRqlUrcdiyUaNG+Oabb/DPf/4TKpUK7733HoYNG4YhQ4aU2A+z2Yy0tDSL+7M/8GiN33vvPchkMmg0GnTv3h0FBQXo1KmTxe+rf//+yM7OtggC/fr1w5AhQzBmzBgoFAr89NNP+OqrryyG4x9o06YNxo8fjxEjRkCpVGLVqlUYOnSoeKT8tGnTUKdOHQQGBiIsLAwKhUIcGn/11VcxY8YMTJs2DZ06dcLy5cuxbNmyv/yN61EdOnTA+PHjERQUhCZNmmDmzJkA7o9cHDhwQDziu0uXLqhXrx4yMzPxwgsvYOnSpViwYAEUCgXi4uLw5ZdfolatWujatSt+//13dO/e/bF19evXD6NGjUJ4eDhUKhWOHDmCtWvXol69elbdpoeNGTMGwcHBeOuttxAQEIAbN26IYVOj0WD69OmYOHEitFotmjZtKu7WqV27Nr7++mscOXIEAQEBGDhwoHiWSFk8PT0RExODVatWQaFQYPHixfj888/F41NmzZoFnU4HpVKJ7777Dn369BGfW1LtWrRogd69e+Odd97BW2+9JQaBsLAw1KpVC507d8bEiRPFduD+bkm5XA6VSoXz588/de3K+htp0KABli9fjm+++QZKpRK7du1Cu3btLHbtVMSrr74q/p+fn48pU6bg4sWL0Gg0WLBggcUZReHh4VAoFOjTpw8GDRokjpACZb83P3DixIkS3xuqHNsfn0hVRc+ePYXk5GTx8cNnDVDJHj1rYP/+/cJbb71V6vyP1tjejhw5Ity9e1d8/P333wtvvvmmzdZf2pHvVDU8eoZBVXL9+nXh5MmTFm2DBw8WNm7caKcelc1sNguBgYHiGRBVGUcEJCw8PPwvfSun++f3l/WNrarV+Msvv8TKlStRVFSEnJwc/PDDDwgICLB3t4jKVVBQgHfeeQe//fYbAODAgQNIT0+v1N08f8WePXugUqnE47eqMgYBCevduzfy8vLKvcAPlUyv1+PZZ5+1GC58VFWr8Zw5c/Dbb79BpVKhX79+UCqVCAsLs3e3iMrl4eGBefPmYfLkyejYsSOWLFmCpUuXWpzlUFUUFhZiw4YN4oWJqjoHQfiL51cQERFRtcURASIiIgljECAiIpIwBgEiIiIJYxAgIiKSMAYBIiIiCWMQICIikrD/Dx9GpncKc8cTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x684 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance through SHAP values performed\n"
     ]
    }
   ],
   "source": [
    "shap_values=feature_importance (X_train, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4e3fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=transform_shap (shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ee9108f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WSHor', 'WDHor', 'WSVer', 'WDVer', 'T1', 'RH1',\n",
       "       'T2', 'RH2', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WD1', 'WD3', 'WD4',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d622497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>SHAP_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WS1</td>\n",
       "      <td>1.002406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WS3</td>\n",
       "      <td>0.059724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WS4</td>\n",
       "      <td>0.228772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSHor</td>\n",
       "      <td>0.593045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WDHor</td>\n",
       "      <td>0.010074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WSVer</td>\n",
       "      <td>0.006019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WDVer</td>\n",
       "      <td>0.023776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.009568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RH1</td>\n",
       "      <td>0.031315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.079024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RH2</td>\n",
       "      <td>0.037318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PR1</td>\n",
       "      <td>0.003846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AD1</td>\n",
       "      <td>0.130607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PR2</td>\n",
       "      <td>0.028675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AD2</td>\n",
       "      <td>0.014858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rain</td>\n",
       "      <td>0.016316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WD1</td>\n",
       "      <td>0.074263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WD3</td>\n",
       "      <td>0.021817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WD4</td>\n",
       "      <td>0.017385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TI</td>\n",
       "      <td>0.033174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WSH</td>\n",
       "      <td>0.234042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WD_bin</td>\n",
       "      <td>0.063878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tod</td>\n",
       "      <td>0.009679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WVeer</td>\n",
       "      <td>0.008532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables  SHAP_abs\n",
       "0        WS1  1.002406\n",
       "1        WS3  0.059724\n",
       "2        WS4  0.228772\n",
       "3      WSHor  0.593045\n",
       "4      WDHor  0.010074\n",
       "5      WSVer  0.006019\n",
       "6      WDVer  0.023776\n",
       "7         T1  0.009568\n",
       "8        RH1  0.031315\n",
       "9         T2  0.079024\n",
       "10       RH2  0.037318\n",
       "11       PR1  0.003846\n",
       "12       AD1  0.130607\n",
       "13       PR2  0.028675\n",
       "14       AD2  0.014858\n",
       "15      Rain  0.016316\n",
       "16       WD1  0.074263\n",
       "17       WD3  0.021817\n",
       "18       WD4  0.017385\n",
       "19        TI  0.033174\n",
       "20       WSH  0.234042\n",
       "21    WD_bin  0.063878\n",
       "22       tod  0.009679\n",
       "23     WVeer  0.008532"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844a2df",
   "metadata": {},
   "source": [
    "## Dataset3- WTG20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "143791ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WSHor', 'WDHor', 'WSVer', 'WDVer', 'T1', 'RH1',\n",
       "       'T2', 'RH2', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WD1', 'WD3', 'WD4',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "X_train= uploading_csv('\\Dataset3-New_Site','\\X_train20.csv')\n",
    "X_test= uploading_csv('\\Dataset3-New_Site','\\X_test20.csv')\n",
    "y_train= uploading_csv('\\Dataset3-New_Site','\\y_train20.csv')\n",
    "y_test= uploading_csv('\\Dataset3-New_Site','\\y_test20.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e5ee809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c5bf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset3-New_Site','\\PC_V150.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca7797",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acf8d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4b969a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [ -0.23451791  -0.31686033 -18.29564063  -8.82532199  -9.66797177\n",
      "  -1.20539242  -0.25203056  -4.76907174  -0.24459523  -0.20385947\n",
      "  -0.210991    -0.19595151  -0.26079905          nan  -0.2019423\n",
      "  -0.2298398   -0.21434557  -0.20442386  -0.27653538  -0.24854774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Early Stopping', 'optimizer': 'Momentum', 'n_neurons': 90, 'n_hidden': 3, 'learning_rate': 0.003, 'input_shape': 24, 'activation': 'elu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.1959515114625295\n",
      "\n",
      "--- 14.987640595436096 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.414 m/s as root mean\n",
      "Wind MAE:  0.31 m/s in avg\n",
      "Wind MAPE:  4.154 %\n",
      "Power RMSE:  257.914 kW as root mean\n",
      "Power MAE:  174.309 kW in avg\n",
      "Power MAPE:  11.014 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.424 m/s as root mean\n",
      "Wind MAE:  0.315 m/s in avg\n",
      "Wind MAPE:  4.213 %\n",
      "Power RMSE:  266.874 kW as root mean\n",
      "Power MAE:  176.217 kW in avg\n",
      "Power MAPE:  11.086 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b0e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0313038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea99f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Early Stopping', 'optimizer': 'Nesterov', 'n_neurons': 40, 'n_hidden': 1, 'learning_rate': 0.01, 'input_shape': 24, 'activation': 'relu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.18890997767448425\n",
      "\n",
      "--- 15.593900048732758 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.468 m/s as root mean\n",
      "Wind MAE:  0.365 m/s in avg\n",
      "Wind MAPE:  4.917 %\n",
      "Power RMSE:  292.336 kW as root mean\n",
      "Power MAE:  204.671 kW in avg\n",
      "Power MAPE:  13.158 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.477 m/s as root mean\n",
      "Wind MAE:  0.37 m/s in avg\n",
      "Wind MAPE:  4.955 %\n",
      "Power RMSE:  297.591 kW as root mean\n",
      "Power MAE:  206.06 kW in avg\n",
      "Power MAPE:  13.108 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fdbd298",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c13bd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [-0.70918836 -0.21971244 -0.51799845 -0.20276275 -0.26355502 -0.82164464\n",
      " -0.22508243 -0.30415701 -0.2987563  -0.1947716          nan -3.41635327\n",
      " -0.23954858 -0.2338862  -4.76900228         nan -0.28551358 -0.25895362\n",
      " -0.64015321 -0.36292622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': None, 'optimizer': 'Momentum', 'n_neurons': 90, 'n_hidden': 2, 'learning_rate': 0.003, 'input_shape': 24, 'activation': 'selu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.19477159778277078\n",
      "\n",
      "--- 15.70096283753713 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.417 m/s as root mean\n",
      "Wind MAE:  0.314 m/s in avg\n",
      "Wind MAPE:  4.293 %\n",
      "Power RMSE:  253.676 kW as root mean\n",
      "Power MAE:  174.297 kW in avg\n",
      "Power MAPE:  11.681 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.424 m/s as root mean\n",
      "Wind MAE:  0.318 m/s in avg\n",
      "Wind MAPE:  4.312 %\n",
      "Power RMSE:  259.612 kW as root mean\n",
      "Power MAE:  175.708 kW in avg\n",
      "Power MAPE:  11.619 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9a321",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8676b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e58a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "93/93 [==============================] - 1s 7ms/step - loss: 8.3702 - val_loss: 0.9333\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.5058 - val_loss: 0.3612\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.3380 - val_loss: 0.3169\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.2979 - val_loss: 0.2852\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2886 - val_loss: 0.2668\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2717 - val_loss: 0.2585\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.2694 - val_loss: 0.2556\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.2547 - val_loss: 0.2492\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2540 - val_loss: 0.2299\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2399 - val_loss: 0.2283\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2375 - val_loss: 0.2330\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 1s 5ms/step - loss: 0.2403 - val_loss: 0.2235\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.2295 - val_loss: 0.2175\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.2300 - val_loss: 0.2199\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.2123 - val_loss: 0.2149\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.2187 - val_loss: 0.2285\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.2092 - val_loss: 0.1939\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.2031 - val_loss: 0.2219\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.2141 - val_loss: 0.1861\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.2016 - val_loss: 0.2104\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.2081 - val_loss: 0.2414\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.2046 - val_loss: 0.1867\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1925 - val_loss: 0.2068\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.2150\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.1958\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1967 - val_loss: 0.1999\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1952 - val_loss: 0.1776\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1906 - val_loss: 0.1759\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1991 - val_loss: 0.1780\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1878 - val_loss: 0.1805\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1836 - val_loss: 0.2032\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1970 - val_loss: 0.1725\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1803 - val_loss: 0.1748\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1770 - val_loss: 0.1870\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1840 - val_loss: 0.3123\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1986 - val_loss: 0.1681\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1796 - val_loss: 0.1947\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1876 - val_loss: 0.1690\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1745 - val_loss: 0.1709\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.1740\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1711 - val_loss: 0.1778\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1854 - val_loss: 0.1783\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1719 - val_loss: 0.1762\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.1891 - val_loss: 0.1639\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1749 - val_loss: 0.1887\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1619\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1700 - val_loss: 0.1620\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1956 - val_loss: 0.2458\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1905\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1759 - val_loss: 0.1667\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1726 - val_loss: 0.1827\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1811 - val_loss: 0.1584\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1662 - val_loss: 0.1637\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1745 - val_loss: 0.1642\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1724 - val_loss: 0.1923\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1681 - val_loss: 0.1675\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1687 - val_loss: 0.1772\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1747 - val_loss: 0.1885\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1711 - val_loss: 0.1613\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1654 - val_loss: 0.1564\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.1622 - val_loss: 0.1610\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 1s 7ms/step - loss: 0.1685 - val_loss: 0.1915\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.1603 - val_loss: 0.1835\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.1722 - val_loss: 0.1586\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.1614 - val_loss: 0.1725\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.1517\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1951\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1534 - val_loss: 0.1517\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.2152\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1649\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1624 - val_loss: 0.1479\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1687 - val_loss: 0.1826\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1580 - val_loss: 0.1571\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1644 - val_loss: 0.1584\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1610 - val_loss: 0.1691\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1616\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1527 - val_loss: 0.1596\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.1573 - val_loss: 0.1633\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1578 - val_loss: 0.1595\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.1584 - val_loss: 0.1634\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1565 - val_loss: 0.1542\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1433 - val_loss: 0.1638\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - ETA: 0s - loss: 0.148 - 0s 3ms/step - loss: 0.1485 - val_loss: 0.1580\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1489 - val_loss: 0.1532\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1451 - val_loss: 0.1560\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1570 - val_loss: 0.1576\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1580 - val_loss: 0.1480\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1482 - val_loss: 0.1522\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1543\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1449 - val_loss: 0.1856\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1600\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1498 - val_loss: 0.1583\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1394 - val_loss: 0.1457\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1430 - val_loss: 0.1519\n",
      "Epoch 95/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1441 - val_loss: 0.1604\n",
      "Epoch 96/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1593\n",
      "Epoch 97/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1422 - val_loss: 0.1539\n",
      "Epoch 98/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1414 - val_loss: 0.1471\n",
      "Epoch 99/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1485 - val_loss: 0.1599\n",
      "Epoch 100/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1422 - val_loss: 0.1544\n",
      "\n",
      "RMSE for validation 0.39292779459886323\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.366 m/s as root mean\n",
      "Wind MAE:  0.27 m/s in avg\n",
      "Wind MAPE:  3.519 %\n",
      "Power RMSE:  233.809 kW as root mean\n",
      "Power MAE:  154.766 kW in avg\n",
      "Power MAPE:  8.815 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.398 m/s as root mean\n",
      "Wind MAE:  0.291 m/s in avg\n",
      "Wind MAPE:  3.79 %\n",
      "Power RMSE:  247.327 kW as root mean\n",
      "Power MAE:  162.78 kW in avg\n",
      "Power MAPE:  9.429 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7a4eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8f12a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "93/93 [==============================] - 1s 10ms/step - loss: 7.2412 - val_loss: 0.4890\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.3653 - val_loss: 0.3331\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.3207 - val_loss: 0.2895\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.3025 - val_loss: 0.3034\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2822 - val_loss: 0.2660\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.2602 - val_loss: 0.2674\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.2515 - val_loss: 0.2369\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2444 - val_loss: 0.2616\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.2302 - val_loss: 0.2244\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.2237 - val_loss: 0.2208\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.2169 - val_loss: 0.2153\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2146 - val_loss: 0.2096\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2324 - val_loss: 0.1994\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.2090 - val_loss: 0.2058\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.2015 - val_loss: 0.1879\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.2081 - val_loss: 0.1888\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.2051 - val_loss: 0.2213\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.1998 - val_loss: 0.1836\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.1938 - val_loss: 0.1970\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.1858 - val_loss: 0.1808\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1891 - val_loss: 0.1919\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1878 - val_loss: 0.1762\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1847 - val_loss: 0.1817\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.1724\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1927 - val_loss: 0.1733\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1875\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1755 - val_loss: 0.2291\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1973 - val_loss: 0.2311\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 0s 5ms/step - loss: 0.1856 - val_loss: 0.1890\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 1s 5ms/step - loss: 0.1729 - val_loss: 0.2038\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 0.1766\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1734 - val_loss: 0.1883\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1732 - val_loss: 0.1693\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1736 - val_loss: 0.1652\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1775 - val_loss: 0.1855\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1753 - val_loss: 0.1669\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1717 - val_loss: 0.1568\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1783 - val_loss: 0.1632\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1745 - val_loss: 0.1667\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1638 - val_loss: 0.1622\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1848 - val_loss: 0.1702\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1692 - val_loss: 0.2060\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1664 - val_loss: 0.1557\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1535\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1600 - val_loss: 0.1773\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1585 - val_loss: 0.1758\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1642 - val_loss: 0.2034\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1589 - val_loss: 0.1921\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1675 - val_loss: 0.1551\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1582 - val_loss: 0.1540\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1679 - val_loss: 0.1591\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1661 - val_loss: 0.1502\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1497\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1641 - val_loss: 0.1630\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1523\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1572 - val_loss: 0.1612\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 0.1696\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.2005\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.2068\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1626 - val_loss: 0.1687\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1654 - val_loss: 0.1484\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1553 - val_loss: 0.1865\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1581 - val_loss: 0.1493\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1450 - val_loss: 0.1783\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1533\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1416 - val_loss: 0.1536\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.1590\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1532 - val_loss: 0.1534\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.2081\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1852\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1459\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1609\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.1394 - val_loss: 0.1843\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1390 - val_loss: 0.1599\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1379 - val_loss: 0.1558\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1410 - val_loss: 0.1669\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1507\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1371 - val_loss: 0.1509\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1442 - val_loss: 0.1561\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.1845\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1636\n",
      "\n",
      "RMSE for validation 0.38194353317831253\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.368 m/s as root mean\n",
      "Wind MAE:  0.272 m/s in avg\n",
      "Wind MAPE:  3.606 %\n",
      "Power RMSE:  232.67 kW as root mean\n",
      "Power MAE:  153.857 kW in avg\n",
      "Power MAPE:  9.241 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.395 m/s as root mean\n",
      "Wind MAE:  0.29 m/s in avg\n",
      "Wind MAPE:  3.829 %\n",
      "Power RMSE:  243.443 kW as root mean\n",
      "Power MAE:  160.638 kW in avg\n",
      "Power MAPE:  9.723 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d8e418",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e68dd",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c679f5f",
   "metadata": {},
   "source": [
    "MAPE power: 9.429%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce6c5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WTG20_ANN1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f90a76",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b580f",
   "metadata": {},
   "source": [
    "MAPE power: 9.723%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5132e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WTG20_ANN2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e998f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ad48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc041588",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec7bcf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "369fd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('WTG20_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a049d80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.366 m/s as root mean\n",
      "Wind MAE:  0.27 m/s in avg\n",
      "Wind MAPE:  3.519 %\n",
      "Power RMSE:  233.809 kW as root mean\n",
      "Power MAE:  154.766 kW in avg\n",
      "Power MAPE:  8.815 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.398 m/s as root mean\n",
      "Wind MAE:  0.291 m/s in avg\n",
      "Wind MAPE:  3.79 %\n",
      "Power RMSE:  247.327 kW as root mean\n",
      "Power MAE:  162.78 kW in avg\n",
      "Power MAPE:  9.429 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "WS_pred=model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad86b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ANN_WTG20.csv saved in \\Results_ folder\n"
     ]
    }
   ],
   "source": [
    "WS_pred=pd.DataFrame(WS_pred)\n",
    "save(WS_pred,'\\Results_','ANN_WTG20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577106b1",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ccaadba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928a62bbf52040f39f6a4bebe21a0f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x684 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance through SHAP values performed\n"
     ]
    }
   ],
   "source": [
    "shap_values=feature_importance (X_train, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a2bc171",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=transform_shap (shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11181317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>SHAP_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WS1</td>\n",
       "      <td>0.920147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WS3</td>\n",
       "      <td>0.133266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WS4</td>\n",
       "      <td>0.332131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSHor</td>\n",
       "      <td>0.594574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WDHor</td>\n",
       "      <td>0.104770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WSVer</td>\n",
       "      <td>0.010211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WDVer</td>\n",
       "      <td>0.007050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.076187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RH1</td>\n",
       "      <td>0.046897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.020094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RH2</td>\n",
       "      <td>0.011602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PR1</td>\n",
       "      <td>0.107139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AD1</td>\n",
       "      <td>0.073577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PR2</td>\n",
       "      <td>0.008654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AD2</td>\n",
       "      <td>0.102296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rain</td>\n",
       "      <td>0.035817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WD1</td>\n",
       "      <td>0.020265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WD3</td>\n",
       "      <td>0.029476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WD4</td>\n",
       "      <td>0.033437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TI</td>\n",
       "      <td>0.025863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WSH</td>\n",
       "      <td>0.242040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WD_bin</td>\n",
       "      <td>0.042347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tod</td>\n",
       "      <td>0.013890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WVeer</td>\n",
       "      <td>0.005984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables  SHAP_abs\n",
       "0        WS1  0.920147\n",
       "1        WS3  0.133266\n",
       "2        WS4  0.332131\n",
       "3      WSHor  0.594574\n",
       "4      WDHor  0.104770\n",
       "5      WSVer  0.010211\n",
       "6      WDVer  0.007050\n",
       "7         T1  0.076187\n",
       "8        RH1  0.046897\n",
       "9         T2  0.020094\n",
       "10       RH2  0.011602\n",
       "11       PR1  0.107139\n",
       "12       AD1  0.073577\n",
       "13       PR2  0.008654\n",
       "14       AD2  0.102296\n",
       "15      Rain  0.035817\n",
       "16       WD1  0.020265\n",
       "17       WD3  0.029476\n",
       "18       WD4  0.033437\n",
       "19        TI  0.025863\n",
       "20       WSH  0.242040\n",
       "21    WD_bin  0.042347\n",
       "22       tod  0.013890\n",
       "23     WVeer  0.005984"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754bb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "886f8e66",
   "metadata": {},
   "source": [
    "## Dataset3- WTG43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a242daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WSHor', 'WDHor', 'WSVer', 'WDVer', 'T1', 'RH1',\n",
       "       'T2', 'RH2', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WD1', 'WD3', 'WD4',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "X_train= uploading_csv('\\Dataset3-New_Site','\\X_train43.csv')\n",
    "X_test= uploading_csv('\\Dataset3-New_Site','\\X_test43.csv')\n",
    "y_train= uploading_csv('\\Dataset3-New_Site','\\y_train43.csv')\n",
    "y_test= uploading_csv('\\Dataset3-New_Site','\\y_test43.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43f87368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0d70110",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset3-New_Site','\\PC_V150.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab9e02",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8eba2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1cfb14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [ -0.36723889 -11.68513997  -0.50415119  -0.37086029  -0.30759893\n",
      "  -0.31647501  -0.63337992  -0.31210221 -12.65431945  -5.7615143\n",
      "  -1.03436295  -0.28930667  -4.61528929  -0.3417361   -0.34600702\n",
      "          nan  -0.40364202  -0.28754005  -0.32675204  -0.36851533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': None, 'optimizer': 'Momentum', 'n_neurons': 90, 'n_hidden': 1, 'learning_rate': 0.01, 'input_shape': 24, 'activation': 'relu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.2875400483608246\n",
      "\n",
      "--- 27.110408918062845 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.503 m/s as root mean\n",
      "Wind MAE:  0.379 m/s in avg\n",
      "Wind MAPE:  4.701 %\n",
      "Power RMSE:  283.235 kW as root mean\n",
      "Power MAE:  172.766 kW in avg\n",
      "Power MAPE:  11.208 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.524 m/s as root mean\n",
      "Wind MAE:  0.395 m/s in avg\n",
      "Wind MAPE:  4.831 %\n",
      "Power RMSE:  292.719 kW as root mean\n",
      "Power MAE:  173.225 kW in avg\n",
      "Power MAPE:  11.25 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc2b3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55a0c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [-0.3477762  -0.46931786 -0.36191315 -0.3403027  -0.32328708 -0.37966281\n",
      " -0.32283702 -3.11807532 -0.31583616 -0.35440189 -0.36590504 -0.31171035\n",
      " -0.35772211 -0.30630846 -0.32278278 -0.37699768 -0.33949298         nan\n",
      " -0.33789137 -0.96155095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': None, 'optimizer': 'Adam', 'n_neurons': 50, 'n_hidden': 1, 'learning_rate': 0.003, 'input_shape': 24, 'activation': 'relu', 'Leaky': True}\n",
      "Best score :\n",
      "-0.30630845824877423\n",
      "\n",
      "--- 29.434219217300416 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.504 m/s as root mean\n",
      "Wind MAE:  0.378 m/s in avg\n",
      "Wind MAPE:  4.643 %\n",
      "Power RMSE:  280.716 kW as root mean\n",
      "Power MAE:  171.124 kW in avg\n",
      "Power MAPE:  10.893 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.519 m/s as root mean\n",
      "Wind MAE:  0.388 m/s in avg\n",
      "Wind MAPE:  4.74 %\n",
      "Power RMSE:  287.202 kW as root mean\n",
      "Power MAE:  170.288 kW in avg\n",
      "Power MAPE:  10.977 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6c74b",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ccb4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6564fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 16ms/step - loss: 11.4603 - val_loss: 0.6939\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5429 - val_loss: 0.4860\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4351 - val_loss: 0.4319\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4038 - val_loss: 0.4375\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3788 - val_loss: 0.4094\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3646 - val_loss: 0.3709\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3606 - val_loss: 0.3685\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3757 - val_loss: 0.4415\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3405 - val_loss: 0.3513\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3422 - val_loss: 0.3471\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3236 - val_loss: 0.3470\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3341 - val_loss: 0.3212\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3231 - val_loss: 0.3258\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3150 - val_loss: 0.3331\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3403 - val_loss: 0.3461\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3002 - val_loss: 0.3130\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.3137 - val_loss: 0.2967\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.3321 - val_loss: 0.4009\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3061 - val_loss: 0.4041\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2994 - val_loss: 0.2884\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3118 - val_loss: 0.3104\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3020 - val_loss: 0.3686\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.2852 - val_loss: 0.2990\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2822 - val_loss: 0.2926\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2809 - val_loss: 0.3064\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2915 - val_loss: 0.2785\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2780 - val_loss: 0.3345\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2786 - val_loss: 0.2924\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2943 - val_loss: 0.2883\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2873 - val_loss: 0.3080\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2875 - val_loss: 0.3072\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2759 - val_loss: 0.2728\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2725 - val_loss: 0.2810\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2796 - val_loss: 0.2988\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2735 - val_loss: 0.2715\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2769 - val_loss: 0.2668\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2739 - val_loss: 0.2792\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2593 - val_loss: 0.2617\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2668 - val_loss: 0.2682\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2615 - val_loss: 0.2867\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2660 - val_loss: 0.2610\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2531 - val_loss: 0.2599\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2519 - val_loss: 0.2982\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2678 - val_loss: 0.2845\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2747 - val_loss: 0.2673\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2587 - val_loss: 0.2527\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2493 - val_loss: 0.2591\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2443 - val_loss: 0.3041\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2583 - val_loss: 0.3064\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2573 - val_loss: 0.2516\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2624 - val_loss: 0.2731\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2454 - val_loss: 0.2576\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2481 - val_loss: 0.2545\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2482 - val_loss: 0.3175\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2424 - val_loss: 0.3370\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2443 - val_loss: 0.2600\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2346 - val_loss: 0.2404\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2363 - val_loss: 0.2497\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2377 - val_loss: 0.2970\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2353 - val_loss: 0.2398\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2236 - val_loss: 0.2664\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2374 - val_loss: 0.2355\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2349 - val_loss: 0.2564\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2316 - val_loss: 0.2569\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2486 - val_loss: 0.2598\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2429 - val_loss: 0.2550\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2312 - val_loss: 0.2366\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2326 - val_loss: 0.2313\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2296 - val_loss: 0.2316\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2158 - val_loss: 0.2340\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2267 - val_loss: 0.2387\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2123 - val_loss: 0.2323\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2174 - val_loss: 0.2503\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2195 - val_loss: 0.2350\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2279 - val_loss: 0.2677\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2252 - val_loss: 0.2335\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2178 - val_loss: 0.2252\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2239 - val_loss: 0.2413\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2146 - val_loss: 0.2502\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2037 - val_loss: 0.2323\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2017 - val_loss: 0.2300\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2114 - val_loss: 0.2278\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2049 - val_loss: 0.2348\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2180 - val_loss: 0.2404\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2019 - val_loss: 0.2555\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1975 - val_loss: 0.2706\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2017 - val_loss: 0.2385\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2033 - val_loss: 0.2471\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2095 - val_loss: 0.2228\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1999 - val_loss: 0.2612\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1972 - val_loss: 0.2335\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1991 - val_loss: 0.2469\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1966 - val_loss: 0.2276\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1979 - val_loss: 0.2174\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1946 - val_loss: 0.2442\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1893 - val_loss: 0.2227\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1868 - val_loss: 0.2178\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1899 - val_loss: 0.3224\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1942 - val_loss: 0.2237\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2072 - val_loss: 0.2246\n",
      "\n",
      "RMSE for validation 0.4739662548088423\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.432 m/s as root mean\n",
      "Wind MAE:  0.327 m/s in avg\n",
      "Wind MAPE:  3.921 %\n",
      "Power RMSE:  236.508 kW as root mean\n",
      "Power MAE:  145.661 kW in avg\n",
      "Power MAPE:  8.567 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.491 m/s as root mean\n",
      "Wind MAE:  0.37 m/s in avg\n",
      "Wind MAPE:  4.408 %\n",
      "Power RMSE:  267.616 kW as root mean\n",
      "Power MAE:  161.384 kW in avg\n",
      "Power MAPE:  9.476 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b7b0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c3cce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 12.3863 - val_loss: 0.6166\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4730 - val_loss: 0.4704\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4061 - val_loss: 0.4194\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3862 - val_loss: 0.4020\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3646 - val_loss: 0.3677\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3545 - val_loss: 0.3534\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3437 - val_loss: 0.3440\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3428 - val_loss: 0.4263\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3393 - val_loss: 0.3243\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3283 - val_loss: 0.3342\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3239 - val_loss: 0.3081\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3187 - val_loss: 0.3196\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.3131 - val_loss: 0.3293\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3119 - val_loss: 0.3484\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3162 - val_loss: 0.3167\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3104 - val_loss: 0.3367\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3131 - val_loss: 0.4370\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3049 - val_loss: 0.3094\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3068 - val_loss: 0.3100\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3158 - val_loss: 0.2846\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3051 - val_loss: 0.3006\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3064 - val_loss: 0.2782\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.3117 - val_loss: 0.3017\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3093 - val_loss: 0.2722\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2980 - val_loss: 0.2792\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3115 - val_loss: 0.3545\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2913 - val_loss: 0.4989\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2997 - val_loss: 0.2767\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2933 - val_loss: 0.2774\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2911 - val_loss: 0.2693\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2864 - val_loss: 0.3787\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2813 - val_loss: 0.2849\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2776 - val_loss: 0.2617\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2969 - val_loss: 0.2702\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2779 - val_loss: 0.2739\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2697 - val_loss: 0.2740\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2748 - val_loss: 0.2733\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2650 - val_loss: 0.2709\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2796 - val_loss: 0.2662\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2720 - val_loss: 0.2657\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2632 - val_loss: 0.2724\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2785 - val_loss: 0.2638\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2703 - val_loss: 0.2746\n",
      "\n",
      "RMSE for validation 0.5115965441029691\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.506 m/s as root mean\n",
      "Wind MAE:  0.381 m/s in avg\n",
      "Wind MAPE:  4.599 %\n",
      "Power RMSE:  280.801 kW as root mean\n",
      "Power MAE:  172.716 kW in avg\n",
      "Power MAPE:  10.431 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.511 m/s as root mean\n",
      "Wind MAE:  0.385 m/s in avg\n",
      "Wind MAPE:  4.582 %\n",
      "Power RMSE:  278.127 kW as root mean\n",
      "Power MAE:  166.424 kW in avg\n",
      "Power MAPE:  10.033 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85cbe214",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':1,\n",
    "    'n_neurons': 50,\n",
    "    'learning_rate':0.003,\n",
    "    'activation':'relu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77a02646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 15.4368 - val_loss: 2.4230\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.1981 - val_loss: 0.6430\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.5554 - val_loss: 0.5218\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4806 - val_loss: 0.5035\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.4395 - val_loss: 0.4481\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.4128 - val_loss: 0.4232\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.4002 - val_loss: 0.4195\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3912 - val_loss: 0.4142\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3845 - val_loss: 0.4165\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3824 - val_loss: 0.3846\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3679 - val_loss: 0.3776\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3645 - val_loss: 0.4088\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3597 - val_loss: 0.3840\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3639 - val_loss: 0.3561\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3546 - val_loss: 0.3627\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3530 - val_loss: 0.3498\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3516 - val_loss: 0.3500\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3481 - val_loss: 0.3441\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3450 - val_loss: 0.3427\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3433 - val_loss: 0.3389\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3405 - val_loss: 0.3949\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3404 - val_loss: 0.3826\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3324 - val_loss: 0.3295\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3406 - val_loss: 0.3498\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3306 - val_loss: 0.3320\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3291 - val_loss: 0.3253\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3306 - val_loss: 0.3620\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.3201\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3276 - val_loss: 0.3559\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.3399\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.3163 - val_loss: 0.3305\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.3155 - val_loss: 0.3170\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3187 - val_loss: 0.3405\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.3253 - val_loss: 0.3110\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.3171 - val_loss: 0.3129\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3202 - val_loss: 0.3246\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.3258 - val_loss: 0.3359\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3167 - val_loss: 0.3091\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3246 - val_loss: 0.3236\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3134 - val_loss: 0.3080\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3112 - val_loss: 0.3112\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3096 - val_loss: 0.3170\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3100 - val_loss: 0.3044\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3027 - val_loss: 0.3020\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3082 - val_loss: 0.2992\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3165 - val_loss: 0.3220\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3168 - val_loss: 0.3688\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3056 - val_loss: 0.3089\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3024\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3093 - val_loss: 0.3067\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3012 - val_loss: 0.2932\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3233 - val_loss: 0.3553\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3159 - val_loss: 0.2974\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2932 - val_loss: 0.3015\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2959 - val_loss: 0.3008\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2978 - val_loss: 0.3261\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3056 - val_loss: 0.3240\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2964 - val_loss: 0.2880\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2991 - val_loss: 0.2975\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3014 - val_loss: 0.2937\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.3079 - val_loss: 0.2911\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2890 - val_loss: 0.2943\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2986 - val_loss: 0.2840\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3041 - val_loss: 0.2965\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2963 - val_loss: 0.2835\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2939 - val_loss: 0.2818\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.2998\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2904 - val_loss: 0.2873\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2916 - val_loss: 0.2752\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2888 - val_loss: 0.2770\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2818 - val_loss: 0.2755\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2890 - val_loss: 0.2738\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2961 - val_loss: 0.3054\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2854 - val_loss: 0.2698\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2865 - val_loss: 0.2753\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2871 - val_loss: 0.2709\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2788 - val_loss: 0.2737\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2803 - val_loss: 0.2812\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2813 - val_loss: 0.3142\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2921 - val_loss: 0.2690\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2772 - val_loss: 0.2955\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.2774\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.2779 - val_loss: 0.2704\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2740 - val_loss: 0.3122\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2754 - val_loss: 0.2901\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2793 - val_loss: 0.3206\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2889 - val_loss: 0.2663\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.2629\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2825 - val_loss: 0.2615\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2727 - val_loss: 0.2709\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2803 - val_loss: 0.2864\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2844 - val_loss: 0.2756\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2725 - val_loss: 0.2619\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2775 - val_loss: 0.2598\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.2739 - val_loss: 0.2837\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2831 - val_loss: 0.3158\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2719 - val_loss: 0.3037\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2703 - val_loss: 0.2716\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2718 - val_loss: 0.2590\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.2790 - val_loss: 0.2631\n",
      "\n",
      "RMSE for validation 0.5128872623816613\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.507 m/s as root mean\n",
      "Wind MAE:  0.382 m/s in avg\n",
      "Wind MAPE:  4.661 %\n",
      "Power RMSE:  281.738 kW as root mean\n",
      "Power MAE:  172.118 kW in avg\n",
      "Power MAPE:  10.853 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.515 m/s as root mean\n",
      "Wind MAE:  0.387 m/s in avg\n",
      "Wind MAPE:  4.675 %\n",
      "Power RMSE:  283.093 kW as root mean\n",
      "Power MAE:  168.771 kW in avg\n",
      "Power MAPE:  10.562 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f5f492",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26db8c",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d5176",
   "metadata": {},
   "source": [
    "MAPE wind: 9.476%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4dd9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WTG43_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71206bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568d86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5148bd3a",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "201fc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('WTG43_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cca62eca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.432 m/s as root mean\n",
      "Wind MAE:  0.327 m/s in avg\n",
      "Wind MAPE:  3.921 %\n",
      "Power RMSE:  236.508 kW as root mean\n",
      "Power MAE:  145.661 kW in avg\n",
      "Power MAPE:  8.567 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.491 m/s as root mean\n",
      "Wind MAE:  0.37 m/s in avg\n",
      "Wind MAPE:  4.408 %\n",
      "Power RMSE:  267.616 kW as root mean\n",
      "Power MAE:  161.384 kW in avg\n",
      "Power MAPE:  9.476 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "WS_pred=model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67ad0ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ANN_WTG43.csv saved in \\Results_ folder\n"
     ]
    }
   ],
   "source": [
    "WS_pred=pd.DataFrame(WS_pred)\n",
    "save(WS_pred,'\\Results_','ANN_WTG43.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94611ab",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "288e9e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e31543b5ce494e94ce5fa21b0f100d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1918 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x684 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance through SHAP values performed\n"
     ]
    }
   ],
   "source": [
    "shap_values=feature_importance (X_train, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "df370857",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=transform_shap (shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3448bcaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>SHAP_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WS1</td>\n",
       "      <td>1.347295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WS3</td>\n",
       "      <td>0.132814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WS4</td>\n",
       "      <td>0.380705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSHor</td>\n",
       "      <td>0.605584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WDHor</td>\n",
       "      <td>0.009814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WSVer</td>\n",
       "      <td>0.013090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WDVer</td>\n",
       "      <td>0.005709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.104708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RH1</td>\n",
       "      <td>0.034690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.038729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RH2</td>\n",
       "      <td>0.032775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PR1</td>\n",
       "      <td>0.063964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AD1</td>\n",
       "      <td>0.194263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PR2</td>\n",
       "      <td>0.026077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AD2</td>\n",
       "      <td>0.020072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rain</td>\n",
       "      <td>0.053182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WD1</td>\n",
       "      <td>0.064510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WD3</td>\n",
       "      <td>0.104729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WD4</td>\n",
       "      <td>0.009276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TI</td>\n",
       "      <td>0.073653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WSH</td>\n",
       "      <td>0.325283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WD_bin</td>\n",
       "      <td>0.014539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tod</td>\n",
       "      <td>0.035251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WVeer</td>\n",
       "      <td>0.015944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables  SHAP_abs\n",
       "0        WS1  1.347295\n",
       "1        WS3  0.132814\n",
       "2        WS4  0.380705\n",
       "3      WSHor  0.605584\n",
       "4      WDHor  0.009814\n",
       "5      WSVer  0.013090\n",
       "6      WDVer  0.005709\n",
       "7         T1  0.104708\n",
       "8        RH1  0.034690\n",
       "9         T2  0.038729\n",
       "10       RH2  0.032775\n",
       "11       PR1  0.063964\n",
       "12       AD1  0.194263\n",
       "13       PR2  0.026077\n",
       "14       AD2  0.020072\n",
       "15      Rain  0.053182\n",
       "16       WD1  0.064510\n",
       "17       WD3  0.104729\n",
       "18       WD4  0.009276\n",
       "19        TI  0.073653\n",
       "20       WSH  0.325283\n",
       "21    WD_bin  0.014539\n",
       "22       tod  0.035251\n",
       "23     WVeer  0.015944"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c2882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bede8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b17ba021",
   "metadata": {},
   "source": [
    "## Dataset3- WTG46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc440e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WSHor', 'WDHor', 'WSVer', 'WDVer', 'T1', 'RH1',\n",
       "       'T2', 'RH2', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WD1', 'WD3', 'WD4',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "X_train= uploading_csv('\\Dataset3-New_Site','\\X_train46.csv')\n",
    "X_test= uploading_csv('\\Dataset3-New_Site','\\X_test46.csv')\n",
    "y_train= uploading_csv('\\Dataset3-New_Site','\\y_train46.csv')\n",
    "y_test= uploading_csv('\\Dataset3-New_Site','\\y_test46.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06d9dbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6178491",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset3-New_Site','\\PC_V150.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5f052",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "750dc1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4311f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [        nan -0.14991749 -0.14112541 -0.15147516 -0.16234613 -0.13085179\n",
      " -0.16194989 -0.16134451 -7.9557333  -0.14604313 -0.16529974 -0.13819598\n",
      " -0.61050423 -0.15987088 -0.12899678 -0.39793547 -0.21996407 -0.14488961\n",
      " -0.15048811 -0.15192912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': None, 'optimizer': 'Nadam', 'n_neurons': 70, 'n_hidden': 1, 'learning_rate': 0.005, 'input_shape': 24, 'activation': 'relu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.12899678200483322\n",
      "\n",
      "--- 21.835569846630097 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.341 m/s as root mean\n",
      "Wind MAE:  0.252 m/s in avg\n",
      "Wind MAPE:  3.507 %\n",
      "Power RMSE:  208.634 kW as root mean\n",
      "Power MAE:  135.901 kW in avg\n",
      "Power MAPE:  9.713 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.363 m/s as root mean\n",
      "Wind MAE:  0.269 m/s in avg\n",
      "Wind MAPE:  3.755 %\n",
      "Power RMSE:  218.66 kW as root mean\n",
      "Power MAE:  144.364 kW in avg\n",
      "Power MAPE:  10.412 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc263fa",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0b1c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8fb47bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 9.4200 - val_loss: 0.3310\n",
      "Epoch 2/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2709 - val_loss: 0.2347\n",
      "Epoch 3/100\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.2224 - val_loss: 0.2071\n",
      "Epoch 4/100\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.2007 - val_loss: 0.1869\n",
      "Epoch 5/100\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.1882 - val_loss: 0.1779\n",
      "Epoch 6/100\n",
      "114/114 [==============================] - 1s 4ms/step - loss: 0.1704 - val_loss: 0.1779\n",
      "Epoch 7/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1693 - val_loss: 0.1638\n",
      "Epoch 8/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1600 - val_loss: 0.1647\n",
      "Epoch 9/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1572 - val_loss: 0.1502\n",
      "Epoch 10/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1508 - val_loss: 0.1478\n",
      "Epoch 11/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1511 - val_loss: 0.1682\n",
      "Epoch 12/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1538 - val_loss: 0.1542\n",
      "Epoch 13/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1450 - val_loss: 0.1628\n",
      "Epoch 14/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1460 - val_loss: 0.1816\n",
      "Epoch 15/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1396 - val_loss: 0.1438\n",
      "Epoch 16/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1419 - val_loss: 0.1525\n",
      "Epoch 17/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1360 - val_loss: 0.1428\n",
      "Epoch 18/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1311 - val_loss: 0.1406\n",
      "Epoch 19/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1590 - val_loss: 0.1374\n",
      "Epoch 20/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1404 - val_loss: 0.1341\n",
      "Epoch 21/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1412 - val_loss: 0.1441\n",
      "Epoch 22/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1328 - val_loss: 0.1362\n",
      "Epoch 23/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1301 - val_loss: 0.1441\n",
      "Epoch 24/100\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.1282 - val_loss: 0.1302\n",
      "Epoch 25/100\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.1280 - val_loss: 0.1357\n",
      "Epoch 26/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1293 - val_loss: 0.1460\n",
      "Epoch 27/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1306 - val_loss: 0.1358\n",
      "Epoch 28/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1305 - val_loss: 0.1527\n",
      "Epoch 29/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1303 - val_loss: 0.1299\n",
      "Epoch 30/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1274 - val_loss: 0.1323\n",
      "Epoch 31/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1310 - val_loss: 0.1394\n",
      "Epoch 32/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1257 - val_loss: 0.1530\n",
      "Epoch 33/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1287 - val_loss: 0.1336\n",
      "Epoch 34/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1283 - val_loss: 0.1305\n",
      "Epoch 35/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1256 - val_loss: 0.1301\n",
      "Epoch 36/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1212 - val_loss: 0.1282\n",
      "Epoch 37/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1291 - val_loss: 0.1432\n",
      "Epoch 38/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1258 - val_loss: 0.1313\n",
      "Epoch 39/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1264 - val_loss: 0.1312\n",
      "Epoch 40/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1235 - val_loss: 0.1457\n",
      "Epoch 41/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1226 - val_loss: 0.1407\n",
      "Epoch 42/100\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.1242 - val_loss: 0.2097\n",
      "Epoch 43/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1277 - val_loss: 0.1229\n",
      "Epoch 44/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1168 - val_loss: 0.1247\n",
      "Epoch 45/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1316 - val_loss: 0.2009\n",
      "Epoch 46/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1281 - val_loss: 0.1283\n",
      "Epoch 47/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1247 - val_loss: 0.1350\n",
      "Epoch 48/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1222 - val_loss: 0.1317\n",
      "Epoch 49/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1197 - val_loss: 0.1582\n",
      "Epoch 50/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1201 - val_loss: 0.1447\n",
      "Epoch 51/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1207 - val_loss: 0.1323\n",
      "Epoch 52/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1242 - val_loss: 0.1311\n",
      "Epoch 53/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1281 - val_loss: 0.1272\n",
      "Epoch 54/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1144 - val_loss: 0.1295\n",
      "Epoch 55/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1131 - val_loss: 0.1400\n",
      "Epoch 56/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1178 - val_loss: 0.1279\n",
      "Epoch 57/100\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.1272\n",
      "Epoch 58/100\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.1257 - val_loss: 0.1302\n",
      "Epoch 59/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1161 - val_loss: 0.1424\n",
      "Epoch 60/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1152 - val_loss: 0.1300\n",
      "Epoch 61/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1162 - val_loss: 0.1325\n",
      "Epoch 62/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1148 - val_loss: 0.1357\n",
      "Epoch 63/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1106 - val_loss: 0.1206\n",
      "Epoch 64/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1119 - val_loss: 0.1268\n",
      "Epoch 65/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1098 - val_loss: 0.1516\n",
      "Epoch 66/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1143 - val_loss: 0.1253\n",
      "Epoch 67/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1149 - val_loss: 0.1326\n",
      "Epoch 68/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1102 - val_loss: 0.1246\n",
      "Epoch 69/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1197 - val_loss: 0.1263\n",
      "Epoch 70/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1254 - val_loss: 0.1311\n",
      "Epoch 71/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1220 - val_loss: 0.1484\n",
      "Epoch 72/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1091 - val_loss: 0.1322\n",
      "Epoch 73/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1080 - val_loss: 0.1266\n",
      "Epoch 74/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1141 - val_loss: 0.1281\n",
      "Epoch 75/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1101 - val_loss: 0.1257\n",
      "Epoch 76/100\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.1076 - val_loss: 0.1258\n",
      "Epoch 77/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1114 - val_loss: 0.1261\n",
      "Epoch 78/100\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.1150 - val_loss: 0.1252\n",
      "Epoch 79/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1095 - val_loss: 0.1206\n",
      "Epoch 80/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1171 - val_loss: 0.1264\n",
      "Epoch 81/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1094 - val_loss: 0.1277\n",
      "Epoch 82/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1103 - val_loss: 0.1809\n",
      "Epoch 83/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1121 - val_loss: 0.1336\n",
      "Epoch 84/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1103 - val_loss: 0.1303\n",
      "Epoch 85/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1095 - val_loss: 0.1336\n",
      "Epoch 86/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1076 - val_loss: 0.1197\n",
      "Epoch 87/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1098 - val_loss: 0.1204\n",
      "Epoch 88/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1069 - val_loss: 0.1257\n",
      "Epoch 89/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1032 - val_loss: 0.1194\n",
      "Epoch 90/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1063 - val_loss: 0.1520\n",
      "Epoch 91/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1064 - val_loss: 0.1379\n",
      "Epoch 92/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1067 - val_loss: 0.1502\n",
      "Epoch 93/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1041 - val_loss: 0.1533\n",
      "Epoch 94/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1100 - val_loss: 0.1546\n",
      "Epoch 95/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1093 - val_loss: 0.1217\n",
      "Epoch 96/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1056 - val_loss: 0.1253\n",
      "Epoch 97/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1087 - val_loss: 0.1254\n",
      "Epoch 98/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1057 - val_loss: 0.2148\n",
      "Epoch 99/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1073 - val_loss: 0.1158\n",
      "Epoch 100/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1099 - val_loss: 0.1234\n",
      "\n",
      "RMSE for validation 0.3512958020564821\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.317 m/s as root mean\n",
      "Wind MAE:  0.233 m/s in avg\n",
      "Wind MAPE:  3.261 %\n",
      "Power RMSE:  195.183 kW as root mean\n",
      "Power MAE:  126.285 kW in avg\n",
      "Power MAPE:  9.08 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.356 m/s as root mean\n",
      "Wind MAE:  0.258 m/s in avg\n",
      "Wind MAPE:  3.638 %\n",
      "Power RMSE:  215.841 kW as root mean\n",
      "Power MAE:  139.714 kW in avg\n",
      "Power MAPE:  10.17 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e62f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "11695a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 7.8658 - val_loss: 0.3844\n",
      "Epoch 2/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.2918 - val_loss: 0.2242\n",
      "Epoch 3/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.2180 - val_loss: 0.1995\n",
      "Epoch 4/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1895 - val_loss: 0.1710\n",
      "Epoch 5/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1775 - val_loss: 0.1964\n",
      "Epoch 6/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1643 - val_loss: 0.2203\n",
      "Epoch 7/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1623 - val_loss: 0.1622\n",
      "Epoch 8/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1559 - val_loss: 0.1549\n",
      "Epoch 9/100\n",
      "114/114 [==============================] - 2s 14ms/step - loss: 0.1507 - val_loss: 0.1617\n",
      "Epoch 10/100\n",
      "114/114 [==============================] - 2s 14ms/step - loss: 0.1512 - val_loss: 0.1456\n",
      "Epoch 11/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1477 - val_loss: 0.1514\n",
      "Epoch 12/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1462 - val_loss: 0.1450\n",
      "Epoch 13/100\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.1444 - val_loss: 0.1411\n",
      "Epoch 14/100\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1396 - val_loss: 0.1407\n",
      "Epoch 15/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1401 - val_loss: 0.1359\n",
      "Epoch 16/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1414 - val_loss: 0.1411\n",
      "Epoch 17/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1362 - val_loss: 0.1410\n",
      "Epoch 18/100\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.1309 - val_loss: 0.1497\n",
      "Epoch 19/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1389 - val_loss: 0.1627\n",
      "Epoch 20/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1310 - val_loss: 0.1308\n",
      "Epoch 21/100\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 0.1332 - val_loss: 0.1345\n",
      "Epoch 22/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1266 - val_loss: 0.1331\n",
      "Epoch 23/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1361 - val_loss: 0.1382\n",
      "Epoch 24/100\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.1290 - val_loss: 0.1328\n",
      "Epoch 25/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1327 - val_loss: 0.1410\n",
      "Epoch 26/100\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 0.1274 - val_loss: 0.1789\n",
      "Epoch 27/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1264 - val_loss: 0.1358\n",
      "Epoch 28/100\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.1234 - val_loss: 0.1340\n",
      "Epoch 29/100\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.1300 - val_loss: 0.1337\n",
      "Epoch 30/100\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.1279 - val_loss: 0.1519\n",
      "\n",
      "RMSE for validation 0.36172139080285565\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.348 m/s as root mean\n",
      "Wind MAE:  0.259 m/s in avg\n",
      "Wind MAPE:  3.576 %\n",
      "Power RMSE:  215.244 kW as root mean\n",
      "Power MAE:  140.746 kW in avg\n",
      "Power MAPE:  9.594 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.367 m/s as root mean\n",
      "Wind MAE:  0.271 m/s in avg\n",
      "Wind MAPE:  3.745 %\n",
      "Power RMSE:  223.352 kW as root mean\n",
      "Power MAE:  146.876 kW in avg\n",
      "Power MAPE:  10.009 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62b7e5",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3644ab2",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':'Early Stopping',\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8138e8",
   "metadata": {},
   "source": [
    "MAPE power: 9.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5bd4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WTG46_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe021cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d166dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df67526a",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2874d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('WTG46_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e7c7af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.336 m/s as root mean\n",
      "Wind MAE:  0.247 m/s in avg\n",
      "Wind MAPE:  3.412 %\n",
      "Power RMSE:  207.686 kW as root mean\n",
      "Power MAE:  133.525 kW in avg\n",
      "Power MAPE:  9.306 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.358 m/s as root mean\n",
      "Wind MAE:  0.257 m/s in avg\n",
      "Wind MAPE:  3.582 %\n",
      "Power RMSE:  217.147 kW as root mean\n",
      "Power MAE:  139.206 kW in avg\n",
      "Power MAPE:  9.803 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "WS_pred=model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d860af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ANN_WTG46.csv saved in \\Results_ folder\n"
     ]
    }
   ],
   "source": [
    "WS_pred=pd.DataFrame(WS_pred)\n",
    "save(WS_pred,'\\Results_','ANN_WTG46.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2290104",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b660c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7222f2d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43495739e89c45c6a0a0806152ea0e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x684 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance through SHAP values performed\n"
     ]
    }
   ],
   "source": [
    "shap_values=feature_importance (X_train, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a4597596",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=transform_shap (shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c674005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>SHAP_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WS1</td>\n",
       "      <td>1.026710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WS3</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WS4</td>\n",
       "      <td>0.213336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSHor</td>\n",
       "      <td>0.633384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WDHor</td>\n",
       "      <td>0.041101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WSVer</td>\n",
       "      <td>0.014257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WDVer</td>\n",
       "      <td>0.003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.019127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RH1</td>\n",
       "      <td>0.007010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.227647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RH2</td>\n",
       "      <td>0.004308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PR1</td>\n",
       "      <td>0.005157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AD1</td>\n",
       "      <td>0.070847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PR2</td>\n",
       "      <td>0.007121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AD2</td>\n",
       "      <td>0.111981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rain</td>\n",
       "      <td>0.010906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WD1</td>\n",
       "      <td>0.312203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WD3</td>\n",
       "      <td>0.066988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WD4</td>\n",
       "      <td>0.125926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TI</td>\n",
       "      <td>0.007467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WSH</td>\n",
       "      <td>0.229583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WD_bin</td>\n",
       "      <td>0.029734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tod</td>\n",
       "      <td>0.009782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WVeer</td>\n",
       "      <td>0.011748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables  SHAP_abs\n",
       "0        WS1  1.026710\n",
       "1        WS3  0.002243\n",
       "2        WS4  0.213336\n",
       "3      WSHor  0.633384\n",
       "4      WDHor  0.041101\n",
       "5      WSVer  0.014257\n",
       "6      WDVer  0.003971\n",
       "7         T1  0.019127\n",
       "8        RH1  0.007010\n",
       "9         T2  0.227647\n",
       "10       RH2  0.004308\n",
       "11       PR1  0.005157\n",
       "12       AD1  0.070847\n",
       "13       PR2  0.007121\n",
       "14       AD2  0.111981\n",
       "15      Rain  0.010906\n",
       "16       WD1  0.312203\n",
       "17       WD3  0.066988\n",
       "18       WD4  0.125926\n",
       "19        TI  0.007467\n",
       "20       WSH  0.229583\n",
       "21    WD_bin  0.029734\n",
       "22       tod  0.009782\n",
       "23     WVeer  0.011748"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590c41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "354.74px",
    "left": "1350.99px",
    "right": "20px",
    "top": "2px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
