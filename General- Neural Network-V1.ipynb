{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ad1a2a",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff62b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#data pre-processing packages\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#results and analysis packages\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78cf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data modelling & results\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#NN\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#feature importance\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304bd4d",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd727e",
   "metadata": {},
   "source": [
    "## Error computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4247b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the Root Mean Squared Error\n",
    "\n",
    "def rmse(y_true, y_predicted):\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910f4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors computation\n",
    "\n",
    "def errors_computation(data):\n",
    "    \n",
    "    df=pd.DataFrame()\n",
    "    #df.at['RMSE (as root mean)', 'Wind']= round(rmse(data['Target'], data['WS_pred']), 3)\n",
    "    df.at['MAE (in avg)', 'Wind']= round(mae(data['Target'], data['WS_pred']), 3)\n",
    "    df.at['MAPE (%)', 'Wind']= round(mape(data['Target'], data['WS_pred'])*100, 3)\n",
    "    \n",
    "    #df.at['RMSE (as root mean)', 'Power']= round(rmse(data['P'], data['P_pred']), 3)\n",
    "    df.at['MAE (in avg)', 'Power']= round(mae(data['P'], data['P_pred']), 3)\n",
    "    df.at['MAPE (%)', 'Power']= round(mape(data['P'], data['P_pred'])*100, 3)\n",
    "    \n",
    "    \n",
    "    print('Wind RMSE: ', round(rmse(data['Target'], data['WS_pred']), 3), 'm/s as root mean')\n",
    "    print('Wind MAE: ', round(mae(data['Target'], data['WS_pred']), 3), 'm/s in avg')\n",
    "    print('Wind MAPE: ', round(mape(data['Target'], data['WS_pred'])*100, 3), '%')\n",
    "    \n",
    "    print('Power RMSE: ', round(rmse(data['P'], data['P_pred']), 3), 'kW as root mean')\n",
    "    print('Power MAE: ', round(mae(data['P'], data['P_pred']), 3), 'kW in avg')\n",
    "    print('Power MAPE: ', round(mape(data['P'], data['P_pred'])*100, 3), '%')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9f017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(data, title):\n",
    "    \n",
    "    #title is expected to be an str\n",
    "    #WS_pred and Target should be the variables names\n",
    "\n",
    "    #plotting the reference\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot([-1,17.5],[-1,17.5], 'green', linewidth=4, alpha=.12)\n",
    "    plt.plot(data['WS_pred'], data['Target'], marker='o', ls='', label='Regression', markersize=5, alpha=.1)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    ax=plt.gca()\n",
    "    ax.set(xlabel='y predicted', ylabel='y actual');\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(ymin=4, ymax=17.5)\n",
    "    ax.set_xlim(xmin=4, xmax=17.5)\n",
    "    \n",
    "    return print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58bd13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powercurve_computation(data, power_curve):\n",
    "    \n",
    "    from scipy import interpolate\n",
    "    \n",
    "    #this function computes the power at a observation given the information at a observation:\n",
    "    # the WS (in m/s) at the wind turbine location and at the hub height (Target)\n",
    "    # the power curve of the wind turbine in an xslx\n",
    "    \n",
    "    \n",
    "    x=power_curve['Wind Speed [m/s]']\n",
    "    y=power_curve['Warranted Power Curve [kW]']\n",
    "    x_new=data['Target']\n",
    "    \n",
    "    f = interpolate.interp1d(x, y)\n",
    "    #, kind='linear'\n",
    "    data['P']=f(x_new)\n",
    "    \n",
    "    if 'WS_pred' in data.keys():\n",
    "        x_new2=data['WS_pred']\n",
    "        data['P_pred']=f(x_new2)\n",
    "    \n",
    "    print('power curve computation performed')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c09062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_power_computation (data_test, data_train, power_curve):\n",
    "    \n",
    "    results_test=pd.DataFrame()\n",
    "    results_train=pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    results_test=powercurve_computation(data_test, power_curve)\n",
    "    results_train=powercurve_computation(data_train, power_curve)\n",
    "\n",
    "    return results_test, results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3896d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results(data_test, data_train, power_curve, plot_error):\n",
    "    \n",
    "    #this function computes and plots the results of a modelling:\n",
    "\n",
    "    results_test, results_train=control_power_computation (data_test, data_train, power_curve)\n",
    "    \n",
    "    \n",
    "    print('Modelling errors for training set:')\n",
    "    errors_computation(results_train)\n",
    "    print('')\n",
    "    print('Modelling errors for test set:')\n",
    "    errors_computation(results_test)\n",
    "    \n",
    "    if plot_error:\n",
    "        print('')\n",
    "        error_plot(results_test, 'Error plot for test set wind speed')\n",
    "\n",
    "    print('')\n",
    "    return print('Showing the results of the modelling: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71970e76",
   "metadata": {},
   "source": [
    "## Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bcfb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploading_csv(file_folder,file_name):\n",
    "    \n",
    "    #file folder required\n",
    "    #file name required\n",
    "    #file is expected to be in the data root: r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    #this function uploads and formats csv/txt/xlsx datasets into DataFrame\n",
    "    \n",
    "    \n",
    "    data_root=r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    data_folder=str(file_folder)\n",
    "    data_file=str(file_name)\n",
    "    \n",
    "    data_path=data_root+data_folder+data_file\n",
    "    \n",
    "    data1 = pd.read_csv(data_path)\n",
    "\n",
    "    \n",
    "    # We will save the WD_bin as the index\n",
    "    \n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c5e33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function saves a data csv\n",
    "\n",
    "def save (data, file_folder,file_name):\n",
    "    \n",
    "    #file folder required\n",
    "    #file name required\n",
    "    #file is expected to be saved in the data root: r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    #this function saves a csv/txt/xlsx into Irma's folder\n",
    "    #the saved file will keep the columns names but not the index\n",
    "    \n",
    "    data_root=r'C:\\Users\\irgaa\\Irma\\Data'\n",
    "    data_folder=str(file_folder)\n",
    "    data_file=str(file_name)\n",
    "    \n",
    "    data_path=data_root+data_folder+data_file\n",
    "    \n",
    "    data.to_csv (data_path, index = False, header=True)\n",
    "    \n",
    "    \n",
    "    return print('file', data_file, 'saved in', data_folder, 'folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaedaca",
   "metadata": {},
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "358a5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_selection(X_train, X_test, inputs):\n",
    "    \n",
    "    #this function returns the columns of the training and test sets in the inputs list\n",
    "    \n",
    "    X_train1 = pd.DataFrame()\n",
    "    X_test1 = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    X_train1 = X_train[inputs]\n",
    "    X_test1 = X_test[inputs]\n",
    "\n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd717ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_drop(X_train, X_test, list_2drop):\n",
    "    \n",
    "    #this function returns the columns of the training and test sets in the inputs list\n",
    "\n",
    "    X_train1 = X_train.drop(columns=list_2drop)\n",
    "    X_test1 = X_test.drop(columns=list_2drop)\n",
    "\n",
    "    \n",
    "    \n",
    "    return X_train1,X_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c2b31",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5c814",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eec63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model (n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8],\n",
    "                 activation='relu', optimizer='Adam', regularization=None, Leaky=False):\n",
    "    \n",
    "    #this function build model is created only for building the NN\n",
    "    #it will always initialize the weights using the strategy 'He normal' unless activation function 'selu' is selected\n",
    "    \n",
    "    \n",
    "    if activation!='relu':\n",
    "        Leaky==False\n",
    "    \n",
    "    \n",
    "    #we create a sequential model:\n",
    "    model=keras.models.Sequential()\n",
    "    \n",
    "    #we add the input layer with n_neurons=n_features (shape of X_train)\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    #we add a hidden layer for each n_hidden with ReLU as activation function\n",
    "    #this code considers the same n_neurons for each hidden layer\n",
    "    for layer in range(n_hidden):\n",
    "        \n",
    "        if regularization=='l2':\n",
    "            if activation=='relu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal',\n",
    "                                            kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "            elif activation=='elu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal',\n",
    "                                            kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "            elif activation=='selu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal',\n",
    "                                           kernel_regularizer=keras.regularizers.l2(0.01)))  \n",
    "        elif regularization=='l1':\n",
    "            if activation=='relu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal',\n",
    "                                             kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "            elif activation=='elu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal',\n",
    "                                             kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "            elif activation=='selu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal',\n",
    "                                            kernel_regularizer=keras.regularizers.l1(0.01))) \n",
    "        else:\n",
    "            if activation=='relu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal'))\n",
    "            elif activation=='elu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal'))\n",
    "            elif activation=='selu':\n",
    "                model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal'))\n",
    "        \n",
    "        if Leaky:\n",
    "            model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    #dropout only considered in the last layer\n",
    "    if regularization=='Dropout':\n",
    "        model.add(keras.layers.Dropout(rate=0.2))\n",
    "        \n",
    "    #we add the output layer with one neuron (we only want to predict 1 target)\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    #we choose our optimizer and build it:\n",
    "    if optimizer=='SGD':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate)\n",
    "    elif optimizer=='Momentum':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer=='Nesterov':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    elif optimizer=='RMSprop':\n",
    "        optimizer=keras.optimizers.RMSprop(lr=learning_rate, rho=0.9)\n",
    "    elif optimizer=='Adam':\n",
    "        optimizer=keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    elif optimizer=='Nadam':\n",
    "        optimizer=keras.optimizers.Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    \n",
    "    #we compile our model with the selected optimizer and set the objective function loss='mse'\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb2847dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_old (n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8],\n",
    "                 activation='relu', optimizer='Adam', regularization=None, Leaky=False):\n",
    "    \n",
    "    #this function build model is created only for building the NN\n",
    "    #it will always initialize the weights using the strategy 'He normal' unless activation function 'selu' is selected\n",
    "    \n",
    "    \n",
    "    if activation!='relu':\n",
    "        Leaky==False\n",
    "    \n",
    "    \n",
    "    #we create a sequential model:\n",
    "    model=keras.models.Sequential()\n",
    "    \n",
    "    #we add the input layer with n_neurons=n_features (shape of X_train)\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    #we add a hidden layer for each n_hidden with ReLU as activation function\n",
    "    #this code considers the same n_neurons for each hidden layer\n",
    "    for layer in range(n_hidden):\n",
    "        if activation=='relu':\n",
    "            model.add(keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_normal'))\n",
    "        elif activation=='elu':\n",
    "            model.add(keras.layers.Dense(n_neurons, activation='elu', kernel_initializer='he_normal'))\n",
    "        elif activation=='selu':\n",
    "            model.add(keras.layers.Dense(n_neurons, activation='selu', kernel_initializer='lecun_normal'))\n",
    "        if Leaky:\n",
    "            model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "            \n",
    "    if regularization=='Dropout':\n",
    "        model.add(keras.layers.Dropout(rate=0.2))\n",
    "        \n",
    "    #we add the output layer with one neuron (we only want to predict 1 target)\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    #we choose our optimizer and build it:\n",
    "    if optimizer=='SGD':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate)\n",
    "    elif optimizer=='Momentum':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer=='Nesterov':\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    elif optimizer=='RMSprop':\n",
    "        optimizer=keras.optimizers.RMSprop(lr=learning_rate, rho=0.9)\n",
    "    elif optimizer=='Adam':\n",
    "        optimizer=keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    elif optimizer=='Nadam':\n",
    "        optimizer=keras.optimizers.Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    \n",
    "    #we compile our model with the selected optimizer and set the objective function loss='mse'\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983f849",
   "metadata": {},
   "source": [
    "### Modelling NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c827782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling_NN (X, X_test, y, y_test, power_curve,  parameters, plot_error, plot):\n",
    "    \n",
    "    #creating the model\n",
    "    \n",
    "    n_hidden=parameters['n_hidden']\n",
    "    n_neurons=parameters['n_neurons']\n",
    "    learning_rate=parameters['learning_rate']\n",
    "    input_shape=X.shape[1:]\n",
    "    activation=parameters['activation']\n",
    "    optimizer=parameters['optimizer']\n",
    "    regularization=parameters['regularization']\n",
    "    Leaky=parameters['Leaky']\n",
    "    \n",
    "    model =build_model(n_hidden, n_neurons, learning_rate, input_shape,\n",
    "                 activation, optimizer, regularization, Leaky)\n",
    " \n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "    if regularization=='Early Stopping':\n",
    "        model.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid))\n",
    "    \n",
    "    \n",
    "#     if plot:\n",
    "#         loss_epochs_plot (history)\n",
    "        \n",
    "    \n",
    "    #model predicting\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    y_pred_valid=model.predict(X_valid)\n",
    "    \n",
    "    rmse_valid=rmse(y_valid, y_pred_valid)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    \n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "    print('')\n",
    "    print('RMSE for validation', rmse_valid)\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('NN modelling performed')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6df93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling_NN_ES (X, X_test, y, y_test, power_curve,  parameters, plot_error, plot):\n",
    "    \n",
    "    #creating the model\n",
    "    \n",
    "    n_hidden=parameters['n_hidden']\n",
    "    n_neurons=parameters['n_neurons']\n",
    "    learning_rate=parameters['learning_rate']\n",
    "    input_shape=X.shape[1:]\n",
    "    activation=parameters['activation']\n",
    "    optimizer=parameters['optimizer']\n",
    "    regularization=parameters['regularization']\n",
    "    Leaky=parameters['Leaky']\n",
    "    \n",
    "    model =build_model(n_hidden, n_neurons, learning_rate, input_shape,\n",
    "                 activation, optimizer, regularization, Leaky)\n",
    " \n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    \n",
    "    \n",
    "#     if plot:\n",
    "#         loss_epochs_plot (history)\n",
    "        \n",
    "    \n",
    "    #model predicting\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    \n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "#     mse_test=model.evaluate(X_test, y_test)\n",
    "#     rmse_test=np.sqrt(mse_test)\n",
    "#     print('RMSE for test', rmse_test)\n",
    "    \n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('NN modelling performed')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c283c5",
   "metadata": {},
   "source": [
    "### Random Search NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c6cd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSearch_NN(X, X_test, y, y_test, power_curve, param_distribs, plot_error):\n",
    "    \n",
    "    #counting the runing time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    #creating the model\n",
    "    input_shape=X.shape[1:]\n",
    "    param_distribs['input_shape']=input_shape\n",
    "    keras_reg =keras.wrappers.scikit_learn.KerasRegressor(build_model, verbose=0)\n",
    "    \n",
    "    \n",
    "    #Random Search CV\n",
    "    rnd_search_cv=RandomizedSearchCV(keras_reg, param_distribs, n_iter=20, cv=3)\n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    regularization=param_distribs['regularization']\n",
    "    \n",
    "    if regularization=='Early Stopping':\n",
    "        rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    else:\n",
    "        rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid))\n",
    "    \n",
    "    \n",
    "    #model predicting\n",
    "    \n",
    "    model=rnd_search_cv.best_estimator_.model\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    print('')\n",
    "    print('Best parameters :')\n",
    "    print(rnd_search_cv.best_params_)\n",
    "    print('Best score :')\n",
    "    print(rnd_search_cv.best_score_)\n",
    "    print('')\n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))\n",
    "    print('')\n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('RandomSearch_ NN performed')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6523601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSearch_NN_ES(X, X_test, y, y_test, power_curve, param_distribs, plot_error):\n",
    "    \n",
    "    #counting the runing time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #creating the model\n",
    "    input_shape=X.shape[1:]\n",
    "    param_distribs['input_shape']=input_shape\n",
    "    keras_reg =keras.wrappers.scikit_learn.KerasRegressor(build_model, verbose=0)\n",
    "    \n",
    "    #Random Search CV\n",
    "    rnd_search_cv=RandomizedSearchCV(keras_reg, param_distribs, n_iter=20, cv=3)\n",
    "    \n",
    "    #model fitting\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "    \n",
    "    \n",
    "    #model predicting\n",
    "    \n",
    "    model=rnd_search_cv.best_estimator_.model\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "    \n",
    "    print('')\n",
    "    print('Best parameters :')\n",
    "    print(rnd_search_cv.best_params_)\n",
    "    print('Best score :')\n",
    "    print(rnd_search_cv.best_score_)\n",
    "    print('')\n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))\n",
    "    print('')\n",
    "\n",
    "    #computing the results\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y['Target']\n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    print('RandomSearch_ NN performed')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7836fc",
   "metadata": {},
   "source": [
    "### Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a862833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_epochs_plot (history):\n",
    "    \n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.show\n",
    "    \n",
    "    return print('Loss vs. epochs plot performed')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54004cbb",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bfe8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing (X_train, X_test, y_train, y_test, power_curve, model, plot_error):\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    y_pred_train=model.predict(X_train)\n",
    "    \n",
    "    test=pd.DataFrame(y_pred_test, columns = ['test'])\n",
    "    train=pd.DataFrame(y_pred_train, columns = ['train'])\n",
    "\n",
    "\n",
    "    data_test = pd.DataFrame()\n",
    "    data_train = pd.DataFrame()\n",
    "    \n",
    "    data_test['WS_pred']=test['test']\n",
    "    data_test['Target']=y_test['Target']\n",
    "    data_train['WS_pred']=train['train']\n",
    "    data_train['Target']=y_train['Target']\n",
    "    \n",
    "    plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    \n",
    "    compute_results(data_test, data_train, power_curve, plot_error)\n",
    "    \n",
    "\n",
    "    \n",
    "    return print('NN results performed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724a96a",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51189ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance (X_train, X_test, model):\n",
    "    \n",
    "    X_t, X_f, y_t, y_f = train_test_split(X_train,y_train, test_size=0.02, random_state=12)\n",
    "    \n",
    "    background = X_f.copy()\n",
    "    \n",
    "    explainer = shap.KernelExplainer(model.predict,background)\n",
    "    shap_values = explainer.shap_values(X_test,nsamples=100)\n",
    "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "    print('Feature importance through SHAP values performed')\n",
    "    \n",
    "\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046028e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_shap (shap_values, X_test):\n",
    "\n",
    "    v=np.array(shap_values)\n",
    "    d=v.reshape(X_test.shape)\n",
    "    shap_v=pd.DataFrame(d)\n",
    "    \n",
    "    feature_list=X_test.columns\n",
    "    shap_v.columns=feature_list\n",
    "    shap_v=shap_v.abs()\n",
    "    k=pd.DataFrame(shap_v.mean()).reset_index()\n",
    "    k.columns=['variables','SHAP_abs']\n",
    "    k.sort_values(by='variables')\n",
    "    \n",
    "    return k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d0819",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fec4a",
   "metadata": {},
   "source": [
    "## Dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3f2c12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T2', 'RH2', 'T1', 'RH1', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WS1',\n",
       "       'WS3', 'WS4', 'WD1', 'WD3', 'WD4', 'WSHor', 'WDHor', 'WSVer', 'WDVer',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "# data_up= uploading_csv('\\Dataset1-Normal_Site','\\data_comp14.csv')\n",
    "X_train= uploading_csv('\\General','\\X_train1.csv')\n",
    "X_test= uploading_csv('\\General','\\X_test14.csv')\n",
    "y_train= uploading_csv('\\General','\\y_train1.csv')\n",
    "y_test= uploading_csv('\\General','\\y_test14.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0a26d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08af60ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T2</th>\n",
       "      <th>RH2</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH1</th>\n",
       "      <th>PR1</th>\n",
       "      <th>AD1</th>\n",
       "      <th>PR2</th>\n",
       "      <th>AD2</th>\n",
       "      <th>Rain</th>\n",
       "      <th>WS1</th>\n",
       "      <th>...</th>\n",
       "      <th>WD4</th>\n",
       "      <th>WSHor</th>\n",
       "      <th>WDHor</th>\n",
       "      <th>WSVer</th>\n",
       "      <th>WDVer</th>\n",
       "      <th>TI</th>\n",
       "      <th>WSH</th>\n",
       "      <th>WD_bin</th>\n",
       "      <th>tod</th>\n",
       "      <th>WVeer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.686743</td>\n",
       "      <td>0.162077</td>\n",
       "      <td>0.615702</td>\n",
       "      <td>0.254286</td>\n",
       "      <td>0.694987</td>\n",
       "      <td>0.391943</td>\n",
       "      <td>0.684273</td>\n",
       "      <td>0.320279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626145</td>\n",
       "      <td>0.331420</td>\n",
       "      <td>0.605429</td>\n",
       "      <td>0.516197</td>\n",
       "      <td>0.518763</td>\n",
       "      <td>0.406958</td>\n",
       "      <td>0.212675</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.531706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535995</td>\n",
       "      <td>0.186494</td>\n",
       "      <td>0.495123</td>\n",
       "      <td>0.265058</td>\n",
       "      <td>0.447523</td>\n",
       "      <td>0.435208</td>\n",
       "      <td>0.448760</td>\n",
       "      <td>0.390702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679629</td>\n",
       "      <td>0.477351</td>\n",
       "      <td>0.636622</td>\n",
       "      <td>0.414907</td>\n",
       "      <td>0.458028</td>\n",
       "      <td>0.504232</td>\n",
       "      <td>0.243045</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.489887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100213</td>\n",
       "      <td>0.993270</td>\n",
       "      <td>0.105457</td>\n",
       "      <td>0.989550</td>\n",
       "      <td>0.403515</td>\n",
       "      <td>0.804920</td>\n",
       "      <td>0.415173</td>\n",
       "      <td>0.792480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746132</td>\n",
       "      <td>0.358311</td>\n",
       "      <td>0.776603</td>\n",
       "      <td>0.569422</td>\n",
       "      <td>0.516569</td>\n",
       "      <td>0.145157</td>\n",
       "      <td>0.520344</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>0.537451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.774422</td>\n",
       "      <td>0.110625</td>\n",
       "      <td>0.832482</td>\n",
       "      <td>0.599315</td>\n",
       "      <td>0.857346</td>\n",
       "      <td>0.609338</td>\n",
       "      <td>0.821287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613695</td>\n",
       "      <td>0.425773</td>\n",
       "      <td>0.519552</td>\n",
       "      <td>0.481510</td>\n",
       "      <td>0.483901</td>\n",
       "      <td>0.354450</td>\n",
       "      <td>0.412821</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.265734</td>\n",
       "      <td>0.459187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309523</td>\n",
       "      <td>0.703601</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.730702</td>\n",
       "      <td>0.659098</td>\n",
       "      <td>0.667381</td>\n",
       "      <td>0.666267</td>\n",
       "      <td>0.661645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522701</td>\n",
       "      <td>0.452193</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>0.355088</td>\n",
       "      <td>0.395601</td>\n",
       "      <td>0.080932</td>\n",
       "      <td>0.352598</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.895105</td>\n",
       "      <td>0.459064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         T2       RH2        T1       RH1       PR1       AD1       PR2  \\\n",
       "0  0.686743  0.162077  0.615702  0.254286  0.694987  0.391943  0.684273   \n",
       "1  0.535995  0.186494  0.495123  0.265058  0.447523  0.435208  0.448760   \n",
       "2  0.100213  0.993270  0.105457  0.989550  0.403515  0.804920  0.415173   \n",
       "3  0.127726  0.774422  0.110625  0.832482  0.599315  0.857346  0.609338   \n",
       "4  0.309523  0.703601  0.317238  0.730702  0.659098  0.667381  0.666267   \n",
       "\n",
       "        AD2  Rain       WS1  ...       WD4     WSHor     WDHor     WSVer  \\\n",
       "0  0.320279   0.0  0.323555  ...  0.626145  0.331420  0.605429  0.516197   \n",
       "1  0.390702   0.0  0.470419  ...  0.679629  0.477351  0.636622  0.414907   \n",
       "2  0.792480   0.0  0.357223  ...  0.746132  0.358311  0.776603  0.569422   \n",
       "3  0.821287   0.0  0.419386  ...  0.613695  0.425773  0.519552  0.481510   \n",
       "4  0.661645   0.0  0.435593  ...  0.522701  0.452193  0.400189  0.355088   \n",
       "\n",
       "      WDVer        TI       WSH    WD_bin       tod     WVeer  \n",
       "0  0.518763  0.406958  0.212675  0.571429  0.636364  0.531706  \n",
       "1  0.458028  0.504232  0.243045  0.571429  0.748252  0.489887  \n",
       "2  0.516569  0.145157  0.520344  0.714286  0.174825  0.537451  \n",
       "3  0.483901  0.354450  0.412821  0.428571  0.265734  0.459187  \n",
       "4  0.395601  0.080932  0.352598  0.285714  0.895105  0.459064  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db055157",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset1-Normal_Site','\\PC_1.15kgm-3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adb853",
   "metadata": {},
   "source": [
    "### RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52c56269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ff683ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam', 'RMSProp'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74963bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Early Stopping', 'optimizer': 'Momentum', 'n_neurons': 100, 'n_hidden': 1, 'learning_rate': 0.005, 'input_shape': 19, 'activation': 'relu', 'Leaky': True}\n",
      "Best score :\n",
      "-0.6488828857739767\n",
      "\n",
      "--- 12.630461589495342 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.774 m/s as root mean\n",
      "Wind MAE:  0.575 m/s in avg\n",
      "Wind MAPE:  7.982 %\n",
      "Power RMSE:  266.681 kW as root mean\n",
      "Power MAE:  152.839 kW in avg\n",
      "Power MAPE:  7.492292220539012e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.857 m/s as root mean\n",
      "Wind MAE:  0.614 m/s in avg\n",
      "Wind MAPE:  10.44 %\n",
      "Power RMSE:  296.199 kW as root mean\n",
      "Power MAE:  163.602 kW in avg\n",
      "Power MAPE:  1.8436701770959404e+18 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b483daf",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4145fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3e2970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 5.7273 - val_loss: 0.4670\n",
      "Epoch 2/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.3802 - val_loss: 0.3325\n",
      "Epoch 3/100\n",
      "186/186 [==============================] - 0s 3ms/step - loss: 0.3359 - val_loss: 0.3050\n",
      "Epoch 4/100\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3324 - val_loss: 0.3062\n",
      "Epoch 5/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3092\n",
      "Epoch 6/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.3081 - val_loss: 0.2799\n",
      "Epoch 7/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.2857\n",
      "Epoch 8/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.3236 - val_loss: 0.3113\n",
      "Epoch 9/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2924 - val_loss: 0.2778\n",
      "Epoch 10/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2903 - val_loss: 0.2865\n",
      "Epoch 11/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.2705\n",
      "Epoch 12/100\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.279 - 1s 3ms/step - loss: 0.2809 - val_loss: 0.2570\n",
      "Epoch 13/100\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2781 - val_loss: 0.2811\n",
      "Epoch 14/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2777\n",
      "Epoch 15/100\n",
      "186/186 [==============================] - 0s 3ms/step - loss: 0.2757 - val_loss: 0.2549\n",
      "Epoch 16/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2922 - val_loss: 0.2923\n",
      "Epoch 17/100\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2834 - val_loss: 0.2548\n",
      "Epoch 18/100\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2805 - val_loss: 0.3039\n",
      "Epoch 19/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2718 - val_loss: 0.2688\n",
      "Epoch 20/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2768 - val_loss: 0.2515\n",
      "Epoch 21/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2667 - val_loss: 0.2722\n",
      "Epoch 22/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2716 - val_loss: 0.2510\n",
      "Epoch 23/100\n",
      "186/186 [==============================] - 0s 3ms/step - loss: 0.2700 - val_loss: 0.2882\n",
      "Epoch 24/100\n",
      "186/186 [==============================] - 0s 3ms/step - loss: 0.2647 - val_loss: 0.2624\n",
      "Epoch 25/100\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2712 - val_loss: 0.2485\n",
      "Epoch 26/100\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2628 - val_loss: 0.2835\n",
      "Epoch 27/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2850 - val_loss: 0.4016\n",
      "Epoch 28/100\n",
      "186/186 [==============================] - 0s 3ms/step - loss: 0.2775 - val_loss: 0.2685\n",
      "Epoch 29/100\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2570 - val_loss: 0.2593\n",
      "Epoch 30/100\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2580 - val_loss: 0.2902\n",
      "Epoch 31/100\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2590 - val_loss: 0.2489\n",
      "Epoch 32/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2647 - val_loss: 0.2545\n",
      "Epoch 33/100\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2692 - val_loss: 0.2435\n",
      "Epoch 34/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.2697 - val_loss: 0.2572\n",
      "Epoch 35/100\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.2534 - val_loss: 0.2440\n",
      "Epoch 36/100\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.2456 - val_loss: 0.3132\n",
      "Epoch 37/100\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.2487 - val_loss: 0.2387\n",
      "Epoch 38/100\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.2494 - val_loss: 0.2743\n",
      "Epoch 39/100\n",
      "186/186 [==============================] - 1s 8ms/step - loss: 0.2462 - val_loss: 0.2497\n",
      "Epoch 40/100\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2564 - val_loss: 0.2807\n",
      "Epoch 41/100\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2643 - val_loss: 0.2542\n",
      "Epoch 42/100\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2521 - val_loss: 0.2377\n",
      "Epoch 43/100\n",
      "186/186 [==============================] - 1s 8ms/step - loss: 0.2464 - val_loss: 0.2372\n",
      "Epoch 44/100\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.2524 - val_loss: 0.2640\n",
      "Epoch 45/100\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.2466 - val_loss: 0.2549\n",
      "Epoch 46/100\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.2531 - val_loss: 0.2376\n",
      "Epoch 47/100\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.2407 - val_loss: 0.2424\n",
      "Epoch 48/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.2432 - val_loss: 0.2565\n",
      "Epoch 49/100\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.2443 - val_loss: 0.2404\n",
      "Epoch 50/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.2440 - val_loss: 0.2383\n",
      "Epoch 51/100\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.2419 - val_loss: 0.2518\n",
      "Epoch 52/100\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.2448 - val_loss: 0.2447\n",
      "Epoch 53/100\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.2366 - val_loss: 0.2702\n",
      "Epoch 54/100\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.2446 - val_loss: 0.2489\n",
      "Epoch 55/100\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.2396 - val_loss: 0.2302\n",
      "Epoch 56/100\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.2359 - val_loss: 0.2529\n",
      "Epoch 57/100\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.2459 - val_loss: 0.2427\n",
      "Epoch 58/100\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.2293 - val_loss: 0.2443\n",
      "Epoch 59/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.2303 - val_loss: 0.2305\n",
      "Epoch 60/100\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.2364 - val_loss: 0.2328\n",
      "Epoch 61/100\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.2412 - val_loss: 0.2356\n",
      "Epoch 62/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.2284 - val_loss: 0.2404\n",
      "Epoch 63/100\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2330 - val_loss: 0.2803\n",
      "Epoch 64/100\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2288 - val_loss: 0.2425\n",
      "Epoch 65/100\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2392 - val_loss: 0.2373\n",
      "Epoch 66/100\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.2284 - val_loss: 0.2366\n",
      "Epoch 67/100\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.2234 - val_loss: 0.2353\n",
      "Epoch 68/100\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.2317 - val_loss: 0.2431\n",
      "Epoch 69/100\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.2295 - val_loss: 0.2309\n",
      "Epoch 70/100\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.2243 - val_loss: 0.2529\n",
      "Epoch 71/100\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.2240 - val_loss: 0.2329\n",
      "Epoch 72/100\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.2276 - val_loss: 0.2354\n",
      "Epoch 73/100\n",
      "186/186 [==============================] - 1s 8ms/step - loss: 0.2284 - val_loss: 0.2283\n",
      "Epoch 74/100\n",
      "186/186 [==============================] - 1s 8ms/step - loss: 0.2140 - val_loss: 0.2244\n",
      "Epoch 75/100\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.2184 - val_loss: 0.2551\n",
      "Epoch 76/100\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.2151 - val_loss: 0.2472\n",
      "Epoch 77/100\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.2141 - val_loss: 0.2576\n",
      "Epoch 78/100\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2179 - val_loss: 0.2198\n",
      "Epoch 79/100\n",
      "186/186 [==============================] - 1s 8ms/step - loss: 0.2251 - val_loss: 0.2337\n",
      "Epoch 80/100\n",
      "186/186 [==============================] - 1s 8ms/step - loss: 0.2159 - val_loss: 0.2316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.2293 - val_loss: 0.2528\n",
      "Epoch 82/100\n",
      "186/186 [==============================] - 1s 8ms/step - loss: 0.2141 - val_loss: 0.2351\n",
      "Epoch 83/100\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.2283 - val_loss: 0.2268\n",
      "Epoch 84/100\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.2135 - val_loss: 0.2252\n",
      "Epoch 85/100\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.2129 - val_loss: 0.2202\n",
      "Epoch 86/100\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.2150 - val_loss: 0.2291\n",
      "Epoch 87/100\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.2095 - val_loss: 0.2711\n",
      "Epoch 88/100\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.2115 - val_loss: 0.2581\n",
      "Epoch 89/100\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.2104 - val_loss: 0.2323\n",
      "Epoch 90/100\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.2073 - val_loss: 0.2258\n",
      "Epoch 91/100\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.2126 - val_loss: 0.2265\n",
      "Epoch 92/100\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.2130 - val_loss: 0.2294\n",
      "Epoch 93/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.2029 - val_loss: 0.2205\n",
      "Epoch 94/100\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2168 - val_loss: 0.2338\n",
      "Epoch 95/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2021 - val_loss: 0.2316\n",
      "Epoch 96/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2036 - val_loss: 0.2431\n",
      "Epoch 97/100\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.2181 - val_loss: 0.2272\n",
      "Epoch 98/100\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1999 - val_loss: 0.2447\n",
      "Epoch 99/100\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2070 - val_loss: 0.2249\n",
      "Epoch 100/100\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2148 - val_loss: 0.2791\n",
      "\n",
      "RMSE for validation 0.5282606418733736\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.496 m/s as root mean\n",
      "Wind MAE:  0.385 m/s in avg\n",
      "Wind MAPE:  4.479 %\n",
      "Power RMSE:  222.381 kW as root mean\n",
      "Power MAE:  145.534 kW in avg\n",
      "Power MAPE:  9.852 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.468 m/s as root mean\n",
      "Wind MAE:  0.377 m/s in avg\n",
      "Wind MAPE:  4.243 %\n",
      "Power RMSE:  201.022 kW as root mean\n",
      "Power MAE:  132.571 kW in avg\n",
      "Power MAPE:  8.67 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb2d2b",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8524f1c",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c207f",
   "metadata": {},
   "source": [
    "MAPE power: 8.67 %- WTG14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1f39b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dataset1_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a401dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1a6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87134b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2a46ffb",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ffdeaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('dataset1_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "809f4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WTG15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c23d5e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T2', 'RH2', 'T1', 'RH1', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WS1',\n",
       "       'WS3', 'WS4', 'WD1', 'WD3', 'WD4', 'WSHor', 'WDHor', 'WSVer', 'WDVer',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "# data_up= uploading_csv('\\Dataset1-Normal_Site','\\data_comp14.csv')\n",
    "X_train= uploading_csv('\\General','\\X_train1.csv')\n",
    "X_test= uploading_csv('\\General','\\X_test15.csv')\n",
    "y_train= uploading_csv('\\General','\\y_train1.csv')\n",
    "y_test= uploading_csv('\\General','\\y_test15.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd3e3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.496 m/s as root mean\n",
      "Wind MAE:  0.385 m/s in avg\n",
      "Wind MAPE:  4.479 %\n",
      "Power RMSE:  222.381 kW as root mean\n",
      "Power MAE:  145.534 kW in avg\n",
      "Power MAPE:  9.852 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.562 m/s as root mean\n",
      "Wind MAE:  0.429 m/s in avg\n",
      "Wind MAPE:  5.169 %\n",
      "Power RMSE:  252.252 kW as root mean\n",
      "Power MAE:  167.161 kW in avg\n",
      "Power MAPE:  12.098 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844a2df",
   "metadata": {},
   "source": [
    "## Dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccb86e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "143791ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WD1', 'WD4', 'WSHor', 'WSVer', 'WDHor', 'RH1',\n",
       "       'Rain', 'WSH', 'WVeer', 'TI', 'WDVer', 'WD_bin', 'tod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "# data_up= uploading_csv('\\Dataset1-Normal_Site','\\data_comp14.csv')\n",
    "X_train= uploading_csv('\\General','\\X_train2.csv')\n",
    "X_test= uploading_csv('\\General','\\X_test11.csv')\n",
    "y_train= uploading_csv('\\General','\\y_train2.csv')\n",
    "y_test= uploading_csv('\\General','\\y_test11.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e5ee809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c5bf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset2-Complex_Site','\\PC_V117.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33745571",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(columns=['RH1'])\n",
    "X_test=X_test.drop(columns=['RH1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca7797",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d34c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acf8d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4b969a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [ -1.07578381  -0.39619265 -16.41513602  -0.49583897  -0.47011769\n",
      "  -0.53511881  -0.6136086  -16.43231742  -1.04724256          nan\n",
      "  -0.40382962 -86.82775116          nan  -0.5123837   -0.46735646\n",
      "  -0.44322575  -0.3673082   -0.4475245   -7.31817595  -0.48747708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Dropout', 'optimizer': 'Nesterov', 'n_neurons': 100, 'n_hidden': 2, 'learning_rate': 0.003, 'input_shape': 16, 'activation': 'relu', 'Leaky': False}\n",
      "Best score :\n",
      "-0.36730819940567017\n",
      "\n",
      "--- 9.923941997687022 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.566 m/s as root mean\n",
      "Wind MAE:  0.435 m/s in avg\n",
      "Wind MAPE:  4.637 %\n",
      "Power RMSE:  234.791 kW as root mean\n",
      "Power MAE:  149.818 kW in avg\n",
      "Power MAPE:  10.28 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.581 m/s as root mean\n",
      "Wind MAE:  0.453 m/s in avg\n",
      "Wind MAPE:  4.874 %\n",
      "Power RMSE:  232.359 kW as root mean\n",
      "Power MAE:  153.256 kW in avg\n",
      "Power MAPE:  10.934 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9a321",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8676b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e58a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 5.0400 - val_loss: 1.0080\n",
      "Epoch 2/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 1.0384 - val_loss: 0.9347\n",
      "Epoch 3/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.9743 - val_loss: 0.8765\n",
      "Epoch 4/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.9246 - val_loss: 0.8647\n",
      "Epoch 5/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.8987 - val_loss: 0.8081\n",
      "Epoch 6/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.8768 - val_loss: 0.7801\n",
      "Epoch 7/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.8506 - val_loss: 0.7550\n",
      "Epoch 8/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.8273 - val_loss: 0.8234\n",
      "Epoch 9/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.8378 - val_loss: 0.7470\n",
      "Epoch 10/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.8034 - val_loss: 0.7405\n",
      "Epoch 11/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.8094 - val_loss: 0.7193\n",
      "Epoch 12/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7844 - val_loss: 0.7476\n",
      "Epoch 13/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7913 - val_loss: 0.6842\n",
      "Epoch 14/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7744 - val_loss: 0.6917\n",
      "Epoch 15/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7847 - val_loss: 0.7496\n",
      "Epoch 16/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7657 - val_loss: 0.7114\n",
      "Epoch 17/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7550 - val_loss: 0.7341\n",
      "Epoch 18/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7550 - val_loss: 0.7012\n",
      "Epoch 19/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7558 - val_loss: 0.6725\n",
      "Epoch 20/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7527 - val_loss: 0.6518\n",
      "Epoch 21/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7561 - val_loss: 0.6674\n",
      "Epoch 22/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7245 - val_loss: 0.7037\n",
      "Epoch 23/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7252 - val_loss: 0.6673\n",
      "Epoch 24/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7182 - val_loss: 0.7381\n",
      "Epoch 25/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7288 - val_loss: 0.6966\n",
      "Epoch 26/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7286 - val_loss: 0.6570\n",
      "Epoch 27/100\n",
      "372/372 [==============================] - 1s 4ms/step - loss: 0.7123 - val_loss: 0.6285\n",
      "Epoch 28/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7097 - val_loss: 0.6780\n",
      "Epoch 29/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.7148 - val_loss: 0.6455\n",
      "Epoch 30/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.7196 - val_loss: 0.6297\n",
      "Epoch 31/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6972 - val_loss: 0.6286\n",
      "Epoch 32/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6973 - val_loss: 0.6213\n",
      "Epoch 33/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6860 - val_loss: 0.6293\n",
      "Epoch 34/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6825 - val_loss: 0.6489\n",
      "Epoch 35/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.7016 - val_loss: 0.6390\n",
      "Epoch 36/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6959 - val_loss: 0.6640\n",
      "Epoch 37/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6976 - val_loss: 0.6607\n",
      "Epoch 38/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6827 - val_loss: 0.6241\n",
      "Epoch 39/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6892 - val_loss: 0.6309\n",
      "Epoch 40/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6706 - val_loss: 0.6363\n",
      "Epoch 41/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6863 - val_loss: 0.6149\n",
      "Epoch 42/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6663 - val_loss: 0.6245\n",
      "Epoch 43/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6640 - val_loss: 0.6161\n",
      "Epoch 44/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6687 - val_loss: 0.6062\n",
      "Epoch 45/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6731 - val_loss: 0.6664\n",
      "Epoch 46/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6672 - val_loss: 0.6165\n",
      "Epoch 47/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6503 - val_loss: 0.6070\n",
      "Epoch 48/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6647 - val_loss: 0.6172\n",
      "Epoch 49/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6540 - val_loss: 0.6003\n",
      "Epoch 50/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6546 - val_loss: 0.6110\n",
      "Epoch 51/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6633 - val_loss: 0.5997\n",
      "Epoch 52/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6493 - val_loss: 0.6820\n",
      "Epoch 53/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6486 - val_loss: 0.7392\n",
      "Epoch 54/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6445 - val_loss: 0.6138\n",
      "Epoch 55/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6355 - val_loss: 0.6321\n",
      "Epoch 56/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6545 - val_loss: 0.6943\n",
      "Epoch 57/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6446 - val_loss: 0.5892\n",
      "Epoch 58/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6407 - val_loss: 0.6481\n",
      "Epoch 59/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6357 - val_loss: 0.5752\n",
      "Epoch 60/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6258 - val_loss: 0.6153\n",
      "Epoch 61/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6310 - val_loss: 0.6103\n",
      "Epoch 62/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6287 - val_loss: 0.6040\n",
      "Epoch 63/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6248 - val_loss: 0.5800\n",
      "Epoch 64/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6253 - val_loss: 0.6040- loss: 0.625\n",
      "Epoch 65/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6180 - val_loss: 0.5973\n",
      "Epoch 66/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6260 - val_loss: 0.6093\n",
      "Epoch 67/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6184 - val_loss: 0.5996\n",
      "Epoch 68/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6135 - val_loss: 0.5854\n",
      "Epoch 69/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6209 - val_loss: 0.6142\n",
      "Epoch 70/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6106 - val_loss: 0.6159 ETA: 0s - loss: 0.60\n",
      "Epoch 71/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6228 - val_loss: 0.5694\n",
      "Epoch 72/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6065 - val_loss: 0.5943\n",
      "Epoch 73/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6027 - val_loss: 0.6053\n",
      "Epoch 74/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6172 - val_loss: 0.6406\n",
      "Epoch 75/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.6023 - val_loss: 0.5841\n",
      "Epoch 76/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6114 - val_loss: 0.5782\n",
      "Epoch 77/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6053 - val_loss: 0.6343\n",
      "Epoch 78/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.5963 - val_loss: 0.5895\n",
      "Epoch 79/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6014 - val_loss: 0.5930\n",
      "Epoch 80/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.5997 - val_loss: 0.6154\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 1s 2ms/step - loss: 0.5944 - val_loss: 0.6143\n",
      "Epoch 82/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.5947 - val_loss: 0.5586\n",
      "Epoch 83/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.5897 - val_loss: 0.5977\n",
      "Epoch 84/100\n",
      "372/372 [==============================] - 1s 4ms/step - loss: 0.5881 - val_loss: 0.5912\n",
      "Epoch 85/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.5942 - val_loss: 0.7637\n",
      "Epoch 86/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.5950 - val_loss: 0.6342\n",
      "Epoch 87/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.6000 - val_loss: 0.5775\n",
      "Epoch 88/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.5814 - val_loss: 0.6080\n",
      "Epoch 89/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.5799 - val_loss: 0.5630\n",
      "Epoch 90/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.5826 - val_loss: 0.5631\n",
      "Epoch 91/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.5824 - val_loss: 0.5774\n",
      "Epoch 92/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.5877 - val_loss: 0.5671\n",
      "Epoch 93/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.5913 - val_loss: 0.5783\n",
      "Epoch 94/100\n",
      "372/372 [==============================] - 1s 4ms/step - loss: 0.5850 - val_loss: 0.5538\n",
      "Epoch 95/100\n",
      "372/372 [==============================] - 1s 4ms/step - loss: 0.5774 - val_loss: 0.5847\n",
      "Epoch 96/100\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.5915 - val_loss: 0.5617\n",
      "Epoch 97/100\n",
      "372/372 [==============================] - 1s 4ms/step - loss: 0.5736 - val_loss: 0.5681\n",
      "Epoch 98/100\n",
      "372/372 [==============================] - 1s 3ms/step - loss: 0.5913 - val_loss: 0.5869\n",
      "Epoch 99/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.5797 - val_loss: 0.5820\n",
      "Epoch 100/100\n",
      "372/372 [==============================] - 1s 2ms/step - loss: 0.5682 - val_loss: 0.6049\n",
      "\n",
      "RMSE for validation 0.7777303071848823\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.757 m/s as root mean\n",
      "Wind MAE:  0.556 m/s in avg\n",
      "Wind MAPE:  7.79 %\n",
      "Power RMSE:  309.456 kW as root mean\n",
      "Power MAE:  183.964 kW in avg\n",
      "Power MAPE:  6.290893209686348e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.866 m/s as root mean\n",
      "Wind MAE:  0.614 m/s in avg\n",
      "Wind MAPE:  9.369 %\n",
      "Power RMSE:  328.203 kW as root mean\n",
      "Power MAE:  175.158 kW in avg\n",
      "Power MAPE:  1.1541772249653957e+18 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d8e418",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e68dd",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c679f5f",
   "metadata": {},
   "source": [
    "MAPE wind T11: 9.369%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce6c5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dataset2_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e998f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ad48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc041588",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "369fd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('dataset2_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43868f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a049d80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.757 m/s as root mean\n",
      "Wind MAE:  0.556 m/s in avg\n",
      "Wind MAPE:  7.79 %\n",
      "Power RMSE:  309.456 kW as root mean\n",
      "Power MAE:  183.964 kW in avg\n",
      "Power MAPE:  6.290893209686348e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.866 m/s as root mean\n",
      "Wind MAE:  0.614 m/s in avg\n",
      "Wind MAPE:  9.369 %\n",
      "Power RMSE:  328.203 kW as root mean\n",
      "Power MAE:  175.158 kW in avg\n",
      "Power MAPE:  1.1541772249653957e+18 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "547c95e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b754bb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WD1', 'WD4', 'WSHor', 'WSVer', 'WDHor', 'RH1',\n",
       "       'Rain', 'WSH', 'WVeer', 'TI', 'WDVer', 'WD_bin', 'tod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "# data_up= uploading_csv('\\Dataset1-Normal_Site','\\data_comp14.csv')\n",
    "X_train= uploading_csv('\\General','\\X_train2.csv')\n",
    "X_test= uploading_csv('\\General','\\X_test17.csv')\n",
    "y_train= uploading_csv('\\General','\\y_train2.csv')\n",
    "y_test= uploading_csv('\\General','\\y_test17.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cad5277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(columns=['RH1'])\n",
    "X_test=X_test.drop(columns=['RH1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51cf679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset2-Complex_Site','\\PC_V112.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66e588d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.757 m/s as root mean\n",
      "Wind MAE:  0.556 m/s in avg\n",
      "Wind MAPE:  7.79 %\n",
      "Power RMSE:  305.568 kW as root mean\n",
      "Power MAE:  187.497 kW in avg\n",
      "Power MAPE:  6.128421798360227e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.666 m/s as root mean\n",
      "Wind MAE:  0.51 m/s in avg\n",
      "Wind MAPE:  5.612 %\n",
      "Power RMSE:  280.857 kW as root mean\n",
      "Power MAE:  175.886 kW in avg\n",
      "Power MAPE:  13.166 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94c406c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98078f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WD1', 'WD4', 'WSHor', 'WSVer', 'WDHor', 'RH1',\n",
       "       'Rain', 'WSH', 'WVeer', 'TI', 'WDVer', 'WD_bin', 'tod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "# data_up= uploading_csv('\\Dataset1-Normal_Site','\\data_comp14.csv')\n",
    "X_train= uploading_csv('\\General','\\X_train2.csv')\n",
    "X_test= uploading_csv('\\General','\\X_test22.csv')\n",
    "y_train= uploading_csv('\\General','\\y_train2.csv')\n",
    "y_test= uploading_csv('\\General','\\y_test22.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ab2d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(columns=['RH1'])\n",
    "X_test=X_test.drop(columns=['RH1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e28f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset2-Complex_Site','\\PC_V112.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "255d795a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.757 m/s as root mean\n",
      "Wind MAE:  0.556 m/s in avg\n",
      "Wind MAPE:  7.79 %\n",
      "Power RMSE:  305.568 kW as root mean\n",
      "Power MAE:  187.497 kW in avg\n",
      "Power MAPE:  6.128421798360227e+17 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.794 m/s as root mean\n",
      "Wind MAE:  0.604 m/s in avg\n",
      "Wind MAPE:  7.993 %\n",
      "Power RMSE:  349.184 kW as root mean\n",
      "Power MAE:  239.061 kW in avg\n",
      "Power MAPE:  33.547 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f8e66",
   "metadata": {},
   "source": [
    "## Dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a242daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WSHor', 'WDHor', 'WSVer', 'WDVer', 'T1', 'RH1',\n",
       "       'T2', 'RH2', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WD1', 'WD3', 'WD4',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "# data_up= uploading_csv('\\Dataset1-Normal_Site','\\data_comp14.csv')\n",
    "X_train= uploading_csv('\\General','\\X_train3.csv')\n",
    "X_test= uploading_csv('\\General','\\X_test18.csv')\n",
    "y_train= uploading_csv('\\General','\\y_train3.csv')\n",
    "y_test= uploading_csv('\\General','\\y_test18.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43f87368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0d70110",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC= uploading_csv('\\Dataset3-New_Site','\\PC_V150.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab9e02",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b4ef62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8eba2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1cfb14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Dropout', 'optimizer': 'Nesterov', 'n_neurons': 80, 'n_hidden': 3, 'learning_rate': 0.001, 'input_shape': 17, 'activation': 'relu', 'Leaky': True}\n",
      "Best score :\n",
      "-0.6610205769538879\n",
      "\n",
      "--- 9.078933183352152 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.707 m/s as root mean\n",
      "Wind MAE:  0.538 m/s in avg\n",
      "Wind MAPE:  7.318 %\n",
      "Power RMSE:  317.923 kW as root mean\n",
      "Power MAE:  213.835 kW in avg\n",
      "Power MAPE:  7.421315656754958e+16 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.741 m/s as root mean\n",
      "Wind MAE:  0.559 m/s in avg\n",
      "Wind MAPE:  7.467 %\n",
      "Power RMSE:  348.899 kW as root mean\n",
      "Power MAE:  227.326 kW in avg\n",
      "Power MAPE:  24.052 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc2b3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs={\n",
    "    'n_hidden':[0, 1, 2, 3],\n",
    "    'n_neurons': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.005, 0.01, 0.03],\n",
    "    'activation':['relu', 'elu', 'selu'],\n",
    "    'optimizer':['Adam', 'Nesterov', 'Momentum', 'Nadam'],\n",
    "    'regularization':[None, 'Dropout', 'Early Stopping'],\n",
    "    'Leaky':[True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55a0c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [-1.37643977 -1.69325157 -1.64425476 -1.00734305 -0.82106346 -0.83543595\n",
      " -0.89177605 -1.17182251 -0.69177105 -0.77259185 -1.05052233 -0.96071255\n",
      " -0.71196856 -0.72100133         nan -0.78692005 -0.82343479 -0.99675479\n",
      " -0.96730433 -1.00919571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters :\n",
      "{'regularization': 'Dropout', 'optimizer': 'Nesterov', 'n_neurons': 30, 'n_hidden': 2, 'learning_rate': 0.003, 'input_shape': 17, 'activation': 'relu', 'Leaky': True}\n",
      "Best score :\n",
      "-0.6917710502942404\n",
      "\n",
      "--- 8.941617663701376 minutes ---\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.844 m/s as root mean\n",
      "Wind MAE:  0.646 m/s in avg\n",
      "Wind MAPE:  8.645 %\n",
      "Power RMSE:  379.044 kW as root mean\n",
      "Power MAE:  251.963 kW in avg\n",
      "Power MAPE:  7.349464790500515e+16 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.821 m/s as root mean\n",
      "Wind MAE:  0.621 m/s in avg\n",
      "Wind MAPE:  8.116 %\n",
      "Power RMSE:  378.153 kW as root mean\n",
      "Power MAE:  242.28 kW in avg\n",
      "Power MAPE:  24.985 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "RandomSearch_ NN performed\n"
     ]
    }
   ],
   "source": [
    "model= RandomSearch_NN(X_train, X_test, y_train, y_test, PC, param_distribs, plot_error=False)\n",
    "#iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6c74b",
   "metadata": {},
   "source": [
    "### Manual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ccb4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6564fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 2.4088 - val_loss: 0.3557\n",
      "Epoch 2/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3201\n",
      "Epoch 3/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.3256 - val_loss: 0.3466\n",
      "Epoch 4/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.3294 - val_loss: 0.3078\n",
      "Epoch 5/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.3063 - val_loss: 0.2974\n",
      "Epoch 6/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.3123 - val_loss: 0.3854\n",
      "Epoch 7/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2995 - val_loss: 0.2889\n",
      "Epoch 8/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.3016 - val_loss: 0.2864\n",
      "Epoch 9/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.3003 - val_loss: 0.2876\n",
      "Epoch 10/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2912 - val_loss: 0.3429\n",
      "Epoch 11/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2905 - val_loss: 0.2851\n",
      "Epoch 12/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2861 - val_loss: 0.2815\n",
      "Epoch 13/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2837 - val_loss: 0.2923\n",
      "Epoch 14/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2864 - val_loss: 0.2810\n",
      "Epoch 15/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2840 - val_loss: 0.2779\n",
      "Epoch 16/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2771 - val_loss: 0.2729\n",
      "Epoch 17/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2726 - val_loss: 0.3003\n",
      "Epoch 18/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2775 - val_loss: 0.2721\n",
      "Epoch 19/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2720 - val_loss: 0.2859\n",
      "Epoch 20/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2794 - val_loss: 0.2693\n",
      "Epoch 21/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2818 - val_loss: 0.2667\n",
      "Epoch 22/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2762 - val_loss: 0.2705\n",
      "Epoch 23/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2698 - val_loss: 0.3646\n",
      "Epoch 24/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2699 - val_loss: 0.2757\n",
      "Epoch 25/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2676 - val_loss: 0.2730\n",
      "Epoch 26/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2736 - val_loss: 0.2707\n",
      "Epoch 27/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2736 - val_loss: 0.2688\n",
      "Epoch 28/100\n",
      "449/449 [==============================] - 2s 4ms/step - loss: 0.2645 - val_loss: 0.2664\n",
      "Epoch 29/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2653 - val_loss: 0.2879\n",
      "Epoch 30/100\n",
      "449/449 [==============================] - 2s 4ms/step - loss: 0.2605 - val_loss: 0.2653\n",
      "Epoch 31/100\n",
      "449/449 [==============================] - 2s 4ms/step - loss: 0.2600 - val_loss: 0.2658\n",
      "Epoch 32/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2602 - val_loss: 0.2624\n",
      "Epoch 33/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2629 - val_loss: 0.2664\n",
      "Epoch 34/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2654 - val_loss: 0.2653\n",
      "Epoch 35/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2539 - val_loss: 0.2665\n",
      "Epoch 36/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2556 - val_loss: 0.2603\n",
      "Epoch 37/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2587 - val_loss: 0.3002\n",
      "Epoch 38/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2525 - val_loss: 0.2587\n",
      "Epoch 39/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2528 - val_loss: 0.3121\n",
      "Epoch 40/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2532 - val_loss: 0.2573\n",
      "Epoch 41/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2534 - val_loss: 0.2668\n",
      "Epoch 42/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2524 - val_loss: 0.2680\n",
      "Epoch 43/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2492 - val_loss: 0.2586\n",
      "Epoch 44/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2466 - val_loss: 0.2814\n",
      "Epoch 45/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2484 - val_loss: 0.2860\n",
      "Epoch 46/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2456 - val_loss: 0.2842\n",
      "Epoch 47/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2441 - val_loss: 0.2855\n",
      "Epoch 48/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2470 - val_loss: 0.3611\n",
      "Epoch 49/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2480 - val_loss: 0.2690\n",
      "Epoch 50/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2409 - val_loss: 0.2712\n",
      "Epoch 51/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2431 - val_loss: 0.2830\n",
      "Epoch 52/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2478 - val_loss: 0.2970\n",
      "Epoch 53/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2401 - val_loss: 0.2589\n",
      "Epoch 54/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2407 - val_loss: 0.2677\n",
      "Epoch 55/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2403 - val_loss: 0.2517\n",
      "Epoch 56/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2409 - val_loss: 0.2633\n",
      "Epoch 57/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2360 - val_loss: 0.2529\n",
      "Epoch 58/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2431 - val_loss: 0.2776\n",
      "Epoch 59/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2400 - val_loss: 0.2610\n",
      "Epoch 60/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2338 - val_loss: 0.2577\n",
      "Epoch 61/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2336 - val_loss: 0.2554\n",
      "Epoch 62/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2347 - val_loss: 0.2683\n",
      "Epoch 63/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2308 - val_loss: 0.2569\n",
      "Epoch 64/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2350 - val_loss: 0.2970\n",
      "Epoch 65/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2341 - val_loss: 0.2543\n",
      "Epoch 66/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2374 - val_loss: 0.2629\n",
      "Epoch 67/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2310 - val_loss: 0.2587\n",
      "Epoch 68/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2326 - val_loss: 0.2649\n",
      "Epoch 69/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2348 - val_loss: 0.2826\n",
      "Epoch 70/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2286 - val_loss: 0.2645\n",
      "Epoch 71/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2290 - val_loss: 0.2666\n",
      "Epoch 72/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2291 - val_loss: 0.2442\n",
      "Epoch 73/100\n",
      "449/449 [==============================] - 2s 3ms/step - loss: 0.2295 - val_loss: 0.2714\n",
      "Epoch 74/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2305 - val_loss: 0.2882\n",
      "Epoch 75/100\n",
      "449/449 [==============================] - 2s 3ms/step - loss: 0.2275 - val_loss: 0.2541\n",
      "Epoch 76/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2261 - val_loss: 0.2576\n",
      "Epoch 77/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2281 - val_loss: 0.2494\n",
      "Epoch 78/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2240 - val_loss: 0.2503\n",
      "Epoch 79/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2251 - val_loss: 0.2646\n",
      "Epoch 80/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2222 - val_loss: 0.2710\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2277 - val_loss: 0.2461\n",
      "Epoch 82/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2229 - val_loss: 0.2530\n",
      "Epoch 83/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2224 - val_loss: 0.2510\n",
      "Epoch 84/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2240 - val_loss: 0.2474\n",
      "Epoch 85/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2160 - val_loss: 0.2492\n",
      "Epoch 86/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2230 - val_loss: 0.2740\n",
      "Epoch 87/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2185 - val_loss: 0.2455\n",
      "Epoch 88/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2188 - val_loss: 0.2628\n",
      "Epoch 89/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2159 - val_loss: 0.2588\n",
      "Epoch 90/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2171 - val_loss: 0.2697\n",
      "Epoch 91/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2211 - val_loss: 0.2535\n",
      "Epoch 92/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2161 - val_loss: 0.2500\n",
      "Epoch 93/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2166 - val_loss: 0.2454\n",
      "Epoch 94/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2154 - val_loss: 0.2539\n",
      "Epoch 95/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2173 - val_loss: 0.2588\n",
      "Epoch 96/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2165 - val_loss: 0.2429\n",
      "Epoch 97/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2195 - val_loss: 0.2693\n",
      "Epoch 98/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2128 - val_loss: 0.2493\n",
      "Epoch 99/100\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2135 - val_loss: 0.2403\n",
      "Epoch 100/100\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2152 - val_loss: 0.2484\n",
      "\n",
      "RMSE for validation 0.498362823694159\n",
      "\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.457 m/s as root mean\n",
      "Wind MAE:  0.338 m/s in avg\n",
      "Wind MAPE:  4.256 %\n",
      "Power RMSE:  259.989 kW as root mean\n",
      "Power MAE:  168.729 kW in avg\n",
      "Power MAPE:  10.304 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.489 m/s as root mean\n",
      "Wind MAE:  0.349 m/s in avg\n",
      "Wind MAPE:  4.526 %\n",
      "Power RMSE:  268.909 kW as root mean\n",
      "Power MAE:  176.203 kW in avg\n",
      "Power MAPE:  21.752 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN modelling performed\n"
     ]
    }
   ],
   "source": [
    "model = modelling_NN (X_train, X_test, y_train, y_test, PC, parameters, plot_error=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9348216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29f5f492",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26db8c",
   "metadata": {},
   "source": [
    "parameters={\n",
    "    'n_hidden':3,\n",
    "    'n_neurons': 80,\n",
    "    'learning_rate':0.001,\n",
    "    'activation':'elu',\n",
    "    'optimizer':'Adam',\n",
    "    'regularization':None,\n",
    "    'Leaky':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d5176",
   "metadata": {},
   "source": [
    "MAPE wind: 4.526% for WTG18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4dd9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dataset3_ANN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71206bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568d86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5148bd3a",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "201fc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('dataset3_ANN1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaaeca8",
   "metadata": {},
   "source": [
    "### WTG18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cca62eca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.457 m/s as root mean\n",
      "Wind MAE:  0.338 m/s in avg\n",
      "Wind MAPE:  4.256 %\n",
      "Power RMSE:  259.989 kW as root mean\n",
      "Power MAE:  168.729 kW in avg\n",
      "Power MAPE:  10.304 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.489 m/s as root mean\n",
      "Wind MAE:  0.349 m/s in avg\n",
      "Wind MAPE:  4.526 %\n",
      "Power RMSE:  268.909 kW as root mean\n",
      "Power MAE:  176.203 kW in avg\n",
      "Power MAPE:  21.752 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc4b97",
   "metadata": {},
   "source": [
    "### WTG20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1575ce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WSHor', 'WDHor', 'WSVer', 'WDVer', 'T1', 'RH1',\n",
       "       'T2', 'RH2', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WD1', 'WD3', 'WD4',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "X_train= uploading_csv('\\General','\\X_train3.csv')\n",
    "X_test= uploading_csv('\\General','\\X_test20.csv')\n",
    "y_train= uploading_csv('\\General','\\y_train3.csv')\n",
    "y_test= uploading_csv('\\General','\\y_test20.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a73203a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.457 m/s as root mean\n",
      "Wind MAE:  0.338 m/s in avg\n",
      "Wind MAPE:  4.256 %\n",
      "Power RMSE:  259.989 kW as root mean\n",
      "Power MAE:  168.729 kW in avg\n",
      "Power MAPE:  10.304 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.456 m/s as root mean\n",
      "Wind MAE:  0.33 m/s in avg\n",
      "Wind MAPE:  4.221 %\n",
      "Power RMSE:  265.775 kW as root mean\n",
      "Power MAE:  174.27 kW in avg\n",
      "Power MAPE:  10.093 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a0f95",
   "metadata": {},
   "source": [
    "### WTG43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd5f45a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WSHor', 'WDHor', 'WSVer', 'WDVer', 'T1', 'RH1',\n",
       "       'T2', 'RH2', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WD1', 'WD3', 'WD4',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "X_train= uploading_csv('\\General','\\X_train3.csv')\n",
    "X_test= uploading_csv('\\General','\\X_test43.csv')\n",
    "y_train= uploading_csv('\\General','\\y_train3.csv')\n",
    "y_test= uploading_csv('\\General','\\y_test43.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d8c2882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.457 m/s as root mean\n",
      "Wind MAE:  0.338 m/s in avg\n",
      "Wind MAPE:  4.256 %\n",
      "Power RMSE:  259.989 kW as root mean\n",
      "Power MAE:  168.729 kW in avg\n",
      "Power MAPE:  10.304 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.557 m/s as root mean\n",
      "Wind MAE:  0.43 m/s in avg\n",
      "Wind MAPE:  4.965 %\n",
      "Power RMSE:  295.341 kW as root mean\n",
      "Power MAE:  185.425 kW in avg\n",
      "Power MAPE:  10.188 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac88f9d",
   "metadata": {},
   "source": [
    "### WTG46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b804f888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WS1', 'WS3', 'WS4', 'WSHor', 'WDHor', 'WSVer', 'WDVer', 'T1', 'RH1',\n",
       "       'T2', 'RH2', 'PR1', 'AD1', 'PR2', 'AD2', 'Rain', 'WD1', 'WD3', 'WD4',\n",
       "       'TI', 'WSH', 'WD_bin', 'tod', 'WVeer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload the dataset with file_folder, file_name\n",
    "X_train= uploading_csv('\\General','\\X_train3.csv')\n",
    "X_test= uploading_csv('\\General','\\X_test46.csv')\n",
    "y_train= uploading_csv('\\General','\\y_train3.csv')\n",
    "y_test= uploading_csv('\\General','\\y_test46.csv')\n",
    "\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5eae6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "power curve computation performed\n",
      "power curve computation performed\n",
      "Modelling errors for training set:\n",
      "Wind RMSE:  0.457 m/s as root mean\n",
      "Wind MAE:  0.338 m/s in avg\n",
      "Wind MAPE:  4.256 %\n",
      "Power RMSE:  259.989 kW as root mean\n",
      "Power MAE:  168.729 kW in avg\n",
      "Power MAPE:  10.304 %\n",
      "\n",
      "Modelling errors for test set:\n",
      "Wind RMSE:  0.416 m/s as root mean\n",
      "Wind MAE:  0.308 m/s in avg\n",
      "Wind MAPE:  4.202 %\n",
      "Power RMSE:  252.933 kW as root mean\n",
      "Power MAE:  162.5 kW in avg\n",
      "Power MAPE:  11.253 %\n",
      "\n",
      "Showing the results of the modelling: \n",
      "NN results performed\n"
     ]
    }
   ],
   "source": [
    "model_testing (X_train, X_test, y_train, y_test, PC, model, plot_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954fb776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "354.74px",
    "left": "1350.99px",
    "right": "20px",
    "top": "2px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
